version: 2.1

parameters:
  ubuntu-amd64-machine-image:
    type: string
    default: "ubuntu-2204:2023.02.1"
  ubuntu-arm64-machine-image:
    type: string
    default: "ubuntu-2204:2023.02.1"
  PYTEST_LOGLEVEL:
    type: string
    default: "WARNING"
  skip_test_selection:
    type: boolean
    default: false
  randomize-aws-credentials:
    type: boolean
    default: false

executors:
  ubuntu-machine-amd64:
    machine:
      image: << pipeline.parameters.ubuntu-amd64-machine-image >>

commands:
  prepare-testselection:
    steps:
      - unless:
          condition: << pipeline.parameters.skip_test_selection >>
          steps:
            - run:
                name: Setup test selection environment variable
                command: |
                  if [[ -n "$CI_PULL_REQUEST" ]] ; then
                    echo "export TESTSELECTION_PYTEST_ARGS='--path-filter=target/testselection/test-selection.txt '" >> $BASH_ENV
                  fi

  prepare-pytest-tinybird:
    steps:
      - run:
          name: Setup Environment Variables
          command: |
            if [[ $CIRCLE_BRANCH == "master" ]] ; then
              echo "export TINYBIRD_PYTEST_ARGS='--report-to-tinybird '" >> $BASH_ENV
            fi
            if << pipeline.parameters.randomize-aws-credentials >> ; then
              echo "export TINYBIRD_DATASOURCE=community_tests_circleci_ma_mr" >> $BASH_ENV
            else
              echo "export TINYBIRD_DATASOURCE=community_tests_circleci" >> $BASH_ENV
            fi
            echo "export TINYBIRD_TOKEN=${TINYBIRD_CI_TOKEN}" >> $BASH_ENV
            echo "export CI_COMMIT_BRANCH=${CIRCLE_BRANCH}" >> $BASH_ENV
            echo "export CI_COMMIT_SHA=${CIRCLE_SHA1}" >> $BASH_ENV
            echo "export CI_JOB_URL=${CIRCLE_BUILD_URL}" >> $BASH_ENV
            # workflow ID as the job name to associate the tests with workflows in TB
            echo "export CI_JOB_NAME=${CIRCLE_WORKFLOW_ID}" >> $BASH_ENV
            echo "export CI_JOB_ID=${CIRCLE_JOB}" >> $BASH_ENV
            source $BASH_ENV

  prepare-account-region-randomization:
    steps:
      - when:
          condition: << pipeline.parameters.randomize-aws-credentials >>
          steps:
            - run:
                name: Generate Random AWS Account ID
                command: |
                  # Generate a random 12-digit number for TEST_AWS_ACCOUNT_ID
                  export TEST_AWS_ACCOUNT_ID=$(LC_ALL=C tr -dc '0-9' < /dev/urandom | fold -w 12 | head -n 1)
                  export TEST_AWS_ACCESS_KEY_ID=$TEST_AWS_ACCOUNT_ID
                  # Set TEST_AWS_REGION_NAME to a random AWS region other than us-east-1
                  export AWS_REGIONS=("us-east-2" "us-west-1" "us-west-2" "ap-southeast-2" "ap-northeast-1" "eu-central-1" "eu-west-1")
                  export TEST_AWS_REGION_NAME=${AWS_REGIONS[$RANDOM % ${#AWS_REGIONS[@]}]}
                  echo "export TEST_AWS_REGION_NAME=${TEST_AWS_REGION_NAME}" >> $BASH_ENV
                  echo "export TEST_AWS_ACCESS_KEY_ID=${TEST_AWS_ACCESS_KEY_ID}" >> $BASH_ENV
                  echo "export TEST_AWS_ACCOUNT_ID=${TEST_AWS_ACCOUNT_ID}" >> $BASH_ENV
                  source $BASH_ENV


jobs:
  install:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - checkout
      - restore_cache:
          key: python-requirements-{{ checksum "requirements-dev.txt" }}
      - run:
          name: Setup environment
          command: |
            make install
            mkdir -p target/reports
            mkdir -p target/coverage
      - save_cache:
          key: python-requirements-{{ checksum "requirements-dev.txt" }}
          paths:
            - "~/.cache/pip"
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo

  preflight:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Linting
          command: make lint
      - run:
          name: Checking AWS compatibility markers
          command: make check-aws-markers


  # can't completely skip it since we need the dependency from other tasks => conditional in run step
  test-selection:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - unless:
          condition: << pipeline.parameters.skip_test_selection >>
          steps:
            - run:
                # script expects an environment variable $GITHUB_API_TOKEN to be set to fetch PR details
                name: Generate test selection filters from changed files
                command: |
                  if [[ -z "$CI_PULL_REQUEST" ]] ; then
                    echo "Skipping test selection"
                    circleci-agent step halt
                  else
                    source .venv/bin/activate
                    python -m localstack.testing.testselection.scripts.generate_test_selection_from_pr /tmp/workspace/repo $CI_PULL_REQUEST target/testselection/test-selection.txt
                    cat target/testselection/test-selection.txt
                  fi

            - persist_to_workspace:
                root:
                  /tmp/workspace
                paths:
                  - repo/target/testselection/

  unit-tests:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Unit tests
          environment:
            TEST_PATH: "tests/unit"
            COVERAGE_ARGS: "-p"
          command: |
            COVERAGE_FILE="target/coverage/.coverage.unit.${CIRCLE_NODE_INDEX}" \
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}--junitxml=target/reports/unit-tests.xml -o junit_suite_name=unit-tests" \
            make test-coverage
      - store_test_results:
          path: target/reports/
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/coverage/

  acceptance-tests:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    environment:
      PYTEST_LOGLEVEL: << pipeline.parameters.PYTEST_LOGLEVEL >>
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Acceptance tests (EXPERIMENTAL)
          environment:
            TEST_PATH: "tests/aws/"
            COVERAGE_ARGS: "-p"
            LOCALSTACK_INTERNAL_TEST_COLLECT_METRIC: 1
          command: |
            COVERAGE_FILE="target/coverage/.coverage.acceptance.${CIRCLE_NODE_INDEX}" \
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}--reruns 3 -m acceptance_test --junitxml=target/reports/acceptance_test.xml -o junit_suite_name='acceptance_test'" \
            make test-coverage
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/reports/
            - repo/target/metric_reports/
            - repo/target/coverage/
      - store_test_results:
          path: target/reports/

  itest-sfn-legacy-provider:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    environment:
      PYTEST_LOGLEVEL: << pipeline.parameters.PYTEST_LOGLEVEL >>
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - prepare-testselection
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Test SFN Legacy provider
          environment:
            PROVIDER_OVERRIDE_STEPFUNCTIONS: "legacy"
            TEST_PATH: "tests/aws/services/stepfunctions/legacy/"
            COVERAGE_ARGS: "-p"
          command: |
            COVERAGE_FILE="target/coverage/.coverage.sfnlegacy.${CIRCLE_NODE_INDEX}" \
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}${TESTSELECTION_PYTEST_ARGS}--reruns 3 --junitxml=target/reports/sfn_legacy.xml -o junit_suite_name='sfn_legacy'" \
            make test-coverage
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/coverage/
      - store_test_results:
          path: target/reports/

  itest-s3-v2-legacy-provider:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    environment:
      PYTEST_LOGLEVEL: << pipeline.parameters.PYTEST_LOGLEVEL >>
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - prepare-testselection
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Test S3 v2 legacy provider
          environment:
            PROVIDER_OVERRIDE_S3: "legacy_v2"
            TEST_PATH: "tests/aws/services/s3/"
            COVERAGE_ARGS: "-p"
          command: |
            COVERAGE_FILE="target/coverage/.coverage.s3legacy.${CIRCLE_NODE_INDEX}" \
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}${TESTSELECTION_PYTEST_ARGS}--reruns 3 --junitxml=target/reports/s3_legacy.xml -o junit_suite_name='s3_legacy'" \
            make test-coverage
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/coverage/
      - store_test_results:
          path: target/reports/

  itest-cloudwatch-v2-provider:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    environment:
      PYTEST_LOGLEVEL: << pipeline.parameters.PYTEST_LOGLEVEL >>
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - prepare-testselection
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Test CloudWatch v2 provider
          environment:
            PROVIDER_OVERRIDE_CLOUDWATCH: "v2"
            TEST_PATH: "tests/aws/services/cloudwatch/"
            COVERAGE_ARGS: "-p"
          command: |
            COVERAGE_FILE="target/coverage/.coverage.cloudwatchV2.${CIRCLE_NODE_INDEX}" \
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}${TESTSELECTION_PYTEST_ARGS}--reruns 3 --junitxml=target/reports/cloudwatch_v2.xml -o junit_suite_name='cloudwatch_v2'" \
            make test-coverage
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/coverage/
      - store_test_results:
          path: target/reports/

  itest-events-v2-provider:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    environment:
      PYTEST_LOGLEVEL: << pipeline.parameters.PYTEST_LOGLEVEL >>
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - prepare-testselection
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Test EventBridge v2 provider
          environment:
            PROVIDER_OVERRIDE_EVENTS: "v2"
            TEST_PATH: "tests/aws/services/events/"
            COVERAGE_ARGS: "-p"
          command: |
            COVERAGE_FILE="target/coverage/.coverage.eventsV2.${CIRCLE_NODE_INDEX}" \
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}${TESTSELECTION_PYTEST_ARGS}--reruns 3 --junitxml=target/reports/events_v2.xml -o junit_suite_name='events_v2'" \
            make test-coverage
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/coverage/
      - store_test_results:
          path: target/reports/

  docker-build:
    parameters:
      platform:
        description: "Platform to build for"
        default: "amd64"
        type: string
      machine_image:
        description: "CircleCI machine type to run at"
        default: "ubuntu-2004:202107-02"
        type: string
      resource_class:
        description: "CircleCI machine type to run at"
        default: "medium"
        type: string
    machine:
      image: << parameters.machine_image >>
    resource_class: << parameters.resource_class >>
    working_directory: /tmp/workspace/repo
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Build community docker image
          command: make docker-build
      - run:
          name: Save docker image
          command: PLATFORM="<< parameters.platform >>" make docker-save-image
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/

  docker-test:
    parameters:
      platform:
        description: "Platform to build for"
        default: "amd64"
        type: string
      resource_class:
        description: "CircleCI machine type to run at"
        default: "medium"
        type: string
      machine_image:
        description: "CircleCI machine type to run at"
        default: << pipeline.parameters.ubuntu-amd64-machine-image >>
        type: string
    machine:
      image: << parameters.machine_image >>
    resource_class: << parameters.resource_class >>
    working_directory: /tmp/workspace/repo
    parallelism: 5
    environment:
      PYTEST_LOGLEVEL: << pipeline.parameters.PYTEST_LOGLEVEL >>
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Load docker image
          command: docker load -i target/localstack-docker-image-<< parameters.platform >>.tar
      # Prebuild and cache Lambda multiruntime test functions, supporting both architectures: amd64 and arm64
      # Currently, all runners prebuild the Lambda functions, not just the one(s) executing Lambda multiruntime tests.
      - run:
          name: Compute Lambda build hashes
          # Any change in the Lambda function source code (i.e., **/src/**) or build process (i.e., **/Makefile) invalidates the cache
          command: |
            find tests/aws/services/lambda_/functions/common -type f \( -path '**/src/**' -o -path '**/Makefile' \) | xargs sha256sum > /tmp/common-functions-checksums
      - restore_cache:
          key: common-functions-<< parameters.platform >>-{{ checksum "/tmp/common-functions-checksums" }}
      - run:
          name: Pre-build Lambda common test packages
          command: ./scripts/build_common_test_functions.sh `pwd`/tests/aws/services/lambda_/functions/common
      - save_cache:
          key: common-functions-<< parameters.platform >>-{{ checksum "/tmp/common-functions-checksums" }}
          paths:
            - "tests/aws/services/lambda_/functions/common"
      - prepare-testselection
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Run integration tests
          # circleci split returns newline separated list, so `tr` is necessary to prevent problems in the Makefile
          # if we're doing performing a test selection, we need to filter the list of files before splitting by timings
          command: |
            if [ -z $TESTSELECTION_PYTEST_ARGS ] ; then
              TEST_FILES=$(circleci tests glob "tests/aws/**/test_*.py" "tests/integration/**/test_*.py" | circleci tests split --verbose --split-by=timings | tr '\n' ' ')
            else
              TEST_FILES=$(circleci tests glob "tests/aws/**/test_*.py" "tests/integration/**/test_*.py" | python -m localstack.testing.testselection.scripts.filter_by_test_selection target/testselection/test-selection.txt | circleci tests split --verbose --split-by=timings | tr '\n' ' ')
            fi
            echo $TEST_FILES
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}${TESTSELECTION_PYTEST_ARGS}-o junit_family=legacy --junitxml=target/reports/test-report-<< parameters.platform >>-${CIRCLE_NODE_INDEX}.xml" \
            COVERAGE_FILE="target/coverage/.coverage.<< parameters.platform >>.${CIRCLE_NODE_INDEX}" \
            TEST_PATH=$TEST_FILES \
            DEBUG=1 \
            make docker-run-tests
      - store_test_results:
          path: target/reports/
      - store_artifacts:
          path: target/reports/
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/reports/
            - repo/target/coverage/
            - repo/target/metric_reports

  bootstrap-tests:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    environment:
      PYTEST_LOGLEVEL: << pipeline.parameters.PYTEST_LOGLEVEL >>
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Load docker image
          command: docker load -i target/localstack-docker-image-amd64.tar
      - prepare-pytest-tinybird
      - prepare-account-region-randomization
      - run:
          name: Run bootstrap tests
          environment:
            TEST_PATH: "tests/bootstrap"
            COVERAGE_ARGS: "-p"
          command: |
            PYTEST_ARGS="${TINYBIRD_PYTEST_ARGS}--junitxml=target/reports/bootstrap-tests.xml -o junit_suite_name=bootstrap-tests" make test-coverage
      - store_test_results:
          path: target/reports/
      - run:
          name: Store coverage results
          command: mv .coverage.* target/coverage/
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/target/coverage/

  capture-not-implemented:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Load docker image
          command: docker load -i target/localstack-docker-image-amd64.tar
      - run:
          name: Run localstack
          command: |
            DEBUG=1 DISABLE_EVENTS="1" IMAGE_NAME="localstack/localstack:latest" bin/localstack start -d
            bin/localstack wait -t 120 || (bin/localstack logs && false)
      - run:
          name: Run capture-not-implemented
          command: |
            source .venv/bin/activate
            cd scripts
            python -m capture_notimplemented_responses
      - run:
          name: Print the logs
          command: |
            source .venv/bin/activate
            localstack logs
      - run:
          name: Stop localstack
          command: |
            source .venv/bin/activate
            localstack stop
      - persist_to_workspace:
          root:
            /tmp/workspace
          paths:
            - repo/scripts/implementation_coverage_aggregated.csv
            - repo/scripts/implementation_coverage_full.csv

  report:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - attach_workspace:
          at: /tmp/workspace
      # store (uncombined) coverage from acceptance tests
      - run:
          name: fetch isolated acceptance coverage
          # might need to combine coverage files in future
          command: |
            cp target/coverage/.coverage.acceptance.* .coverage.acceptance
      - store_artifacts:
          path: .coverage.acceptance
      - run:
          name: Collect coverage
          command: |
            source .venv/bin/activate
            cd target/coverage
            ls -la
            coverage combine
            mv .coverage ../../
      - run:
          name: Report coverage statistics
          command: |
            if [ -z "${CI_PULL_REQUEST}" ]; then
              source .venv/bin/activate
              coverage report || true
              coverage html || true
              coveralls || true
            else
              echo "Skipping coverage reporting for pull request."
            fi
      - run:
          name: store acceptance parity metrics
          command: |
            mkdir acceptance_parity_metrics
            mv target/metric_reports/metric-report*acceptance* acceptance_parity_metrics/
      - run:
          name: Upload test metrics and implemented coverage data to tinybird
          command: |
            # check if a fork-only env var is set (https://circleci.com/docs/variables/)
            if [ -z "$CIRCLE_PR_REPONAME" ]; then
              source .venv/bin/activate
              mkdir parity_metrics && mv target/metric_reports/metric-report-raw-data-*amd64*.csv parity_metrics
              METRIC_REPORT_DIR_PATH=parity_metrics \
              IMPLEMENTATION_COVERAGE_FILE=scripts/implementation_coverage_full.csv \
              SOURCE_TYPE=community \
              python -m scripts.tinybird.upload_raw_test_metrics_and_coverage
            else
              echo "Skipping parity reporting to tinybird (no credentials, running on fork)..."
            fi

      - run:
          name: Create Coverage Diff (Code Coverage)
          # pycobertura diff will return with exit code 0-3 -> we currently expect 2 (2: the changes worsened the overall coverage),
          # but we still want cirecleci to continue with the tasks, so we return 0.
          # From the docs:
          # Upon exit, the diff command may return various exit codes:
          #    0: all changes are covered, no new uncovered statements have been introduced
          #    1: some exception occurred (likely due to inappropriate usage or a bug in pycobertura)
          #    2: the changes worsened the overall coverage
          #    3: the changes introduced uncovered statements but the overall coverage is still better than before
          command: |
            source .venv/bin/activate
            pip install pycobertura
            coverage xml --data-file=.coverage -o all.coverage.report.xml --include="localstack/services/*/**" --omit="*/**/__init__.py"
            coverage xml --data-file=.coverage.acceptance -o acceptance.coverage.report.xml --include="localstack/services/*/**"  --omit="*/**/__init__.py"
            pycobertura show --format html -s localstack/ acceptance.coverage.report.xml -o coverage-acceptance.html
            bash -c "pycobertura diff --format html -s1 localstack/ -s2 localstack/ all.coverage.report.xml acceptance.coverage.report.xml -o coverage-diff.html; if [[ \$? -eq 1 ]] ; then exit 1 ; else exit 0 ; fi"
      - run:
          name: Create Metric Coverage Diff (API Coverage)
          environment:
            COVERAGE_DIR_ALL: "parity_metrics"
            COVERAGE_DIR_ACCEPTANCE: "acceptance_parity_metrics"
            OUTPUT_DIR: "api-coverage"
          command: |
            source .venv/bin/activate
            mkdir api-coverage
            python -m scripts.metrics_coverage.diff_metrics_coverage
      - store_artifacts:
          path: api-coverage/
      - store_artifacts:
          path: coverage-acceptance.html
      - store_artifacts:
          path: coverage-diff.html
      - store_artifacts:
          path: parity_metrics/
      - store_artifacts:
          path: acceptance_parity_metrics/
      - store_artifacts:
          path: scripts/implementation_coverage_aggregated.csv
          destination: community/implementation_coverage_aggregated.csv
      - store_artifacts:
          path: scripts/implementation_coverage_full.csv
          destination: community/implementation_coverage_full.csv
      - store_artifacts:
          path: .coverage


  push:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Load docker image - amd64
          command: |
            # Load all image for AMD64
            docker load -i target/localstack-docker-image-amd64.tar
      - run:
          name: Log in to ECR registry
          command: aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws
      - run:
          name: Push docker image - amd64
          command: |
            # Push to Docker Hub
            PLATFORM="amd64" make docker-push-master
            # Push to Amazon Public ECR
            PLATFORM="amd64" SOURCE_IMAGE_NAME="localstack/localstack" TARGET_IMAGE_NAME="public.ecr.aws/localstack/localstack" make docker-push-master
      # Load and push per architecture (load overwrites the previous ones)
      - run:
          name: Load docker image - arm64
          command: |
            # Load all image for AMD64
            docker load -i target/localstack-docker-image-arm64.tar
      - run:
          name: Push docker image - arm64
          command: |
            # Push to Docker Hub
            PLATFORM="arm64" make docker-push-master
            # Push to Amazon Public ECR
            PLATFORM="arm64" SOURCE_IMAGE_NAME="localstack/localstack" TARGET_IMAGE_NAME="public.ecr.aws/localstack/localstack" make docker-push-master
      - run:
          name: Create multi-platform manifests
          command: |
            # Push to Docker Hub
            make docker-create-push-manifests
            # Push to Amazon Public ECR
            MANIFEST_IMAGE_NAME="public.ecr.aws/localstack/localstack" make docker-create-push-manifests
      - run:
          name: Publish a dev release
          command: |
            source .venv/bin/activate
            bin/release-helper.sh set-ver $(bin/release-helper.sh next-dev-ver)
            make publish
  push-to-tinybird:
    executor: ubuntu-machine-amd64
    working_directory: /tmp/workspace/repo
    steps:
      - run:
          name: Wait for the workflow to complete
          command: |
            # Record the time this step started
            START_TIME=$(date +%s)

            # wait for the workflow to be done
            while [[ $(curl --location --request GET "https://circleci.com/api/v2/workflow/$CIRCLE_WORKFLOW_ID/job"| jq -r '.items[]|select(.name != "push-to-tinybird" and .name != "push" and .name != "report")|.status' | grep -c "running") -gt 0 ]]; do
              sleep 10
            done

            # check if a step failed / determine the outcome
            FAILED_COUNT=$(curl --location --request GET "https://circleci.com/api/v2/workflow/$CIRCLE_WORKFLOW_ID/job" | jq -r '.items[]|.status' | grep -c "failed") || true
            echo "failed count: $FAILED_COUNT"
            if [[ $FAILED_COUNT -eq 0 ]]; then
                OUTCOME="success"
            else
                OUTCOME="failure"
            fi
            echo "outcome: $OUTCOME"

            # Record the time this step is done
            END_TIME=$(date +%s)

            if << pipeline.parameters.randomize-aws-credentials >> ; then
              TINYBIRD_WORKFLOW=tests_circleci_ma_mr
            else
              TINYBIRD_WORKFLOW=tests_circleci
            fi

            # Build the payload
            echo '{"workflow": "'$TINYBIRD_WORKFLOW'", "attempt": 1, "run_id": "'$CIRCLE_WORKFLOW_ID'", "start": '$START_TIME', "end": '$END_TIME', "commit": "'$CIRCLE_SHA1'", "branch": "'$CIRCLE_BRANCH'", "repository": "'$CIRCLE_PROJECT_USERNAME'/'$CIRCLE_PROJECT_REPONAME'", "outcome": "'$OUTCOME'", "workflow_url": "'$CIRCLE_BUILD_URL'"}' > stats.json
            echo 'Sending: '$(cat stats.json)

            # Send the data to Tinybird
            curl -X POST "https://api.tinybird.co/v0/events?name=ci_workflows" -H "Authorization: Bearer $TINYBIRD_CI_TOKEN" -d @stats.json

            # Fail this step depending on the success to trigger a rerun of this step together with others in case of a "rerun failed"
            [[ $OUTCOME = "success" ]] && exit 0 || exit 1

workflows:
  main:
    jobs:
      - push-to-tinybird:
          filters:
            branches:
              only: master
      - install
      - preflight:
          requires:
            - install
      - test-selection:
          requires:
            - install
      - acceptance-tests:
          requires:
            - preflight
      - itest-sfn-legacy-provider:
          requires:
            - preflight
            - test-selection
      - itest-s3-v2-legacy-provider:
          requires:
            - preflight
            - test-selection
      - itest-cloudwatch-v2-provider:
          requires:
            - preflight
            - test-selection
      - itest-events-v2-provider:
          requires:
            - preflight
            - test-selection
      - unit-tests:
          requires:
            - preflight
      - docker-build:
          name: docker-build-amd64
          platform: amd64
          machine_image: << pipeline.parameters.ubuntu-amd64-machine-image >>
          resource_class: medium
          requires:
            - preflight
      - docker-build:
          name: docker-build-arm64
          platform: arm64
          # The latest version of ubuntu is not yet supported for ARM:
          # https://circleci.com/docs/2.0/arm-resources/
          machine_image: << pipeline.parameters.ubuntu-arm64-machine-image >>
          resource_class: arm.medium
          requires:
            - preflight
      - docker-test:
          name: docker-test-arm64
          platform: arm64
          resource_class: arm.medium
          machine_image: << pipeline.parameters.ubuntu-arm64-machine-image >>
          requires:
            - docker-build-arm64
            - test-selection
      - docker-test:
          name: docker-test-amd64
          platform: amd64
          resource_class: medium
          machine_image: << pipeline.parameters.ubuntu-amd64-machine-image >>
          requires:
            - docker-build-amd64
            - test-selection
      - bootstrap-tests:
          requires:
            - docker-build-amd64
      - capture-not-implemented:
          name: collect-not-implemented
          requires:
            - docker-build-amd64
      - report:
          requires:
            - itest-sfn-legacy-provider
            - itest-s3-v2-legacy-provider
            - itest-cloudwatch-v2-provider
            - itest-events-v2-provider
            - acceptance-tests
            - docker-test-amd64
            - docker-test-arm64
            - collect-not-implemented
            - unit-tests
      - push:
          filters:
            branches:
              only: master
          requires:
            - itest-sfn-legacy-provider
            - itest-s3-v2-legacy-provider
            - itest-cloudwatch-v2-provider
            - itest-events-v2-provider
            - acceptance-tests
            - docker-test-amd64
            - docker-test-arm64
            - unit-tests
