name: AWS Integration Tests

on:
  workflow_dispatch:
    inputs:
      disableCaching:
        description: 'Disable Caching'
        required: false
        type: boolean
        default: false
      PYTEST_LOGLEVEL:
        type: choice
        description: Loglevel for PyTest
        options:
          - DEBUG
          - INFO
          - WARNING
          - ERROR
          - CRITICAL
        default: WARNING
      disableTestSelection:
        description: 'Disable Test Selection'
        required: false
        type: boolean
        default: false
      randomize-aws-credentials:
        description: 'Randomize AWS credentials'
        default: false
        required: false
        type: boolean
      onlyAcceptanceTests:
        description: 'Run only acceptance tests'
        default: false
        required: false
        type: boolean
      forceARMTests:
        description: 'Run the ARM64 tests'
        default: false
        required: false
        type: boolean
      testAWSRegion:
        description: 'AWS test region'
        required: false
        type: string
        default: 'us-east-1'
      testAWSAccountId:
        description: 'AWS test account ID'
        required: false
        type: string
        default: '000000000000'
      testAWSAccessKeyId:
        description: 'AWS test access key ID'
        required: false
        type: string
        default: 'test'
  workflow_call:
    inputs:
      disableCaching:
        description: 'Disable Caching'
        required: false
        type: boolean
        default: false
      PYTEST_LOGLEVEL:
        type: string
        required: false
        description: Loglevel for PyTest
        default: WARNING
      disableTestSelection:
        description: 'Disable Test Selection'
        required: false
        type: boolean
        default: false
      randomize-aws-credentials:
        description: "Randomize AWS credentials"
        default: false
        required: false
        type: boolean
      onlyAcceptanceTests:
        description: "Run only acceptance tests"
        default: false
        required: false
        type: boolean
      forceARMTests:
        description: 'Run the ARM64 tests'
        default: false
        required: false
        type: boolean
      testAWSRegion:
        description: 'AWS test region'
        required: false
        type: string
        default: 'us-east-1'
      testAWSAccountId:
        description: 'AWS test account ID'
        required: false
        type: string
        default: '000000000000'
      testAWSAccessKeyId:
        description: 'AWS test access key ID'
        required: false
        type: string
        default: 'test'
    secrets:
      DOCKERHUB_PULL_USERNAME:
        description: 'A DockerHub username - Used to avoid rate limiting issues.'
        required: true
      DOCKERHUB_PULL_TOKEN:
        description: 'A DockerHub token - Used to avoid rate limiting issues.'
        required: true
      TINYBIRD_CI_TOKEN:
        description: 'Token for accessing our tinybird ci analytics workspace.'
        required: true

env:
  PYTEST_LOGLEVEL: ${{ inputs.PYTEST_LOGLEVEL || 'WARNING' }}
  IMAGE_NAME: "localstack/localstack"
  TESTSELECTION_PYTEST_ARGS: "${{ !inputs.disableTestSelection && '--path-filter=dist/testselection/test-selection.txt ' || '' }}"
  TEST_AWS_REGION_NAME: ${{ inputs.testAWSRegion }}
  TEST_AWS_ACCOUNT_ID: ${{ inputs.testAWSAccountId }}
  TEST_AWS_ACCESS_KEY_ID: ${{ inputs.testAWSAccessKeyId }}
  # Set non-job-specific environment variables for pytest-tinybird
  TINYBIRD_URL: https://api.tinybird.co
  TINYBIRD_DATASOURCE: raw_tests
  TINYBIRD_TOKEN: ${{ secrets.TINYBIRD_CI_TOKEN }}
  TINYBIRD_TIMEOUT: 5
  CI_REPOSITORY_NAME: localstack/localstack
  # differentiate between "acceptance", "mamr" and "full" runs
  CI_WORKFLOW_NAME: ${{ inputs.onlyAcceptanceTests && 'tests_acceptance'
    || inputs.testAWSAccountId != '000000000000' && 'tests_mamr'
    || 'tests_full' }}
  CI_COMMIT_BRANCH: ${{ github.head_ref || github.ref_name }}
  CI_COMMIT_SHA: ${{ github.sha }}
  CI_JOB_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/${{ github.run_attempt }}
  # report to tinybird if executed on master
  TINYBIRD_PYTEST_ARGS: "${{ github.ref == 'refs/heads/master' && '--report-to-tinybird ' || '' }}"



jobs:
  build:
    name: "Build Docker Image (${{ contains(matrix.runner, 'arm') && 'ARM64' || 'AMD64' }})"
    needs:
      - test-preflight
    strategy:
      matrix:
        runner:
          - ubuntu-latest
          - ubuntu-24.04-arm
        exclude:
          # skip the ARM integration tests in case we are not on the master and not on the upgrade-dependencies branch and forceARMTests is not set to true
          - runner: ${{ (github.ref != 'refs/heads/master' && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false) && 'ubuntu-24.04-arm' || ''}}
      fail-fast: false
    runs-on: ${{ matrix.runner }}
    steps:
      - name: Determine Runner Architecture
        shell: bash
        run: echo "PLATFORM=${{ (runner.arch == 'X64' && 'amd64') || (runner.arch == 'ARM64' && 'arm64') || '' }}" >> $GITHUB_ENV

      - name: Checkout
        uses: actions/checkout@v4
        with:
          path: localstack
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Build Image
        uses: localstack/localstack/.github/actions/build-image@master
        with:
          disableCaching: ${{ inputs.disableCaching == true && 'true' || 'false' }}
          dockerhubPullUsername: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          dockerhubPullToken: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Restore Lambda common runtime packages
        id: cached-lambda-common-restore
        if: inputs.disableCaching != true
        uses: actions/cache/restore@v4
        with:
          path: localstack/tests/aws/services/lambda_/functions/common
          key: common-it-${{ runner.os }}-${{ runner.arch }}-lambda-common-${{ hashFiles('localstack/tests/aws/services/lambda_/functions/common/**/src/*', 'localstack/tests/aws/services/lambda_/functions/common/**/Makefile') }}

      - name: Prebuild lambda common packages
        run: ./localstack/scripts/build_common_test_functions.sh `pwd`/localstack/tests/aws/services/lambda_/functions/common

      - name: Save Lambda common runtime packages
        if: inputs.disableCaching != true
        uses: actions/cache/save@v4
        with:
          path: localstack/tests/aws/services/lambda_/functions/common
          key: ${{ steps.cached-lambda-common-restore.outputs.cache-primary-key }}

      - name: Archive Lambda common packages
        uses: actions/upload-artifact@v4
        with:
          name: lambda-common-${{ env.PLATFORM }}
          path: |
            localstack/tests/aws/services/lambda_/functions/common
          retention-days: 1


  test-preflight:
    name: "Preflight & Unit-Tests"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Linting
        run: make lint

      - name: Check AWS compatibility markers
        run: make check-aws-markers

      - name: Determine Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        run: |
          source .venv/bin/activate
          if [ -z "${{ github.event.pull_request.base.sha }}" ]; then
            echo "Do test selection based on branch name"
          else
            echo "Do test selection based on Pull Request event"
            SCRIPT_OPTS="--base-commit-sha ${{ github.event.pull_request.base.sha }} --head-commit-sha ${{ github.event.pull_request.head.sha }}"
          fi
          source .venv/bin/activate
          python -m localstack.testing.testselection.scripts.generate_test_selection $(pwd) dist/testselection/test-selection.txt $SCRIPT_OPTS || (mkdir -p dist/testselection && echo "SENTINEL_ALL_TESTS" >> dist/testselection/test-selection.txt)
          echo "Test selection:"
          cat dist/testselection/test-selection.txt

      - name: Archive Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/upload-artifact@v4
        with:
          name: test-selection
          path: |
            dist/testselection/test-selection.txt
          retention-days: 1

      - name: Run Unit Tests
        timeout-minutes: 8
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          TEST_PATH: "tests/unit"
          JUNIT_REPORTS_FILE: "pytest-junit-unit.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} -o junit_suite_name=unit-tests"
          COVERAGE_FILE: ".coverage.unit"
          # Set job-specific environment variables for pytest-tinybird
          CI_JOB_NAME: ${{ github.job }}-unit
          CI_JOB_ID: ${{ github.job }}-unit
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-preflight
          include-hidden-files: true
          path: |
            pytest-junit-unit.xml
            .coverage.unit
          retention-days: 30

  publish-preflight-test-results:
    name: Publish Preflight- & Unit-Test Results
    needs: test-preflight
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    # execute on success or failure, but not if the workflow is cancelled or any of the dependencies has been skipped
    if: always() && !cancelled() && !contains(needs.*.result, 'skipped')
    steps:
      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-preflight

      - name: Publish Preflight- & Unit-Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            test-results-preflight/*.xml
          check_name: "Test Results ${{ inputs.testAWSAccountId != '000000000000' && '(MA/MR) ' || ''}}- Preflight, Unit"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true


  test-integration:
    name: "Integration Tests (${{ contains(matrix.runner, 'arm') && 'ARM64' || 'AMD64' }} - ${{ matrix.group }})"
    if: ${{ !inputs.onlyAcceptanceTests }}
    needs:
      - build
      - test-preflight
    strategy:
      matrix:
        group: [ 1, 2, 3, 4 ]
        runner:
          - ubuntu-latest
          - ubuntu-24.04-arm
        exclude:
          # skip the ARM integration tests in case we are not on the master and not on the upgrade-dependencies branch and forceARMTests is not set to true
          - runner: ${{ (github.ref != 'refs/heads/master' && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false) && 'ubuntu-24.04-arm' || ''}}
      fail-fast: false
    runs-on: ${{ matrix.runner }}
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
      CI_JOB_ID: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
    steps:
      - name: Determine Runner Architecture
        shell: bash
        run: echo "PLATFORM=${{ (runner.arch == 'X64' && 'amd64') || (runner.arch == 'ARM64' && 'arm64') || '' }}" >> $GITHUB_ENV

      - name: Login to Docker Hub
        # login to DockerHub to avoid rate limiting issues on custom runners
        if: github.repository_owner == 'localstack'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Set environment
        if: ${{ inputs.testEnvironmentVariables != ''}}
        shell: bash
        run: |
          echo "${{ inputs.testEnvironmentVariables }}" | sed "s/;/\n/" >> $GITHUB_ENV

      - name: Checkout
        uses: actions/checkout@v4
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Download Lambda Common packages
        uses: actions/download-artifact@v4
        with:
          name: lambda-common-${{ env.PLATFORM }}
          path: |
            tests/aws/services/lambda_/functions/common

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v4
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run Integration Tests
        timeout-minutes: 120
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --splits 4 --group ${{ matrix.group }} --store-durations --clean-durations --ignore=tests/unit/ --ignore=tests/bootstrap"
          COVERAGE_FILE: "target/.coverage.integration-${{ env.PLATFORM }}-${{ matrix.group }}"
          JUNIT_REPORTS_FILE: "target/pytest-junit-integration-${{ env.PLATFORM }}-${{ matrix.group }}.xml"
          DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          DOCKERHUB_PASSWORD: ${{ secrets.DOCKERHUB_PULL_TOKEN }}
          # increase Docker SDK timeout to avoid timeouts on BuildJet runners - https://github.com/docker/docker-py/issues/2266
          DOCKER_SDK_DEFAULT_TIMEOUT_SECONDS: 300
        run: make docker-run-tests

      - name: Archive Test Durations
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: pytest-split-durations-${{ env.PLATFORM }}-${{ matrix.group }}
          path: .test_durations
          include-hidden-files: true
          retention-days: 5

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-integration-${{ env.PLATFORM }}-${{ matrix.group }}
          include-hidden-files: true
          path: |
            target/pytest-junit-integration-${{ env.PLATFORM }}-${{ matrix.group }}.xml
            target/.coverage.integration-${{ env.PLATFORM }}-${{ matrix.group }}
          retention-days: 30

  test-bootstrap:
    name: Test Bootstrap
    if: ${{ !inputs.onlyAcceptanceTests }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      PLATFORM: 'amd64'
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Run Bootstrap Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TEST_PATH: "tests/bootstrap"
          COVERAGE_FILE: ".coverage.bootstrap"
          JUNIT_REPORTS_FILE: "pytest-junit-bootstrap.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} -o junit_suite_name=bootstrap-tests"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-bootstrap
          include-hidden-files: true
          path: |
            pytest-junit-bootstrap.xml
            .coverage.bootstrap
          retention-days: 30

  publish-test-results:
    name: Publish Test Results
    strategy:
      matrix:
        arch:
          - amd64
          - arm64
        exclude:
          # skip the ARM integration tests in case we are not on the master and not on the upgrade-dependencies branch and forceARMTests is not set to true
          - arch: ${{ (github.ref != 'refs/heads/master' && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false) && 'arm64' || ''}}
    needs:
      - test-integration
      - test-bootstrap
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    # execute on success or failure, but not if the workflow is cancelled or any of the dependencies has been skipped
    if: always() && !cancelled() && !contains(needs.*.result, 'skipped')
    steps:
      - name: Download Bootstrap Artifacts
        uses: actions/download-artifact@v4
        if: ${{ matrix.arch == 'amd64' }}
        with:
          pattern: test-results-bootstrap

      - name: Download Integration Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-integration-${{ matrix.arch }}-*

      - name: Publish Bootstrap and Integration Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            **/pytest-junit-*.xml
          check_name: "Test Results (${{ matrix.arch }}${{ inputs.testAWSAccountId != '000000000000' && ', MA/MR' || ''}}) - Integration${{ matrix.arch == 'amd64' && ', Bootstrap' || ''}}"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true


  test-acceptance:
    name: "Acceptance Tests (${{ contains(matrix.runner, 'arm') && 'ARM64' || 'AMD64' }})"
    needs:
      - build
    strategy:
      matrix:
        runner:
          - ubuntu-latest
          - ubuntu-24.04-arm
        exclude:
          # skip the ARM integration tests in case we are not on the master and not on the upgrade-dependencies branch and forceARMTests is not set to true
          - runner: ${{ (github.ref != 'refs/heads/master' && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false) && 'ubuntu-24.04-arm' || ''}}
      fail-fast: false
    runs-on: ${{ matrix.runner }}
    env:
      # Acceptance tests are executed for all test cases, without any test selection
      TESTSELECTION_PYTEST_ARGS: ""
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
      CI_JOB_ID: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
    steps:
      - name: Determine Runner Architecture
        shell: bash
        run: echo "PLATFORM=${{ (runner.arch == 'X64' && 'amd64') || (runner.arch == 'ARM64' && 'arm64') || '' }}" >> $GITHUB_ENV

      - name: Login to Docker Hub
        # login to DockerHub to avoid rate limiting issues on custom runners
        if: github.repository_owner == 'localstack'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Set environment
        if: ${{ inputs.testEnvironmentVariables != ''}}
        shell: bash
        run: |
          echo "${{ inputs.testEnvironmentVariables }}" | sed "s/;/\n/" >> $GITHUB_ENV

      - name: Checkout
        uses: actions/checkout@v4
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Run Acceptance Tests
        timeout-minutes: 120
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          LOCALSTACK_INTERNAL_TEST_COLLECT_METRIC: 1
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --reruns 3 -m acceptance_test -o junit_suite_name='acceptance_test'"
          COVERAGE_FILE: "target/.coverage.acceptance-${{ env.PLATFORM }}"
          JUNIT_REPORTS_FILE: "target/pytest-junit-acceptance-${{ env.PLATFORM }}.xml"
          TEST_PATH: "tests/aws/"
          DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          DOCKERHUB_PASSWORD: ${{ secrets.DOCKERHUB_PULL_TOKEN }}
        run: make docker-run-tests

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-acceptance-${{ env.PLATFORM }}
          include-hidden-files: true
          path: |
            target/pytest-junit-acceptance-${{ env.PLATFORM }}.xml
            target/.coverage.acceptance-${{ env.PLATFORM }}
          retention-days: 30

  publish-acceptance-test-results:
    name: Publish Acceptance Test Results
    strategy:
      matrix:
        arch:
          - amd64
          - arm64
        exclude:
          # skip the ARM integration tests in case we are not on the master and not on the upgrade-dependencies branch and forceARMTests is not set to true
          - arch: ${{ (github.ref != 'refs/heads/master' && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false) && 'arm64' || ''}}
    needs:
      - test-acceptance
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    # execute on success or failure, but not if the workflow is cancelled or any of the dependencies has been skipped
    if: always() && !cancelled() && !contains(needs.*.result, 'skipped')
    steps:
      - name: Download Acceptance Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-acceptance-${{ matrix.arch }}

      - name: Publish Acceptance Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            **/pytest-junit-*.xml
          check_name: "Test Results (${{ matrix.arch }}${{ inputs.testAWSAccountId != '000000000000' && ', MA/MR' || ''}}) - Acceptance"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true

  test-cloudwatch-v1:
    name: Test CloudWatch V1
    if: ${{ !inputs.onlyAcceptanceTests }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Run Cloudwatch v1 Provider Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          COVERAGE_FILE: ".coverage.cloudwatch_v1"
          TEST_PATH: "tests/aws/services/cloudwatch/"
          JUNIT_REPORTS_FILE: "pytest-junit-cloudwatch-v1.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} --reruns 3 -o junit_suite_name=cloudwatch_v1"
          PROVIDER_OVERRIDE_CLOUDWATCH: "v1"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-cloudwatch-v1
          include-hidden-files: true
          path: |
            pytest-junit-cloudwatch-v1.xml
            .coverage.cloudwatch_v1
          retention-days: 30

  test-ddb-v2:
    name: Test DynamoDB(Streams) v2
    if: ${{ !inputs.onlyAcceptanceTests }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v4
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run DynamoDB(Streams) v2 Provider Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          COVERAGE_FILE: ".coverage.dynamodb_v2"
          TEST_PATH: "tests/aws/services/dynamodb/ tests/aws/services/dynamodbstreams/ tests/aws/services/lambda_/event_source_mapping/test_lambda_integration_dynamodbstreams.py"
          JUNIT_REPORTS_FILE: "pytest-junit-dynamodb-v2.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} --reruns 3 -o junit_suite_name=dynamodb_v2"
          PROVIDER_OVERRIDE_DYNAMODB: "v2"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-dynamodb-v2
          include-hidden-files: true
          path: |
            pytest-junit-dynamodb-v2.xml
            .coverage.dynamodb_v2
          retention-days: 30

  test-events-v1:
    name: Test EventBridge v1
    if: ${{ !inputs.onlyAcceptanceTests }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v4
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run EventBridge v1 Provider Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          COVERAGE_FILE: ".coverage.events_v1"
          TEST_PATH: "tests/aws/services/events/"
          JUNIT_REPORTS_FILE: "pytest-junit-events-v1.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} --reruns 3 -o junit_suite_name=events_v1"
          PROVIDER_OVERRIDE_EVENTS: "v1"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-events-v1
          path: |
            pytest-junit-events-v1.xml
            .coverage.events_v1
          retention-days: 30

  test-cfn-v2-engine:
    name: Test CloudFormation Engine v2
    if: ${{ !inputs.onlyAcceptanceTests }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      COVERAGE_FILE: ".coverage.cloudformation_v2"
      JUNIT_REPORTS_FILE: "pytest-junit-cloudformation-v2.xml"
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v4
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run CloudFormation Engine v2 Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TEST_PATH: "tests/aws/services/cloudformation/v2"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} --reruns 3 -o junit_suite_name='cloudformation_v2'"
          PROVIDER_OVERRIDE_CLOUDFORMATION: "engine-v2"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v4
        if: success() || failure()
        with:
          name: test-results-cloudformation-v2
          include-hidden-files: true
          path: |
            ${{ env.COVERAGE_FILE }}
            ${{ env.JUNIT_REPORTS_FILE }}
          retention-days: 30

  publish-alternative-provider-test-results:
    name: Publish Alternative Provider Test Results
    needs:
      - test-cfn-v2-engine
      - test-events-v1
      - test-ddb-v2
      - test-cloudwatch-v1
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    # execute on success or failure, but not if the workflow is cancelled or any of the dependencies has been skipped
    if: always() && !cancelled() && !contains(needs.*.result, 'skipped')
    steps:
      - name: Download Cloudformation v2 Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-cloudformation-v2

      - name: Download EventBridge v1 Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-events-v1

      - name: Download DynamoDB v2 Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-dynamodb-v2

      - name: Download CloudWatch v1 Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-cloudwatch-v1

      - name: Publish Bootstrap and Integration Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            **/pytest-junit-*.xml
          check_name: "Test Results ${{ inputs.testAWSAccountId != '000000000000' && '(MA/MR) ' || ''}}- Alternative Providers"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true

  capture-not-implemented:
    name: "Capture Not Implemented"
    if: ${{ !inputs.onlyAcceptanceTests && github.ref == 'refs/heads/master' }}
    runs-on: ubuntu-latest
    needs: build
    env:
      PLATFORM: 'amd64'
    steps:
      - name: Login to Docker Hub
        # login to DockerHub to avoid rate limiting issues on custom runners
        if: github.repository_owner == 'localstack'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Checkout
        uses: actions/checkout@v4
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Install Community Dependencies
        run: make install-dev

      - name: Start LocalStack
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DISABLE_EVENTS: "1"
          DEBUG: 1
          IMAGE_NAME: "localstack/localstack:latest"
        run: |
          source .venv/bin/activate
          localstack start -d
          localstack wait -t 120 || (localstack logs && false)

      - name: Run capture-not-implemented
        run: |
          source .venv/bin/activate
          cd scripts
          mkdir ../results
          python -m capture_notimplemented_responses ../results/

      - name: Print the logs
        run: |
          source .venv/bin/activate
          localstack logs

      - name: Stop localstack
        run: |
          source .venv/bin/activate
          localstack stop

      - name: Archive Capture-Not-Implemented Results
        uses: actions/upload-artifact@v4
        with:
          name: capture-notimplemented
          path: results/
          retention-days: 30
