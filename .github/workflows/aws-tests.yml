name: AWS / Integration Tests

on:
  workflow_dispatch:
    inputs:
      disableCaching:
        description: 'Disable Caching'
        required: false
        type: boolean
        default: false
      PYTEST_LOGLEVEL:
        type: choice
        description: Loglevel for PyTest
        options:
          - DEBUG
          - INFO
          - WARNING
          - ERROR
          - CRITICAL
        default: WARNING
      disableTestSelection:
        description: 'Disable Test Selection'
        required: false
        type: boolean
        default: false
      randomize-aws-credentials:
        description: 'Randomize AWS credentials'
        default: false
        required: false
        type: boolean
      onlyAcceptanceTests:
        description: 'Run only acceptance tests'
        default: false
        required: false
        type: boolean
      forceARMTests:
        description: 'Run the ARM64 tests'
        default: false
        required: false
        type: boolean
      testAWSRegion:
        description: 'AWS test region'
        required: false
        type: string
        default: 'us-east-1'
      testAWSAccountId:
        description: 'AWS test account ID'
        required: false
        type: string
        default: '000000000000'
      testAWSAccessKeyId:
        description: 'AWS test access key ID'
        required: false
        type: string
        default: 'test'
  workflow_call:
    inputs:
      disableCaching:
        description: 'Disable Caching'
        required: false
        type: boolean
        default: false
      PYTEST_LOGLEVEL:
        type: string
        required: false
        description: Loglevel for PyTest
        default: WARNING
      disableTestSelection:
        description: 'Disable Test Selection'
        required: false
        type: boolean
        default: false
      randomize-aws-credentials:
        description: "Randomize AWS credentials"
        default: false
        required: false
        type: boolean
      onlyAcceptanceTests:
        description: "Run only acceptance tests"
        default: false
        required: false
        type: boolean
      forceARMTests:
        description: 'Run the ARM64 tests'
        default: false
        required: false
        type: boolean
      testAWSRegion:
        description: 'AWS test region'
        required: false
        type: string
        default: 'us-east-1'
      testAWSAccountId:
        description: 'AWS test account ID'
        required: false
        type: string
        default: '000000000000'
      testAWSAccessKeyId:
        description: 'AWS test access key ID'
        required: false
        type: string
        default: 'test'
    secrets:
      DOCKERHUB_PULL_USERNAME:
        description: 'A DockerHub username - Used to avoid rate limiting issues.'
        required: true
      DOCKERHUB_PULL_TOKEN:
        description: 'A DockerHub token - Used to avoid rate limiting issues.'
        required: true
      TINYBIRD_CI_TOKEN:
        description: 'Token for accessing our tinybird ci analytics workspace.'
        required: true

env:
  PYTEST_LOGLEVEL: ${{ inputs.PYTEST_LOGLEVEL || 'WARNING' }}
  IMAGE_NAME: "localstack/localstack"
  TESTSELECTION_PYTEST_ARGS: "${{ !inputs.disableTestSelection && '--path-filter=dist/testselection/test-selection.txt ' || '' }}"
  TEST_AWS_REGION_NAME: ${{ inputs.testAWSRegion }}
  TEST_AWS_ACCOUNT_ID: ${{ inputs.testAWSAccountId }}
  TEST_AWS_ACCESS_KEY_ID: ${{ inputs.testAWSAccessKeyId }}
  # Set non-job-specific environment variables for pytest-tinybird
  TINYBIRD_URL: https://api.tinybird.co
  TINYBIRD_DATASOURCE: raw_tests
  TINYBIRD_TOKEN: ${{ secrets.TINYBIRD_CI_TOKEN }}
  TINYBIRD_TIMEOUT: 5
  CI_REPOSITORY_NAME: localstack/localstack
  # differentiate between "acceptance", "mamr" and "full" runs
  CI_WORKFLOW_NAME: ${{ inputs.onlyAcceptanceTests && 'tests_acceptance'
    || inputs.testAWSAccountId != '000000000000' && 'tests_mamr'
    || 'tests_full' }}
  CI_COMMIT_BRANCH: ${{ github.head_ref || github.ref_name }}
  CI_COMMIT_SHA: ${{ github.sha }}
  CI_JOB_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/${{ github.run_attempt }}
  # report to tinybird if executed on main
  TINYBIRD_PYTEST_ARGS: "${{ github.repository == 'localstack/localstack' && ( github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v') ) && '--report-to-tinybird ' || '' }}"
  DOCKER_PULL_SECRET_AVAILABLE: ${{ secrets.DOCKERHUB_PULL_USERNAME != '' && secrets.DOCKERHUB_PULL_TOKEN != '' && 'true' || 'false' }}

# Only one pull-request triggered run should be executed at a time
# (head_ref is only set for PR events, otherwise fallback to run_id which differs for every run).
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  build:
    name: "Build Docker Image (${{ contains(matrix.runner, 'arm') && 'ARM64' || 'AMD64' }})"
    needs:
      - test-preflight
    strategy:
      matrix:
        runner:
          - ubuntu-latest
          - ubuntu-24.04-arm
        exclude:
          # skip the ARM integration tests in forks, and also if not on main/upgrade-dependencies and forceARMTests is not set to true
          # TODO ARM runners are not yet available for private repositories; skip them for potential private forks
          - runner: ${{ ((github.repository != 'localstack/localstack') || (github.ref != 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/v') && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false)) && 'ubuntu-24.04-arm' || ''}}
      fail-fast: false
    runs-on: ${{ matrix.runner }}
    steps:
      - name: Determine Runner Architecture
        shell: bash
        run: echo "PLATFORM=${{ (runner.arch == 'X64' && 'amd64') || (runner.arch == 'ARM64' && 'arm64') || '' }}" >> $GITHUB_ENV

      - name: Checkout
        uses: actions/checkout@v6
        with:
          path: localstack
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Build Image
        uses: localstack/localstack/.github/actions/build-image@main
        with:
          disableCaching: ${{ inputs.disableCaching == true && 'true' || 'false' }}
          dockerhubPullUsername: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          dockerhubPullToken: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Restore Lambda common runtime packages
        id: cached-lambda-common-restore
        if: inputs.disableCaching != true
        uses: actions/cache/restore@v5
        with:
          path: localstack/tests/aws/services/lambda_/functions/common
          key: common-it-${{ runner.os }}-${{ runner.arch }}-lambda-common-${{ hashFiles('localstack/tests/aws/services/lambda_/functions/common/**/src/*', 'localstack/tests/aws/services/lambda_/functions/common/**/Makefile') }}

      - name: Prebuild lambda common packages
        run: ./localstack/scripts/build_common_test_functions.sh `pwd`/localstack/tests/aws/services/lambda_/functions/common

      - name: Save Lambda common runtime packages
        if: inputs.disableCaching != true
        uses: actions/cache/save@v5
        with:
          path: localstack/tests/aws/services/lambda_/functions/common
          key: ${{ steps.cached-lambda-common-restore.outputs.cache-primary-key }}

      - name: Archive Lambda common packages
        uses: actions/upload-artifact@v6
        with:
          name: lambda-common-${{ env.PLATFORM }}
          path: |
            localstack/tests/aws/services/lambda_/functions/common
          retention-days: 1


  test-preflight:
    name: "Preflight & Unit-Tests"
    runs-on: ubuntu-latest
    outputs:
      cloudwatch-v1: ${{ steps.changes.outputs.cloudwatch-v1 }}
      dynamodb-v2: ${{ steps.changes.outputs.dynamodb-v2 }}
      events-v1: ${{ steps.changes.outputs.events-v1 }}
      cloudformation-legacy: ${{ steps.changes.outputs.cloudformation-legacy }}
      sns-v2: ${{ steps.changes.outputs.sns-v2 }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Linting
        run: make lint

      - name: Check AWS compatibility markers
        run: make check-aws-markers

      - name: Determine Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        run: |
          source .venv/bin/activate
          if [ -z "${{ github.event.pull_request.base.sha }}" ]; then
            echo "Do test selection based on branch name"
          else
            echo "Do test selection based on Pull Request event"
            SCRIPT_OPTS="--base-commit-sha ${{ github.event.pull_request.base.sha }} --head-commit-sha ${{ github.event.pull_request.head.sha }}"
          fi
          source .venv/bin/activate
          python -m localstack.testing.testselection.scripts.generate_test_selection $(pwd) dist/testselection/test-selection.txt $SCRIPT_OPTS || (mkdir -p dist/testselection && echo "SENTINEL_ALL_TESTS" >> dist/testselection/test-selection.txt)
          echo "Test selection:"
          cat dist/testselection/test-selection.txt

      - name: Archive Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/upload-artifact@v6
        with:
          name: test-selection
          path: |
            dist/testselection/test-selection.txt
          retention-days: 1

      # This step determines which services were affected by changes of the modified files
      # The output from this step is later used in combination with the test-selection file
      #
      # The test-selection file specifies which tests to run for each service,
      # while this step allows skipping entire jobs when no relevant services have changed
      - name: Determine services affected by change
        uses: dorny/paths-filter@v3.0.2
        id: changes
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          filters: |
            cloudwatch-v1:
               - 'localstack-core/localstack/services/cloudwatch/**'
               - 'tests/aws/services/cloudwatch/**'
            dynamodb-v2:
               - 'localstack-core/localstack/services/dynamodb/**'
               - 'tests/aws/services/dynamodb/**'
               - 'tests/aws/services/dynamodbstreams/**'
               - 'tests/aws/services/lambda_/event_source_mapping/test_lambda_integration_dynamodbstreams.py'
            events-v1:
               - 'localstack-core/localstack/services/events/**'
               - 'tests/aws/services/events/**'
            cloudformation-legacy:
               - 'localstack-core/localstack/services/cloudformation/**'
               - 'tests/aws/services/cloudformation/**'
            sns-v2:
               - 'tests/aws/services/sns/**' # todo: potentially add more locations (lambda/sqs tests?)

      - name: Run Unit Tests
        timeout-minutes: 20
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          TEST_PATH: "tests/unit"
          JUNIT_REPORTS_FILE: "pytest-junit-unit.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} -o junit_suite_name=unit-tests"
          COVERAGE_FILE: ".coverage.unit"
          # Set job-specific environment variables for pytest-tinybird
          CI_JOB_NAME: ${{ github.job }}-unit
          CI_JOB_ID: ${{ github.job }}-unit
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-preflight
          include-hidden-files: true
          path: |
            pytest-junit-unit.xml
            .coverage.unit
          retention-days: 30

  publish-preflight-test-results:
    name: Publish Preflight- & Unit-Test Results
    needs: test-preflight
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    # execute on success or failure, but not if the workflow is cancelled or any of the dependencies has been skipped
    if: always() && !cancelled() && !contains(needs.*.result, 'skipped')
    steps:
      - name: Download Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-preflight

      - name: Publish Preflight- & Unit-Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            **/pytest-junit-*.xml
          check_name: "Test Results ${{ inputs.testAWSAccountId != '000000000000' && '(MA/MR) ' || ''}}- Preflight, Unit"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true


  test-integration:
    name: "Integration Tests (${{ contains(matrix.runner, 'arm') && 'ARM64' || 'AMD64' }} - ${{ matrix.group }})"
    if: ${{ !inputs.onlyAcceptanceTests }}
    needs:
      - build
      - test-preflight
    strategy:
      matrix:
        group: [ 1, 2, 3, 4 ]
        runner:
          - ubuntu-latest
          - ubuntu-24.04-arm
        exclude:
          # skip the ARM integration tests in forks, and also if not on main/upgrade-dependencies and forceARMTests is not set to true
          # TODO ARM runners are not yet available for private repositories; skip them for potential private forks
          - runner: ${{ ((github.repository != 'localstack/localstack') || (github.ref != 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/v') && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false)) && 'ubuntu-24.04-arm' || ''}}
      fail-fast: false
    runs-on: ${{ matrix.runner }}
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
      CI_JOB_ID: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
    steps:
      - name: Determine Runner Architecture
        shell: bash
        run: echo "PLATFORM=${{ (runner.arch == 'X64' && 'amd64') || (runner.arch == 'ARM64' && 'arm64') || '' }}" >> $GITHUB_ENV

      - name: Login to Docker Hub
        # login to DockerHub to avoid rate limiting issues on custom runners
        if: github.repository_owner == 'localstack' && env.DOCKER_PULL_SECRET_AVAILABLE == 'true'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Set environment
        if: ${{ inputs.testEnvironmentVariables != ''}}
        shell: bash
        run: |
          echo "${{ inputs.testEnvironmentVariables }}" | sed "s/;/\n/" >> $GITHUB_ENV

      - name: Checkout
        uses: actions/checkout@v6
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Download Lambda Common packages
        uses: actions/download-artifact@v7
        with:
          name: lambda-common-${{ env.PLATFORM }}
          path: |
            tests/aws/services/lambda_/functions/common

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v7
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run Integration Tests
        timeout-minutes: 120
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --splits 4 --group ${{ matrix.group }} --store-durations --clean-durations --ignore=tests/unit/ --ignore=tests/bootstrap"
          COVERAGE_FILE: "target/.coverage.integration-${{ env.PLATFORM }}-${{ matrix.group }}"
          JUNIT_REPORTS_FILE: "target/pytest-junit-integration-${{ env.PLATFORM }}-${{ matrix.group }}.xml"
          DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          DOCKERHUB_PASSWORD: ${{ secrets.DOCKERHUB_PULL_TOKEN }}
          # increase Docker SDK timeout to avoid timeouts on BuildJet runners - https://github.com/docker/docker-py/issues/2266
          DOCKER_SDK_DEFAULT_TIMEOUT_SECONDS: 300
        run: make docker-run-tests

      # Test durations are fetched and merged automatically by a separate workflow.
      # Files must have unique names to prevent overwrites when multiple artifacts are downloaded
      - name: Rename test durations file
        run: |
          mv .test_durations .test_durations-${{ env.PLATFORM }}-${{ matrix.group }}

      - name: Archive Test Durations
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: pytest-split-durations-${{ env.PLATFORM }}-${{ matrix.group }}
          path: .test_durations-${{ env.PLATFORM }}-${{ matrix.group }}
          include-hidden-files: true
          retention-days: 5

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-integration-${{ env.PLATFORM }}-${{ matrix.group }}
          include-hidden-files: true
          path: |
            target/pytest-junit-integration-${{ env.PLATFORM }}-${{ matrix.group }}.xml
            target/.coverage.integration-${{ env.PLATFORM }}-${{ matrix.group }}
          retention-days: 30

      - name: Archive Parity Metric Results
        if: success()
        uses: actions/upload-artifact@v6
        with:
          name: parity-metric-raw-${{ env.PLATFORM }}-${{ matrix.group }}
          path: target/metric_reports
          retention-days: 30

  test-bootstrap:
    name: Test Bootstrap
    if: ${{ !inputs.onlyAcceptanceTests }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      PLATFORM: 'amd64'
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Run Bootstrap Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TEST_PATH: "tests/bootstrap"
          COVERAGE_FILE: ".coverage.bootstrap"
          JUNIT_REPORTS_FILE: "pytest-junit-bootstrap.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }} -o junit_suite_name=bootstrap-tests"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-bootstrap
          include-hidden-files: true
          path: |
            pytest-junit-bootstrap.xml
            .coverage.bootstrap
          retention-days: 30

  publish-test-results:
    name: Publish Test Results
    strategy:
      matrix:
        arch:
          - amd64
          - arm64
        exclude:
          # skip the ARM integration tests in forks, and also if not on main/upgrade-dependencies and forceARMTests is not set to true
          # TODO ARM runners are not yet available for private repositories; skip them for potential private forks
          - arch: ${{ ((github.repository != 'localstack/localstack') || (github.ref != 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/v') && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false)) && 'arm64' || ''}}
    needs:
      - test-integration
      - test-bootstrap
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    # execute on success or failure, but not if the workflow is cancelled or any of the dependencies has been skipped
    if: always() && !cancelled() && !contains(needs.*.result, 'skipped')
    steps:
      - name: Download Bootstrap Artifacts
        uses: actions/download-artifact@v7
        if: ${{ matrix.arch == 'amd64' }}
        with:
          pattern: test-results-bootstrap

      - name: Download Integration Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-integration-${{ matrix.arch }}-*

      - name: Publish Bootstrap and Integration Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            **/pytest-junit-*.xml
          check_name: "Test Results (${{ matrix.arch }}${{ inputs.testAWSAccountId != '000000000000' && ', MA/MR' || ''}}) - Integration${{ matrix.arch == 'amd64' && ', Bootstrap' || ''}}"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true

  test-acceptance:
    name: "Acceptance Tests (${{ contains(matrix.runner, 'arm') && 'ARM64' || 'AMD64' }})"
    needs:
      - build
    strategy:
      matrix:
        runner:
          - ubuntu-latest
          - ubuntu-24.04-arm
        exclude:
          # skip the ARM integration tests in forks, and also if not on main/upgrade-dependencies and forceARMTests is not set to true
          # TODO ARM runners are not yet available for private repositories; skip them for potential private forks
          - runner: ${{ ((github.repository != 'localstack/localstack') || (github.ref != 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/v') && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false)) && 'ubuntu-24.04-arm' || ''}}
      fail-fast: false
    runs-on: ${{ matrix.runner }}
    env:
      # Acceptance tests are executed for all test cases, without any test selection
      TESTSELECTION_PYTEST_ARGS: ""
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
      CI_JOB_ID: ${{ github.job }}-${{ contains(matrix.runner, 'arm') && 'arm' || 'amd' }}
    steps:
      - name: Determine Runner Architecture
        shell: bash
        run: echo "PLATFORM=${{ (runner.arch == 'X64' && 'amd64') || (runner.arch == 'ARM64' && 'arm64') || '' }}" >> $GITHUB_ENV

      - name: Login to Docker Hub
        # login to DockerHub to avoid rate limiting issues on custom runners
        if: github.repository_owner == 'localstack' && env.DOCKER_PULL_SECRET_AVAILABLE == 'true'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Set environment
        if: ${{ inputs.testEnvironmentVariables != ''}}
        shell: bash
        run: |
          echo "${{ inputs.testEnvironmentVariables }}" | sed "s/;/\n/" >> $GITHUB_ENV

      - name: Checkout
        uses: actions/checkout@v6
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Run Acceptance Tests
        timeout-minutes: 120
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          LOCALSTACK_INTERNAL_TEST_COLLECT_METRIC: 1
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --reruns 3 -m acceptance_test -o junit_suite_name='acceptance_test'"
          COVERAGE_FILE: "target/.coverage.acceptance-${{ env.PLATFORM }}"
          JUNIT_REPORTS_FILE: "target/pytest-junit-acceptance-${{ env.PLATFORM }}.xml"
          TEST_PATH: "tests/aws/"
          DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          DOCKERHUB_PASSWORD: ${{ secrets.DOCKERHUB_PULL_TOKEN }}
        run: make docker-run-tests

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-acceptance-${{ env.PLATFORM }}
          include-hidden-files: true
          path: |
            target/pytest-junit-acceptance-${{ env.PLATFORM }}.xml
            target/.coverage.acceptance-${{ env.PLATFORM }}
          retention-days: 30

  publish-acceptance-test-results:
    name: Publish Acceptance Test Results
    strategy:
      matrix:
        arch:
          - amd64
          - arm64
        exclude:
          # skip the ARM integration tests in forks, and also if not on main/upgrade-dependencies and forceARMTests is not set to true
          # TODO ARM runners are not yet available for private repositories; skip them for potential private forks
          - arch: ${{ ((github.repository != 'localstack/localstack') || (github.ref != 'refs/heads/main' && !startsWith(github.ref, 'refs/tags/v') && github.ref != 'upgrade-dependencies' && inputs.forceARMTests == false)) && 'arm64' || ''}}
    needs:
      - test-acceptance
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    # execute on success or failure, but not if the workflow is cancelled or any of the dependencies has been skipped
    if: always() && !cancelled() && !contains(needs.*.result, 'skipped')
    steps:
      - name: Download Acceptance Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-acceptance-${{ matrix.arch }}

      - name: Publish Acceptance Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            **/pytest-junit-*.xml
          check_name: "Test Results (${{ matrix.arch }}${{ inputs.testAWSAccountId != '000000000000' && ', MA/MR' || ''}}) - Acceptance"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true

  test-cloudwatch-v1:
    name: Test CloudWatch V1
    if: ${{ !inputs.onlyAcceptanceTests && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v') || inputs.disableTestSelection || needs.test-preflight.outputs.cloudwatch-v1 == 'true') }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    outputs:
      # we need this output to conditionally execute the Publishing step
      job_status: "executed"
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v7
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run Cloudwatch v1 Provider Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          COVERAGE_FILE: ".coverage.cloudwatch_v1"
          TEST_PATH: "tests/aws/services/cloudwatch/"
          JUNIT_REPORTS_FILE: "pytest-junit-cloudwatch-v1.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --reruns 3 -o junit_suite_name=cloudwatch_v1"
          PROVIDER_OVERRIDE_CLOUDWATCH: "v1"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-cloudwatch-v1
          include-hidden-files: true
          path: |
            pytest-junit-cloudwatch-v1.xml
            .coverage.cloudwatch_v1
          retention-days: 30

  test-ddb-v2:
    name: Test DynamoDB(Streams) v2
    if: ${{ !inputs.onlyAcceptanceTests && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v') || inputs.disableTestSelection || needs.test-preflight.outputs.dynamodb-v2 == 'true') }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    outputs:
      # we need this output to conditionally execute the Publishing step
      job_status: "executed"
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v7
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run DynamoDB(Streams) v2 Provider Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          COVERAGE_FILE: ".coverage.dynamodb_v2"
          TEST_PATH: "tests/aws/services/dynamodb/ tests/aws/services/dynamodbstreams/ tests/aws/services/lambda_/event_source_mapping/test_lambda_integration_dynamodbstreams.py"
          JUNIT_REPORTS_FILE: "pytest-junit-dynamodb-v2.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --reruns 3 -o junit_suite_name=dynamodb_v2"
          PROVIDER_OVERRIDE_DYNAMODB: "v2"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-dynamodb-v2
          include-hidden-files: true
          path: |
            pytest-junit-dynamodb-v2.xml
            .coverage.dynamodb_v2
          retention-days: 30

  test-events-v1:
    name: Test EventBridge v1
    if: ${{ !inputs.onlyAcceptanceTests && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v') || inputs.disableTestSelection || needs.test-preflight.outputs.events-v1 == 'true') }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    outputs:
      # we need this output to conditionally execute the Publishing step
      job_status: "executed"
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v7
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run EventBridge v1 Provider Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          COVERAGE_FILE: ".coverage.events_v1"
          TEST_PATH: "tests/aws/services/events/"
          JUNIT_REPORTS_FILE: "pytest-junit-events-v1.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --reruns 3 -o junit_suite_name=events_v1"
          PROVIDER_OVERRIDE_EVENTS: "v1"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-events-v1
          path: |
            pytest-junit-events-v1.xml
            .coverage.events_v1
          retention-days: 30

  test-cfn-legacy-engine:
    name: Test CloudFormation Engine legacy
    if: ${{ !inputs.onlyAcceptanceTests && ( github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v') || inputs.disableTestSelection || needs.test-preflight.outputs.cloudformation-legacy == 'true' )}}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      COVERAGE_FILE: ".coverage.cloudformation_legacy"
      JUNIT_REPORTS_FILE: "pytest-junit-cloudformation-legacy.xml"
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    outputs:
      # we need this output to conditionally execute the Publishing step
      job_status: "executed"
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v7
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run CloudFormation Engine legacy Tests
        timeout-minutes: 60
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TEST_PATH: "tests/aws/services/cloudformation"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --reruns 3 -o junit_suite_name='cloudformation_legacy'"
          PROVIDER_OVERRIDE_CLOUDFORMATION: "engine-legacy"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-cloudformation-legacy
          include-hidden-files: true
          path: |
            ${{ env.COVERAGE_FILE }}
            ${{ env.JUNIT_REPORTS_FILE }}
          retention-days: 30

  test-sns-v2:
    name: Test SNS V2
    if: ${{ !inputs.onlyAcceptanceTests && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v') || needs.test-preflight.outputs.sns-v2 == 'true') }}
    runs-on: ubuntu-latest
    needs:
      - test-preflight
      - build
    timeout-minutes: 60
    env:
      # Set job-specific environment variables for pytest-tinybird
      CI_JOB_NAME: ${{ github.job }}
      CI_JOB_ID: ${{ github.job }}
    outputs:
      # we need this output to conditionally execute the Publishing step
      job_status: "executed"
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Prepare Local Test Environment
        uses: ./.github/actions/setup-tests-env

      - name: Download Test Selection
        if: ${{ env.TESTSELECTION_PYTEST_ARGS }}
        uses: actions/download-artifact@v7
        with:
          name: test-selection
          path: dist/testselection/

      - name: Run SNS v2 Provider Tests
        timeout-minutes: 30
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DEBUG: 1
          COVERAGE_FILE: ".coverage.sns_v2"
          TEST_PATH: "tests/aws/services/sns/"
          JUNIT_REPORTS_FILE: "pytest-junit-sns-v2.xml"
          PYTEST_ARGS: "${{ env.TINYBIRD_PYTEST_ARGS }}${{ env.TESTSELECTION_PYTEST_ARGS }} --reruns 3 -o junit_suite_name=sns_v2"
          PROVIDER_OVERRIDE_SNS: "v2"
        run: make test-coverage

      - name: Archive Test Results
        uses: actions/upload-artifact@v6
        if: success() || failure()
        with:
          name: test-results-sns-v2
          include-hidden-files: true
          path: |
            pytest-junit-sns-v2.xml
            .coverage.sns_v2
          retention-days: 30

  publish-alternative-provider-test-results:
    name: Publish Alternative Provider Test Results
    # execute on success or failure, but not if the workflow is cancelled or all of the dependencies has been skipped
    if: ${{ !cancelled() && (contains(needs.*.outputs.job_status, 'executed')) }}
    needs:
      - test-cfn-legacy-engine
      - test-events-v1
      - test-ddb-v2
      - test-cloudwatch-v1
      - test-sns-v2
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    steps:
      - name: Download Cloudformation legacy Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-cloudformation-legacy

      - name: Download EventBridge v1 Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-events-v1

      - name: Download DynamoDB v2 Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-dynamodb-v2

      - name: Download CloudWatch v1 Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-cloudwatch-v1

      - name: Download SNS v2 Artifacts
        uses: actions/download-artifact@v7
        with:
          pattern: test-results-sns-v2

      - name: Publish Bootstrap and Integration Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: success() || failure()
        with:
          files: |
            **/pytest-junit-*.xml
          check_name: "Test Results ${{ inputs.testAWSAccountId != '000000000000' && '(MA/MR) ' || ''}}- Alternative Providers"
          test_file_prefix: "-/opt/code/localstack/"
          action_fail_on_inconclusive: true

  capture-not-implemented:
    name: "Capture Not Implemented"
    if: ${{ (!inputs.onlyAcceptanceTests && github.ref == 'refs/heads/main') || startsWith(github.ref, 'refs/tags/v') }}
    runs-on: ubuntu-latest
    needs: build
    env:
      PLATFORM: 'amd64'
    steps:
      - name: Login to Docker Hub
        # login to DockerHub to avoid rate limiting issues on custom runners
        if: github.repository_owner == 'localstack' && env.DOCKER_PULL_SECRET_AVAILABLE == 'true'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_PULL_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PULL_TOKEN }}

      - name: Checkout
        uses: actions/checkout@v6
        with:
          # setuptools_scm requires the git history (at least until the last tag) to determine the version
          fetch-depth: 0

      - name: Load Localstack Docker Image
        uses: ./.github/actions/load-localstack-docker-from-artifacts
        with:
          platform: "${{ env.PLATFORM }}"

      - name: Install Community Dependencies
        run: make install-dev

      - name: Start LocalStack
        env:
          # add the GitHub API token to avoid rate limit issues
          GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DISABLE_EVENTS: "1"
          DEBUG: 1
          IMAGE_NAME: "localstack/localstack:latest"
        run: |
          source .venv/bin/activate
          localstack start -d
          localstack wait -t 120 || (localstack logs && false)

      - name: Run capture-not-implemented
        run: |
          source .venv/bin/activate
          cd scripts
          mkdir ../results
          python -m capture_notimplemented_responses ../results/

      - name: Print the logs
        run: |
          source .venv/bin/activate
          localstack logs

      - name: Stop localstack
        run: |
          source .venv/bin/activate
          localstack stop

      - name: Archive Capture-Not-Implemented Results
        uses: actions/upload-artifact@v6
        with:
          name: capture-notimplemented
          path: results/
          retention-days: 30
