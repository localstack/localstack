import contextlib
import json
import logging
import queue
import random
import time
from io import BytesIO
from operator import itemgetter

import pytest
import requests
import xmltodict
from botocore.auth import SigV4Auth
from botocore.exceptions import ClientError
from pytest_httpserver import HTTPServer
from werkzeug import Response

from localstack import config
from localstack.aws.api.lambda_ import Runtime
from localstack.constants import (
    AWS_REGION_US_EAST_1,
    SECONDARY_TEST_AWS_ACCOUNT_ID,
    SECONDARY_TEST_AWS_REGION_NAME,
    TEST_AWS_ACCESS_KEY_ID,
    TEST_AWS_ACCOUNT_ID,
    TEST_AWS_REGION_NAME,
    TEST_AWS_SECRET_ACCESS_KEY,
)
from localstack.services.sns.constants import (
    PLATFORM_ENDPOINT_MSGS_ENDPOINT,
    SMS_MSGS_ENDPOINT,
    SUBSCRIPTION_TOKENS_ENDPOINT,
)
from localstack.services.sns.provider import SnsProvider
from localstack.testing.aws.util import is_aws_cloud
from localstack.testing.pytest import markers
from localstack.utils import testutil
from localstack.utils.aws.arns import parse_arn, sqs_queue_arn
from localstack.utils.net import wait_for_port_closed, wait_for_port_open
from localstack.utils.strings import short_uid, to_str
from localstack.utils.sync import poll_condition, retry
from localstack.utils.testutil import check_expected_lambda_log_events_length
from tests.aws.services.lambda_.functions import lambda_integration
from tests.aws.services.lambda_.test_lambda import TEST_LAMBDA_PYTHON, TEST_LAMBDA_PYTHON_ECHO

LOG = logging.getLogger(__name__)

PUBLICATION_TIMEOUT = 0.500
PUBLICATION_RETRIES = 4


@pytest.fixture(autouse=True)
def sns_snapshot_transformer(snapshot):
    snapshot.add_transformer(snapshot.transform.sns_api())


@pytest.fixture
def sns_create_platform_application(aws_client):
    platform_applications = []

    def factory(**kwargs):
        if "Name" not in kwargs:
            kwargs["Name"] = f"platform-app-{short_uid()}"
        response = aws_client.sns.create_platform_application(**kwargs)
        platform_applications.append(response["PlatformApplicationArn"])
        return response

    yield factory

    for platform_application in platform_applications:
        endpoints = aws_client.sns.list_endpoints_by_platform_application(
            PlatformApplicationArn=platform_application
        )
        for endpoint in endpoints["Endpoints"]:
            try:
                aws_client.sns.delete_endpoint(EndpointArn=endpoint["EndpointArn"])
            except Exception as e:
                LOG.debug(
                    "Error cleaning up platform endpoint '%s' for platform app '%s': %s",
                    endpoint["EndpointArn"],
                    platform_application,
                    e,
                )
        try:
            aws_client.sns.delete_platform_application(PlatformApplicationArn=platform_application)
        except Exception as e:
            LOG.debug("Error cleaning up platform application '%s': %s", platform_application, e)


class TestSNSTopicCrud:
    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.get-topic-attrs.Attributes.DeliveryPolicy",
            "$.get-topic-attrs.Attributes.EffectiveDeliveryPolicy",
            "$.get-topic-attrs.Attributes.Policy.Statement..Action",  # SNS:Receive is added by moto but not returned in AWS
        ]
    )
    def test_create_topic_with_attributes(self, sns_create_topic, snapshot, aws_client):
        create_topic = sns_create_topic(
            Name="topictest.fifo",
            Attributes={
                "DisplayName": "TestTopic",
                "SignatureVersion": "2",
                "FifoTopic": "true",
            },
        )
        topic_arn = create_topic["TopicArn"]

        get_attrs_resp = aws_client.sns.get_topic_attributes(
            TopicArn=topic_arn,
        )
        snapshot.match("get-topic-attrs", get_attrs_resp)

        with pytest.raises(ClientError) as e:
            wrong_topic_arn = f"{topic_arn[:-8]}{short_uid()}"
            aws_client.sns.get_topic_attributes(TopicArn=wrong_topic_arn)

        snapshot.match("get-attrs-nonexistent-topic", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.get_topic_attributes(TopicArn="test-topic")

        snapshot.match("get-attrs-malformed-topic", e.value.response)

    @markers.aws.validated
    def test_tags(self, sns_create_topic, snapshot, aws_client):
        topic_arn = sns_create_topic()["TopicArn"]
        with pytest.raises(ClientError) as exc:
            aws_client.sns.tag_resource(
                ResourceArn=topic_arn,
                Tags=[
                    {"Key": "k1", "Value": "v1"},
                    {"Key": "k2", "Value": "v2"},
                    {"Key": "k2", "Value": "v2"},
                ],
            )
        snapshot.match("duplicate-key-error", exc.value.response)

        aws_client.sns.tag_resource(
            ResourceArn=topic_arn,
            Tags=[
                {"Key": "k1", "Value": "v1"},
                {"Key": "k2", "Value": "v2"},
            ],
        )

        tags = aws_client.sns.list_tags_for_resource(ResourceArn=topic_arn)
        # could not figure out the logic for tag order in AWS, so resorting to sorting it manually in place
        tags["Tags"].sort(key=itemgetter("Key"))
        snapshot.match("list-created-tags", tags)

        aws_client.sns.untag_resource(ResourceArn=topic_arn, TagKeys=["k1"])
        tags = aws_client.sns.list_tags_for_resource(ResourceArn=topic_arn)
        snapshot.match("list-after-delete-tags", tags)

        # test update tag
        aws_client.sns.tag_resource(ResourceArn=topic_arn, Tags=[{"Key": "k2", "Value": "v2b"}])
        tags = aws_client.sns.list_tags_for_resource(ResourceArn=topic_arn)
        snapshot.match("list-after-update-tags", tags)

    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.get-topic-attrs.Attributes.DeliveryPolicy",
            "$.get-topic-attrs.Attributes.EffectiveDeliveryPolicy",
            "$.get-topic-attrs.Attributes.Policy.Statement..Action",
            # SNS:Receive is added by moto but not returned in AWS
        ]
    )
    def test_create_topic_test_arn(self, sns_create_topic, snapshot, aws_client):
        topic_name = "topic-test-create"
        response = sns_create_topic(Name=topic_name)
        snapshot.match("create-topic", response)
        topic_arn = response["TopicArn"]
        topic_arn_params = topic_arn.split(":")
        testutil.response_arn_matches_partition(aws_client.sns, topic_arn)
        # we match the response but need to be sure the resource name is the same
        assert topic_arn_params[5] == topic_name

        if not is_aws_cloud():
            assert topic_arn_params[4] == TEST_AWS_ACCOUNT_ID

        topic_attrs = aws_client.sns.get_topic_attributes(TopicArn=topic_arn)
        snapshot.match("get-topic-attrs", topic_attrs)

        response = aws_client.sns.delete_topic(TopicArn=topic_arn)
        snapshot.match("delete-topic", response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.get_topic_attributes(TopicArn=topic_arn)
        snapshot.match("topic-not-exists", e.value.response)

    @markers.aws.validated
    def test_create_duplicate_topic_with_more_tags(self, sns_create_topic, snapshot, aws_client):
        topic_name = "test-duplicated-topic-more-tags"
        sns_create_topic(Name=topic_name)

        with pytest.raises(ClientError) as e:
            aws_client.sns.create_topic(Name=topic_name, Tags=[{"Key": "key1", "Value": "value1"}])

        snapshot.match("exception-duplicate", e.value.response)

    @markers.aws.validated
    def test_create_duplicate_topic_check_idempotency(self, sns_create_topic, snapshot):
        topic_name = f"test-{short_uid()}"
        tags = [{"Key": "a", "Value": "1"}, {"Key": "b", "Value": "2"}]
        kwargs = [
            {"Tags": tags},  # to create the same topic again with same tags
            {"Tags": [tags[0]]},  # to create the same topic again with one of the tags from above
            {"Tags": []},  # to create the same topic again with no tags
        ]

        # create topic with two tags
        response = sns_create_topic(Name=topic_name, Tags=tags)
        snapshot.match("response-created", response)

        for index, arg in enumerate(kwargs):
            response = sns_create_topic(Name=topic_name, **arg)
            # we check in the snapshot that they all have the same <resource:1> tag (original topic)
            snapshot.match(f"response-same-arn-{index}", response)

    @markers.aws.validated
    def test_create_topic_after_delete_with_new_tags(self, sns_create_topic, snapshot, aws_client):
        topic_name = f"test-{short_uid()}"
        topic = sns_create_topic(Name=topic_name, Tags=[{"Key": "Name", "Value": "pqr"}])
        snapshot.match("topic-0", topic)
        aws_client.sns.delete_topic(TopicArn=topic["TopicArn"])

        topic1 = sns_create_topic(Name=topic_name, Tags=[{"Key": "Name", "Value": "abc"}])
        snapshot.match("topic-1", topic1)

    @markers.aws.validated
    def test_unsubscribe_wrong_arn_format(self, snapshot, aws_client):
        with pytest.raises(ClientError) as e:
            aws_client.sns.unsubscribe(SubscriptionArn="randomstring")

        snapshot.match("invalid-unsubscribe-arn-1", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.unsubscribe(SubscriptionArn="arn:aws:sns:us-east-1:random")

        snapshot.match("invalid-unsubscribe-arn-2", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.unsubscribe(SubscriptionArn="arn:aws:sns:us-east-1:111111111111:random")

        snapshot.match("invalid-unsubscribe-arn-3", e.value.response)


class TestSNSPublishCrud:
    """
    This class contains tests related to the global `Publish` validation, not tied to a particular kind of subscription
    """

    @markers.aws.validated
    def test_publish_by_path_parameters(
        self,
        sns_create_topic,
        sqs_create_queue,
        sns_create_sqs_subscription,
        aws_http_client_factory,
        snapshot,
        aws_client,
    ):
        message = "test message direct post request"
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        client = aws_http_client_factory(
            "sns",
            signer_factory=SigV4Auth,
            region=TEST_AWS_REGION_NAME,
            aws_access_key_id=TEST_AWS_ACCESS_KEY_ID,
            aws_secret_access_key=TEST_AWS_SECRET_ACCESS_KEY,
        )

        if is_aws_cloud():
            endpoint_url = f"https://sns.{TEST_AWS_REGION_NAME}.amazonaws.com"
        else:
            endpoint_url = config.get_edge_url()

        response = client.post(
            endpoint_url,
            params={
                "Action": "Publish",
                "Version": "2010-03-31",
                "TopicArn": topic_arn,
                "Message": message,
            },
        )

        json_response = xmltodict.parse(response.content)
        json_response["PublishResponse"].pop("@xmlns")
        json_response["PublishResponse"]["ResponseMetadata"][
            "HTTPStatusCode"
        ] = response.status_code
        json_response["PublishResponse"]["ResponseMetadata"]["HTTPHeaders"] = dict(response.headers)
        snapshot.match("post-request", json_response)

        assert response.status_code == 200
        assert b"<PublishResponse" in response.content

        rs = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=5
        )
        snapshot.match("messages", rs)
        msg_body = json.loads(rs["Messages"][0]["Body"])
        assert msg_body["TopicArn"] == topic_arn
        assert msg_body["Message"] == message

    @markers.aws.validated
    def test_publish_wrong_arn_format(self, snapshot, aws_client):
        message = "Good news everyone!"
        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(Message=message, TopicArn="randomstring")

        snapshot.match("invalid-topic-arn", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(Message=message, TopicArn="randomstring:1")

        snapshot.match("invalid-topic-arn-1", e.value.response)

    @markers.aws.validated
    def test_publish_message_by_target_arn(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        # using an SQS subscription to test TopicArn/TargetArn as it is easier to check against AWS
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        aws_client.sns.publish(TopicArn=topic_arn, Message="test-msg-1")

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            MessageAttributeNames=["All"],
            VisibilityTimeout=0,
            WaitTimeSeconds=4,
        )

        snapshot.match("receive-topic-arn", response)

        message = response["Messages"][0]
        aws_client.sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=message["ReceiptHandle"])

        # publish with TargetArn instead of TopicArn
        aws_client.sns.publish(TargetArn=topic_arn, Message="test-msg-2")

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            MessageAttributeNames=["All"],
            VisibilityTimeout=0,
            WaitTimeSeconds=4,
        )
        snapshot.match("receive-target-arn", response)

    @markers.aws.validated
    def test_publish_message_before_subscribe_topic(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()

        rs = aws_client.sns.publish(
            TopicArn=topic_arn, Subject="test-subject-before-sub", Message="test_message_before"
        )
        snapshot.match("publish-before-subscribing", rs)

        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        message_subject = "test-subject-after-sub"
        message_body = "test_message_after"

        rs = aws_client.sns.publish(
            TopicArn=topic_arn, Subject=message_subject, Message=message_body
        )
        snapshot.match("publish-after-subscribing", rs)

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=5
        )
        # nothing was subscribing to the topic, so the first message is lost
        snapshot.match("receive-messages", response)

    @markers.aws.validated
    def test_unknown_topic_publish(self, sns_create_topic, snapshot, aws_client):
        # create topic to get the basic arn structure
        # otherwise you get InvalidClientTokenId exception because of account id
        topic_arn = sns_create_topic()["TopicArn"]
        # append to get an unknown topic
        fake_arn = f"{topic_arn}-fake"
        message = "This is a test message"

        # test to send a message with no subscribers
        response = aws_client.sns.publish(TopicArn=topic_arn, Message=message)
        snapshot.match("success", response)

        # test to send to a nonexistent topic
        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(TopicArn=fake_arn, Message=message)

        snapshot.match("error", e.value.response)

    @markers.aws.validated
    def test_publish_non_existent_target(self, sns_create_topic, snapshot, aws_client):
        topic_arn = sns_create_topic()["TopicArn"]
        account_id = parse_arn(topic_arn)["account"]
        with pytest.raises(ClientError) as ex:
            aws_client.sns.publish(
                TargetArn=f"arn:aws:sns:us-east-1:{account_id}:endpoint/APNS/abcdef/0f7d5971-aa8b-4bd5-b585-0826e9f93a66",
                Message="This is a push notification",
            )
        snapshot.match("non-existent-endpoint", ex.value.response)

    @markers.aws.validated
    def test_publish_with_empty_subject(self, sns_create_topic, snapshot, aws_client):
        topic_arn = sns_create_topic()["TopicArn"]

        # Publish without subject
        rs = aws_client.sns.publish(
            TopicArn=topic_arn, Message=json.dumps({"message": "test_publish"})
        )
        snapshot.match("response-without-subject", rs)
        assert rs["ResponseMetadata"]["HTTPStatusCode"] == 200

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Subject="",
                Message=json.dumps({"message": "test_publish"}),
            )

        snapshot.match("response-with-empty-subject", e.value.response)

    @markers.aws.validated
    def test_empty_sns_message(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(Message="", TopicArn=topic_arn)

        snapshot.match("empty-msg-error", e.value.response)

        queue_attrs = aws_client.sqs.get_queue_attributes(
            QueueUrl=queue_url, AttributeNames=["ApproximateNumberOfMessages"]
        )
        snapshot.match("queue-attrs", queue_attrs)

    @markers.aws.validated
    def test_publish_too_long_message(self, sns_create_topic, snapshot, aws_client):
        topic_arn = sns_create_topic()["TopicArn"]
        # simulate payload over 256kb
        message = "This is a test message" * 12000

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(TopicArn=topic_arn, Message=message)

        snapshot.match("error", e.value.response)

        assert e.value.response["Error"]["Code"] == "InvalidParameter"
        assert e.value.response["Error"]["Message"] == "Invalid parameter: Message too long"
        assert e.value.response["ResponseMetadata"]["HTTPStatusCode"] == 400

    @markers.aws.validated
    def test_message_structure_json_exc(self, sns_create_topic, snapshot, aws_client):
        topic_arn = sns_create_topic()["TopicArn"]
        # TODO: add batch

        # missing `default` key for the JSON
        with pytest.raises(ClientError) as e:
            message = json.dumps({"sqs": "Test message"})
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message=message,
                MessageStructure="json",
            )
        snapshot.match("missing-default-key", e.value.response)

        # invalid JSON
        with pytest.raises(ClientError) as e:
            message = '{"default": "This is a default message"} }'
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message=message,
                MessageStructure="json",
            )
        snapshot.match("invalid-json", e.value.response)

        # duplicate keys: from SNS docs, should fail but does work
        # https://docs.aws.amazon.com/sns/latest/api/API_Publish.html
        # `Duplicate keys are not allowed.`
        message = '{"default": "This is a default message", "default": "Duplicate"}'
        resp = aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageStructure="json",
        )
        snapshot.match("duplicate-json-keys", resp)

        with pytest.raises(ClientError) as e:
            message = json.dumps({"default": {"object": "test"}})
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message=message,
                MessageStructure="json",
            )
        snapshot.match("key-is-not-string", e.value.response)


class TestSNSSubscriptionCrud:
    @markers.aws.validated
    def test_subscribe_with_invalid_protocol(self, sns_create_topic, sns_subscription, snapshot):
        topic_arn = sns_create_topic()["TopicArn"]

        with pytest.raises(ClientError) as e:
            sns_subscription(
                TopicArn=topic_arn, Protocol="test-protocol", Endpoint="localstack@yopmail.com"
            )

        snapshot.match("exception", e.value.response)

    @markers.aws.validated
    def test_unsubscribe_from_non_existing_subscription(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        aws_client.sns.unsubscribe(SubscriptionArn=subscription["SubscriptionArn"])
        # unsubscribing a second time
        response = aws_client.sns.unsubscribe(SubscriptionArn=subscription["SubscriptionArn"])
        snapshot.match("empty-unsubscribe", response)

    @markers.aws.validated
    def test_create_subscriptions_with_attributes(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        snapshot,
        aws_client,
        sns_subscription,
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        queue_arn = sqs_get_queue_arn(queue_url)

        subscribe_resp = sns_subscription(
            TopicArn=topic_arn,
            Protocol="sqs",
            Endpoint=queue_arn,
            Attributes={
                "RawMessageDelivery": "true",
                "FilterPolicyScope": "MessageBody",
            },
            ReturnSubscriptionArn=True,
        )
        snapshot.match("subscribe", subscribe_resp)

        get_attrs_resp = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscribe_resp["SubscriptionArn"]
        )
        snapshot.match("get-attrs", get_attrs_resp)

        with pytest.raises(ClientError) as e:
            wrong_sub_arn = f"{subscribe_resp['SubscriptionArn'][:-8]}{short_uid()}"
            aws_client.sns.get_subscription_attributes(SubscriptionArn=wrong_sub_arn)

        snapshot.match("get-attrs-nonexistent-sub", e.value.response)

    @markers.aws.validated
    def test_not_found_error_on_set_subscription_attributes(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        sns_subscription,
        snapshot,
        aws_client,
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        queue_arn = sqs_get_queue_arn(queue_url)
        subscription = sns_subscription(TopicArn=topic_arn, Protocol="sqs", Endpoint=queue_arn)
        snapshot.match("sub", subscription)
        subscription_arn = subscription["SubscriptionArn"]

        response = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        subscription_attributes = response["Attributes"]
        snapshot.match("sub-attrs", response)

        assert subscription_attributes["SubscriptionArn"] == subscription_arn

        subscriptions_by_topic = aws_client.sns.list_subscriptions_by_topic(TopicArn=topic_arn)
        snapshot.match("subscriptions-for-topic-before-unsub", subscriptions_by_topic)
        assert len(subscriptions_by_topic["Subscriptions"]) == 1

        aws_client.sns.unsubscribe(SubscriptionArn=subscription_arn)

        def check_subscription_deleted():
            try:
                # AWS doesn't give NotFound error on GetSubscriptionAttributes for a while, might be cached
                aws_client.sns.set_subscription_attributes(
                    SubscriptionArn=subscription_arn,
                    AttributeName="RawMessageDelivery",
                    AttributeValue="true",
                )
                raise Exception("Subscription is not deleted")
            except ClientError as e:
                assert e.response["Error"]["Code"] == "NotFound"
                assert e.response["ResponseMetadata"]["HTTPStatusCode"] == 404
                snapshot.match("sub-not-found", e.response)

        retry(check_subscription_deleted, retries=10, sleep_before=0.2, sleep=3)
        subscriptions_by_topic = aws_client.sns.list_subscriptions_by_topic(TopicArn=topic_arn)
        snapshot.match("subscriptions-for-topic-after-unsub", subscriptions_by_topic)
        assert len(subscriptions_by_topic["Subscriptions"]) == 0

    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.invalid-json-redrive-policy.Error.Message",  # message contains java trace in AWS, assert instead
            "$.invalid-json-filter-policy.Error.Message",  # message contains java trace in AWS, assert instead
        ]
    )
    def test_validate_set_sub_attributes(
        self,
        sns_create_topic,
        sqs_create_queue,
        sns_create_sqs_subscription,
        snapshot,
        aws_client,
    ):
        topic_name = f"topic-{short_uid()}"
        queue_name = f"queue-{short_uid()}"
        topic_arn = sns_create_topic(Name=topic_name)["TopicArn"]
        queue_url = sqs_create_queue(QueueName=queue_name)
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        sub_arn = subscription["SubscriptionArn"]

        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=sub_arn,
                AttributeName="FakeAttribute",
                AttributeValue="test-value",
            )
        snapshot.match("fake-attribute", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=sub_arn,
                AttributeName="RedrivePolicy",
                AttributeValue=json.dumps({"deadLetterTargetArn": "fake-arn"}),
            )
        snapshot.match("fake-arn-redrive-policy", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=sub_arn,
                AttributeName="RedrivePolicy",
                AttributeValue="{invalidjson}",
            )
        snapshot.match("invalid-json-redrive-policy", e.value.response)
        assert e.value.response["Error"]["Message"].startswith(
            "Invalid parameter: RedrivePolicy: failed to parse JSON."
        )

        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=sub_arn,
                AttributeName="FilterPolicy",
                AttributeValue="{invalidjson}",
            )
        snapshot.match("invalid-json-filter-policy", e.value.response)
        assert e.value.response["Error"]["Message"].startswith(
            "Invalid parameter: FilterPolicy: failed to parse JSON."
        )

    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=["$.invalid-token.Error.Message"]  # validate the token shape
    )
    def test_sns_confirm_subscription_wrong_token(self, sns_create_topic, snapshot, aws_client):
        topic_arn = sns_create_topic()["TopicArn"]

        with pytest.raises(ClientError) as e:
            wrong_topic = topic_arn[:-1] + "i"
            aws_client.sns.confirm_subscription(
                TopicArn=wrong_topic,
                Token="51b2ff3edb475b7d91550e0ab6edf0c1de2a34e6ebaf6c2262a001bcb7e051c43aa00022ceecce70bd2a67b2042da8d8eb47fef7a4e4e942d23e7fa56146b9ee35da040b4b8af564cc4184a7391c834cb75d75c22981f776ad1ce8805e9bab29da2329985337bb8095627907b46c8577c8440556b6f86582a954758026f41fc62041c4b3f67b0f5921232b5dae5aaca1",
            )

        snapshot.match("topic-not-exists", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.confirm_subscription(TopicArn=topic_arn, Token="randomtoken")

        snapshot.match("invalid-token", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.confirm_subscription(
                TopicArn=topic_arn,
                Token="51b2ff3edb475b7d91550e0ab6edf0c1de2a34e6ebaf6c2262a001bcb7e051c43aa00022ceecce70bd2a67b2042da8d8eb47fef7a4e4e942d23e7fa56146b9ee35da040b4b8af564cc4184a7391c834cb75d75c22981f776ad1ce8805e9bab29da2329985337bb8095627907b46c8577c8440556b6f86582a954758026f41fc62041c4b3f67b0f5921232b5dae5aaca1",
            )

        snapshot.match("token-not-exists", e.value.response)

    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=["$.list-subscriptions.Subscriptions"],
        # there could be cleanup issues and don't want to flake, manually assert
    )
    def test_list_subscriptions(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        sns_subscription,
        snapshot,
        aws_client,
    ):
        snapshot.add_transformer(snapshot.transform.key_value("NextToken"))
        topic = sns_create_topic()
        topic_arn = topic["TopicArn"]
        snapshot.match("create-topic-1", topic)
        topic_2 = sns_create_topic()
        topic_arn_2 = topic_2["TopicArn"]
        snapshot.match("create-topic-2", topic_2)
        sorting_list = []
        for i in range(3):
            queue_url = sqs_create_queue()
            queue_arn = sqs_get_queue_arn(queue_url)
            subscription = sns_subscription(TopicArn=topic_arn, Protocol="sqs", Endpoint=queue_arn)
            snapshot.match(f"sub-topic-1-{i}", subscription)
            sorting_list.append((topic_arn, queue_arn))
        for i in range(3):
            queue_url = sqs_create_queue()
            queue_arn = sqs_get_queue_arn(queue_url)
            subscription = sns_subscription(
                TopicArn=topic_arn_2, Protocol="sqs", Endpoint=queue_arn
            )
            snapshot.match(f"sub-topic-2-{i}", subscription)
            sorting_list.append((topic_arn_2, queue_arn))

        list_subs = aws_client.sns.list_subscriptions()
        all_subs = list_subs["Subscriptions"]
        if list_subs.get("NextToken"):
            while next_token := list_subs.get("NextToken"):
                list_subs = aws_client.sns.list_subscriptions(NextToken=next_token)
                all_subs.extend(list_subs["Subscriptions"])

        all_subs.sort(key=lambda x: sorting_list.index((x["TopicArn"], x["Endpoint"])))
        list_subs["Subscriptions"] = all_subs
        snapshot.match("list-subscriptions-aggregated", list_subs)

        assert all((sub["TopicArn"], sub["Endpoint"]) in sorting_list for sub in all_subs)

    @markers.aws.validated
    def test_subscribe_idempotency(
        self, aws_client, sns_create_topic, sqs_create_queue, sqs_get_queue_arn, snapshot
    ):
        """
        Test the idempotency of SNS subscribe calls for a given endpoint and its attributes
        """
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        queue_arn = sqs_get_queue_arn(queue_url)

        def subscribe_queue_to_topic(attributes: dict = None) -> dict:
            kwargs = {}
            if attributes is not None:
                kwargs["Attributes"] = attributes
            response = aws_client.sns.subscribe(
                TopicArn=topic_arn,
                Protocol="sqs",
                Endpoint=queue_arn,
                ReturnSubscriptionArn=True,
                **kwargs,
            )
            return response

        subscribe_resp = subscribe_queue_to_topic(
            {
                "RawMessageDelivery": "true",
            }
        )
        snapshot.match("subscribe", subscribe_resp)

        get_attrs_resp = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscribe_resp["SubscriptionArn"]
        )
        snapshot.match("get-sub-attrs", get_attrs_resp)

        subscribe_resp = subscribe_queue_to_topic(
            {
                "RawMessageDelivery": "true",
            }
        )
        snapshot.match("subscribe-exact-same-raw", subscribe_resp)

        subscribe_resp = subscribe_queue_to_topic(
            {
                "RawMessageDelivery": "true",
                "FilterPolicyScope": "MessageAttributes",  # test if it also matches default values
            }
        )

        snapshot.match("subscribe-idempotent", subscribe_resp)

        # no attributes and empty attributes are working as well
        subscribe_resp = subscribe_queue_to_topic()
        snapshot.match("subscribe-idempotent-no-attributes", subscribe_resp)

        subscribe_resp = subscribe_queue_to_topic({})
        snapshot.match("subscribe-idempotent-empty-attributes", subscribe_resp)

        subscribe_resp = subscribe_queue_to_topic({"FilterPolicyScope": "MessageAttributes"})
        snapshot.match("subscribe-missing-attributes", subscribe_resp)

        with pytest.raises(ClientError) as e:
            subscribe_queue_to_topic(
                {
                    "RawMessageDelivery": "false",
                    "FilterPolicyScope": "MessageBody",
                }
            )
        snapshot.match("subscribe-diff-attributes", e.value.response)


class TestSNSSubscriptionLambda:
    @markers.aws.validated
    def test_python_lambda_subscribe_sns_topic(
        self,
        sns_create_topic,
        sns_subscription,
        lambda_su_role,
        create_lambda_function,
        snapshot,
        aws_client,
    ):
        function_name = f"lambda-function-{short_uid()}"
        permission_id = f"test-statement-{short_uid()}"
        subject = "[Subject] Test subject"
        message = "Hello world."
        topic_arn = sns_create_topic()["TopicArn"]

        lambda_creation_response = create_lambda_function(
            func_name=function_name,
            handler_file=TEST_LAMBDA_PYTHON_ECHO,
            runtime=Runtime.python3_9,
            role=lambda_su_role,
        )
        lambda_arn = lambda_creation_response["CreateFunctionResponse"]["FunctionArn"]
        aws_client.lambda_.add_permission(
            FunctionName=function_name,
            StatementId=permission_id,
            Action="lambda:InvokeFunction",
            Principal="sns.amazonaws.com",
            SourceArn=topic_arn,
        )

        subscription = sns_subscription(
            TopicArn=topic_arn,
            Protocol="lambda",
            Endpoint=lambda_arn,
        )

        def check_subscription():
            subscription_arn = subscription["SubscriptionArn"]
            subscription_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=subscription_arn
            )
            assert subscription_attrs["Attributes"]["PendingConfirmation"] == "false"

        retry(check_subscription, retries=PUBLICATION_RETRIES, sleep=PUBLICATION_TIMEOUT)

        aws_client.sns.publish(TopicArn=topic_arn, Subject=subject, Message=message)

        # access events sent by lambda
        events = retry(
            check_expected_lambda_log_events_length,
            retries=10,
            sleep=1,
            function_name=function_name,
            expected_length=1,
            regex_filter="Records.*Sns",
            logs_client=aws_client.logs,
        )
        notification = events[0]["Records"][0]["Sns"]
        snapshot.match("notification", notification)

    @markers.aws.validated
    def test_sns_topic_as_lambda_dead_letter_queue(
        self,
        lambda_su_role,
        create_lambda_function,
        sns_create_topic,
        sqs_create_queue,
        sns_subscription,
        sns_create_sqs_subscription,
        snapshot,
        aws_client,
    ):
        """Tests an async event chain: SNS => Lambda => SNS DLQ => SQS
        1) SNS => Lambda: An SNS subscription triggers the Lambda function asynchronously.
        2) Lambda => SNS DLQ: A failing Lambda function triggers the SNS DLQ after all retries are exhausted.
        3) SNS DLQ => SQS: An SNS subscription forwards the DLQ message to SQS.
        """
        snapshot.add_transformer(
            snapshot.transform.jsonpath(
                "$..Messages..MessageAttributes.RequestID.Value", "request-id"
            )
        )

        # create an SNS topic that will be used as a DLQ by the lambda
        dlq_topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()

        # sqs_subscription
        sns_create_sqs_subscription(topic_arn=dlq_topic_arn, queue_url=queue_url)

        # create an SNS topic that will be used to invoke the lambda
        lambda_topic_arn = sns_create_topic()["TopicArn"]

        function_name = f"lambda-function-{short_uid()}"
        lambda_creation_response = create_lambda_function(
            func_name=function_name,
            handler_file=TEST_LAMBDA_PYTHON,
            runtime=Runtime.python3_9,
            role=lambda_su_role,
            DeadLetterConfig={"TargetArn": dlq_topic_arn},
        )
        snapshot.match(
            "lambda-response-dlq-config",
            lambda_creation_response["CreateFunctionResponse"]["DeadLetterConfig"],
        )
        lambda_arn = lambda_creation_response["CreateFunctionResponse"]["FunctionArn"]

        # allow the SNS topic to invoke the lambda
        permission_id = f"test-statement-{short_uid()}"
        aws_client.lambda_.add_permission(
            FunctionName=function_name,
            StatementId=permission_id,
            Action="lambda:InvokeFunction",
            Principal="sns.amazonaws.com",
            SourceArn=lambda_topic_arn,
        )

        # subscribe the lambda to the SNS topic: lambda_subscription
        sns_subscription(
            TopicArn=lambda_topic_arn,
            Protocol="lambda",
            Endpoint=lambda_arn,
        )

        # Set retries to zero to speed up the test
        aws_client.lambda_.put_function_event_invoke_config(
            FunctionName=function_name,
            MaximumRetryAttempts=0,
        )

        payload = {
            lambda_integration.MSG_BODY_RAISE_ERROR_FLAG: 1,
        }
        aws_client.sns.publish(TopicArn=lambda_topic_arn, Message=json.dumps(payload))

        def receive_dlq():
            result = aws_client.sqs.receive_message(
                QueueUrl=queue_url, MessageAttributeNames=["All"], VisibilityTimeout=0
            )
            assert len(result["Messages"]) > 0
            return result

        sleep = 3 if is_aws_cloud() else 1
        messages = retry(receive_dlq, retries=30, sleep=sleep)

        messages["Messages"][0]["Body"] = json.loads(messages["Messages"][0]["Body"])
        messages["Messages"][0]["Body"]["Message"] = json.loads(
            messages["Messages"][0]["Body"]["Message"]
        )

        snapshot.match("messages", messages)

    @markers.aws.validated
    def test_redrive_policy_lambda_subscription(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        create_lambda_function,
        lambda_su_role,
        sns_subscription,
        sns_allow_topic_sqs_queue,
        snapshot,
        aws_client,
    ):
        dlq_url = sqs_create_queue()
        dlq_arn = sqs_get_queue_arn(dlq_url)
        topic_arn = sns_create_topic()["TopicArn"]
        sns_allow_topic_sqs_queue(
            sqs_queue_url=dlq_url, sqs_queue_arn=dlq_arn, sns_topic_arn=topic_arn
        )

        lambda_name = f"test-{short_uid()}"
        lambda_arn = create_lambda_function(
            func_name=lambda_name,
            handler_file=TEST_LAMBDA_PYTHON,
            runtime=Runtime.python3_9,
            role=lambda_su_role,
        )["CreateFunctionResponse"]["FunctionArn"]

        subscription = sns_subscription(TopicArn=topic_arn, Protocol="lambda", Endpoint=lambda_arn)

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"],
            AttributeName="RedrivePolicy",
            AttributeValue=json.dumps({"deadLetterTargetArn": dlq_arn}),
        )
        response_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"]
        )

        snapshot.match("subscription-attributes", response_attributes)

        aws_client.lambda_.delete_function(FunctionName=lambda_name)

        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message="test_redrive_policy",
            MessageAttributes={"attr1": {"DataType": "Number", "StringValue": "1"}},
        )

        response = aws_client.sqs.receive_message(
            QueueUrl=dlq_url, WaitTimeSeconds=10, MessageAttributeNames=["All"]
        )
        snapshot.match("messages", response)


class TestSNSSubscriptionSQS:
    @markers.aws.validated
    def test_subscribe_sqs_queue(
        self, sqs_create_queue, sns_create_topic, sns_create_sqs_subscription, snapshot, aws_client
    ):
        # TODO: check with non default external port

        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()

        # create subscription with filter policy
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        filter_policy = {"attr1": [{"numeric": [">", 0, "<=", 100]}]}
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"],
            AttributeName="FilterPolicy",
            AttributeValue=json.dumps(filter_policy),
        )

        response_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"],
        )
        snapshot.match("subscription-attributes", response_attributes)

        # publish message that satisfies the filter policy
        message = "This is a test message"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageAttributes={"attr1": {"DataType": "Number", "StringValue": "99.12"}},
        )

        # assert that message is received
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            VisibilityTimeout=0,
            MessageAttributeNames=["All"],
            WaitTimeSeconds=4,
        )
        snapshot.match("messages", response)

    @markers.aws.validated
    def test_publish_unicode_chars(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        # publish message to SNS, receive it from SQS, assert that messages are equal
        message = 'ö§a1"_!?,. £$-'
        aws_client.sns.publish(TopicArn=topic_arn, Message=message)

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )

        snapshot.match("received-message", response)

    @markers.aws.validated
    def test_attribute_raw_subscribe(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        # the hash isn't the same because of the Binary attributes (maybe decoding order?)
        snapshot.add_transformer(
            snapshot.transform.key_value(
                "MD5OfMessageAttributes",
                value_replacement="<md5-hash>",
                reference_replacement=False,
            )
        )
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(
            topic_arn=topic_arn, queue_url=queue_url, Attributes={"RawMessageDelivery": "true"}
        )
        subscription_arn = subscription["SubscriptionArn"]

        response_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("subscription-attributes", response_attributes)

        # publish message to SNS, receive it from SQS, assert that messages are equal and that they are Raw
        message = "This is a test message"
        binary_attribute = b"\x02\x03\x04"
        # extending this test case to test support for binary message attribute data
        # https://github.com/localstack/localstack/issues/2432
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageAttributes={"store": {"DataType": "Binary", "BinaryValue": binary_attribute}},
        )

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            MessageAttributeNames=["All"],
            VisibilityTimeout=0,
            WaitTimeSeconds=4,
        )
        snapshot.match("messages-response", response)

    @markers.aws.validated
    def test_sqs_topic_subscription_confirmation(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription_attrs = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        def check_subscription():
            nonlocal subscription_attrs
            if not subscription_attrs["PendingConfirmation"] == "false":
                subscription_arn = subscription_attrs["SubscriptionArn"]
                subscription_attrs = aws_client.sns.get_subscription_attributes(
                    SubscriptionArn=subscription_arn
                )["Attributes"]
            else:
                snapshot.match("subscription-attrs", subscription_attrs)

            return subscription_attrs["PendingConfirmation"] == "false"

        # SQS subscriptions are auto confirmed if the endpoint and the topic are in the same AWS account
        assert poll_condition(check_subscription, timeout=5)

    @markers.aws.validated
    def test_publish_sqs_from_sns(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="RawMessageDelivery",
            AttributeValue="true",
        )
        response = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        snapshot.match("sub-attrs-raw-true", response)

        string_value = "99.12"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message="Test msg",
            MessageAttributes={"attr1": {"DataType": "Number", "StringValue": string_value}},
        )

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            MessageAttributeNames=["All"],
            VisibilityTimeout=0,
            WaitTimeSeconds=4,
        )
        snapshot.match("message-raw-true", response)
        # format is of SQS MessageAttributes when RawDelivery is set to "true"
        assert response["Messages"][0]["MessageAttributes"] == {
            "attr1": {"DataType": "Number", "StringValue": string_value}
        }

        aws_client.sqs.delete_message(
            QueueUrl=queue_url, ReceiptHandle=response["Messages"][0]["ReceiptHandle"]
        )

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="RawMessageDelivery",
            AttributeValue="false",
        )
        response = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        snapshot.match("sub-attrs-raw-false", response)

        string_value = "100.12"
        aws_client.sns.publish(
            TargetArn=topic_arn,
            Message="Test msg",
            MessageAttributes={"attr1": {"DataType": "Number", "StringValue": string_value}},
        )
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            MessageAttributeNames=["All"],
            VisibilityTimeout=0,
            WaitTimeSeconds=4,
        )
        snapshot.match("message-raw-false", response)
        message_body = json.loads(response["Messages"][0]["Body"])
        # format is SNS MessageAttributes when RawDelivery is "false"
        assert message_body["MessageAttributes"] == {
            "attr1": {"Type": "Number", "Value": string_value}
        }

    @markers.aws.validated
    def test_publish_batch_messages_from_sns_to_sqs(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="RawMessageDelivery",
            AttributeValue="true",
        )
        response = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        snapshot.match("sub-attrs-raw-true", response)

        publish_batch_response = aws_client.sns.publish_batch(
            TopicArn=topic_arn,
            PublishBatchRequestEntries=[
                {
                    "Id": "1",
                    "Message": "Test Message with two attributes",
                    "Subject": "Subject",
                    "MessageAttributes": {
                        "attr1": {"DataType": "Number", "StringValue": "99.12"},
                        "attr2": {"DataType": "Number", "StringValue": "109.12"},
                    },
                },
                {
                    "Id": "2",
                    "Message": "Test Message with one attribute",
                    "Subject": "Subject",
                    "MessageAttributes": {"attr1": {"DataType": "Number", "StringValue": "19.12"}},
                },
                {
                    "Id": "3",
                    "Message": "Test Message without attribute",
                    "Subject": "Subject",
                },
                {
                    "Id": "4",
                    "Message": "Test Message without subject",
                },
                {
                    "Id": "5",
                    "Message": json.dumps({"default": "test default", "sqs": "test sqs"}),
                    "MessageStructure": "json",
                },
            ],
        )
        snapshot.match("publish-batch", publish_batch_response)

        messages = []

        def get_messages():
            # due to the random nature of receiving SQS messages, we need to consolidate a single object to match
            sqs_response = aws_client.sqs.receive_message(
                QueueUrl=queue_url,
                WaitTimeSeconds=1,
                VisibilityTimeout=0,
                MessageAttributeNames=["All"],
                AttributeNames=["All"],
            )
            for message in sqs_response["Messages"]:
                messages.append(message)
                aws_client.sqs.delete_message(
                    QueueUrl=queue_url, ReceiptHandle=message["ReceiptHandle"]
                )

            assert len(messages) == 5

        retry(get_messages, retries=10, sleep=0.1)
        # we need to sort the list (the order does not matter as we're not using FIFO)
        messages.sort(key=itemgetter("Body"))
        snapshot.match("messages", {"Messages": messages})

    @markers.aws.validated
    def test_publish_batch_messages_without_topic(self, sns_create_topic, snapshot, aws_client):
        topic_arn = sns_create_topic()["TopicArn"]
        fake_topic_arn = topic_arn + "fake-topic"

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish_batch(
                TopicArn=fake_topic_arn,
                PublishBatchRequestEntries=[
                    {
                        "Id": "1",
                        "Message": "Test Message with two attributes",
                        "Subject": "Subject",
                    }
                ],
            )
        snapshot.match("publish-batch-no-topic", e.value.response)

    @markers.aws.validated
    def test_publish_batch_exceptions(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        fifo_topic_name = f"topic-{short_uid()}.fifo"
        topic_arn = sns_create_topic(Name=fifo_topic_name, Attributes={"FifoTopic": "true"})[
            "TopicArn"
        ]

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish_batch(
                TopicArn=topic_arn,
                PublishBatchRequestEntries=[
                    {
                        "Id": "1",
                        "Message": "Test message without Group ID",
                    }
                ],
            )
        snapshot.match("no-group-id", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish_batch(
                TopicArn=topic_arn,
                PublishBatchRequestEntries=[
                    {"Id": f"Id_{i}", "Message": "Too many messages"} for i in range(11)
                ],
            )
        snapshot.match("too-many-msg", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish_batch(
                TopicArn=topic_arn,
                PublishBatchRequestEntries=[
                    {"Id": "1", "Message": "Messages with the same ID"} for _ in range(2)
                ],
            )
        snapshot.match("same-msg-id", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish_batch(
                TopicArn=topic_arn,
                PublishBatchRequestEntries=[
                    {
                        "Id": "1",
                        "Message": "Test message without MessageDeduplicationId",
                        "MessageGroupId": "msg1",
                    }
                ],
            )
        snapshot.match("no-dedup-id", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish_batch(
                TopicArn=topic_arn,
                PublishBatchRequestEntries=[
                    {
                        "Id": "1",
                        "Message": json.dumps({"sqs": "test sqs"}),
                        "MessageStructure": "json",
                    }
                ],
            )
        snapshot.match("no-default-key-json", e.value.response)

    @markers.aws.validated
    def test_subscribe_to_sqs_with_queue_url(
        self, sns_create_topic, sqs_create_queue, sns_subscription, snapshot
    ):
        topic = sns_create_topic()
        topic_arn = topic["TopicArn"]
        queue_url = sqs_create_queue()
        with pytest.raises(ClientError) as e:
            sns_subscription(TopicArn=topic_arn, Protocol="sqs", Endpoint=queue_url)
        snapshot.match("sub-queue-url", e.value.response)

    @markers.aws.validated
    def test_publish_sqs_from_sns_with_xray_propagation(
        self, sns_create_topic, sqs_create_queue, sns_create_sqs_subscription, snapshot, aws_client
    ):
        def add_xray_header(request, **_kwargs):
            request.headers[
                "X-Amzn-Trace-Id"
            ] = "Root=1-3152b799-8954dae64eda91bc9a23a7e8;Parent=7fa8c0f79203be72;Sampled=1"

        try:
            aws_client.sns.meta.events.register("before-send.sns.Publish", add_xray_header)

            topic = sns_create_topic()
            topic_arn = topic["TopicArn"]
            queue_url = sqs_create_queue()
            sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
            aws_client.sns.publish(TargetArn=topic_arn, Message="X-Ray propagation test msg")

            response = aws_client.sqs.receive_message(
                QueueUrl=queue_url,
                AttributeNames=["SentTimestamp", "AWSTraceHeader"],
                MaxNumberOfMessages=1,
                MessageAttributeNames=["All"],
                VisibilityTimeout=2,
                WaitTimeSeconds=2,
            )

            assert len(response["Messages"]) == 1
            message = response["Messages"][0]
            snapshot.match("xray-msg", message)
            assert (
                message["Attributes"]["AWSTraceHeader"]
                == "Root=1-3152b799-8954dae64eda91bc9a23a7e8;Parent=7fa8c0f79203be72;Sampled=1"
            )
        finally:
            aws_client.sns.meta.events.unregister("before-send.sns.Publish", add_xray_header)

    @pytest.mark.parametrize("raw_message_delivery", [True, False])
    @markers.aws.validated
    def test_redrive_policy_sqs_queue_subscription(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        sqs_queue_exists,
        sns_create_sqs_subscription,
        sns_allow_topic_sqs_queue,
        raw_message_delivery,
        snapshot,
        aws_client,
    ):
        # the hash isn't the same because of the Binary attributes (maybe decoding order?)
        snapshot.add_transformer(
            snapshot.transform.key_value(
                "MD5OfMessageAttributes",
                value_replacement="<md5-hash>",
                reference_replacement=False,
            )
        )
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()

        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        dlq_url = sqs_create_queue()
        dlq_arn = sqs_get_queue_arn(dlq_url)

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"],
            AttributeName="RedrivePolicy",
            AttributeValue=json.dumps({"deadLetterTargetArn": dlq_arn}),
        )

        if raw_message_delivery:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription["SubscriptionArn"],
                AttributeName="RawMessageDelivery",
                AttributeValue="true",
            )

        sns_allow_topic_sqs_queue(
            sqs_queue_url=dlq_url,
            sqs_queue_arn=dlq_arn,
            sns_topic_arn=topic_arn,
        )

        aws_client.sqs.delete_queue(QueueUrl=queue_url)

        # AWS takes some time to delete the queue, which make the test fails as it delivers the message correctly
        assert poll_condition(lambda: not sqs_queue_exists(queue_url), timeout=5)

        message = "test_dlq_after_sqs_endpoint_deleted"
        message_attr = {
            "attr1": {
                "DataType": "Number",
                "StringValue": "111",
            },
            "attr2": {
                "DataType": "Binary",
                "BinaryValue": b"\x02\x03\x04",
            },
        }
        aws_client.sns.publish(TopicArn=topic_arn, Message=message, MessageAttributes=message_attr)

        response = aws_client.sqs.receive_message(
            QueueUrl=dlq_url,
            WaitTimeSeconds=10,
            AttributeNames=["All"],
            MessageAttributeNames=["All"],
        )
        snapshot.match("messages", response)

    @markers.aws.validated
    def test_message_attributes_not_missing(
        self, sns_create_sqs_subscription, sns_create_topic, sqs_create_queue, snapshot, aws_client
    ):
        # the hash isn't the same because of the Binary attributes (maybe decoding order?)
        snapshot.add_transformer(
            snapshot.transform.key_value(
                "MD5OfMessageAttributes",
                value_replacement="<md5-hash>",
                reference_replacement=False,
            )
        )
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()

        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"],
            AttributeName="RawMessageDelivery",
            AttributeValue="true",
        )
        attributes = {
            "an-attribute-key": {"DataType": "String", "StringValue": "an-attribute-value"},
            "binary-attribute": {"DataType": "Binary", "BinaryValue": b"\x02\x03\x04"},
        }

        publish_response = aws_client.sns.publish(
            TopicArn=topic_arn,
            Message="text",
            MessageAttributes=attributes,
        )
        snapshot.match("publish-msg-raw", publish_response)

        msg = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            AttributeNames=["All"],
            MessageAttributeNames=["All"],
            WaitTimeSeconds=3,
        )
        # as SNS piggybacks on SQS MessageAttributes when RawDelivery is true
        # BinaryValue depends on SQS implementation, and is decoded automatically
        snapshot.match("raw-delivery-msg-attrs", msg)

        aws_client.sqs.delete_message(
            QueueUrl=queue_url, ReceiptHandle=msg["Messages"][0]["ReceiptHandle"]
        )

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"],
            AttributeName="RawMessageDelivery",
            AttributeValue="false",
        )

        publish_response = aws_client.sns.publish(
            TopicArn=topic_arn,
            Message="text",
            MessageAttributes=attributes,
        )
        snapshot.match("publish-msg-json", publish_response)

        msg = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            AttributeNames=["All"],
            MessageAttributeNames=["All"],
            WaitTimeSeconds=3,
        )
        snapshot.match("json-delivery-msg-attrs", msg)
        # binary payload in base64 encoded by AWS, UTF-8 for JSON
        # https://docs.aws.amazon.com/sns/latest/api/API_MessageAttributeValue.html

    @markers.aws.validated
    def test_subscription_after_failure_to_deliver(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        sqs_queue_exists,
        sns_create_sqs_subscription,
        sns_allow_topic_sqs_queue,
        sqs_receive_num_messages,
        snapshot,
        aws_client,
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_name = f"test-queue-{short_uid()}"
        queue_url = sqs_create_queue(QueueName=queue_name)

        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        dlq_url = sqs_create_queue()
        dlq_arn = sqs_get_queue_arn(dlq_url)

        sns_allow_topic_sqs_queue(
            sqs_queue_url=dlq_url,
            sqs_queue_arn=dlq_arn,
            sns_topic_arn=topic_arn,
        )

        sub_attrs = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        snapshot.match("subscriptions-attrs", sub_attrs)

        message = "test_dlq_before_sqs_endpoint_deleted"
        aws_client.sns.publish(TopicArn=topic_arn, Message=message)
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, WaitTimeSeconds=10, MaxNumberOfMessages=4
        )
        snapshot.match("messages-before-delete", response)
        aws_client.sqs.delete_message(
            QueueUrl=queue_url, ReceiptHandle=response["Messages"][0]["ReceiptHandle"]
        )

        aws_client.sqs.delete_queue(QueueUrl=queue_url)

        # setting up a second queue to be able to poll and know approximately when the message on the deleted queue
        # have been published
        queue_test_url = sqs_create_queue()
        test_subscription = sns_create_sqs_subscription(
            topic_arn=topic_arn, queue_url=queue_test_url
        )
        test_subscription_arn = test_subscription["SubscriptionArn"]
        # try to send a message before setting a DLQ
        message = "test_dlq_after_sqs_endpoint_deleted"
        aws_client.sns.publish(TopicArn=topic_arn, Message=message)

        # to avoid race condition, publish is async and the redrive policy can be in effect before the actual publish
        # we wait until the 2nd subscription received the message
        poll_condition(
            lambda: sqs_receive_num_messages(
                queue_url=queue_test_url, expected_messages=1, max_iterations=2
            ),
            timeout=10,
        )
        aws_client.sns.unsubscribe(SubscriptionArn=test_subscription_arn)
        # we still wait a bit to be sure the message is well published
        time.sleep(1)

        # check the subscription is still there after we deleted the queue
        subscriptions = aws_client.sns.list_subscriptions_by_topic(TopicArn=topic_arn)
        snapshot.match("subscriptions", subscriptions)

        # set the RedrivePolicy with a DLQ. Subsequent failing messages to the subscription should go there
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="RedrivePolicy",
            AttributeValue=json.dumps({"deadLetterTargetArn": dlq_arn}),
        )

        sub_attrs = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        snapshot.match("subscriptions-attrs-with-redrive", sub_attrs)

        # AWS takes some time to delete the queue, which make the test fails as it delivers the message correctly
        assert poll_condition(lambda: not sqs_queue_exists(queue_url), timeout=5)

        # test sending and receiving multiple messages
        for i in range(2):
            message = f"test_dlq_after_sqs_endpoint_deleted_{i}"

            aws_client.sns.publish(TopicArn=topic_arn, Message=message)
            response = aws_client.sqs.receive_message(
                QueueUrl=dlq_url, WaitTimeSeconds=10, MaxNumberOfMessages=4
            )
            aws_client.sqs.delete_message(
                QueueUrl=dlq_url, ReceiptHandle=response["Messages"][0]["ReceiptHandle"]
            )

            snapshot.match(f"message-{i}-after-delete", response)

    @markers.aws.validated
    def test_empty_or_wrong_message_attributes(
        self, sns_create_sqs_subscription, sns_create_topic, sqs_create_queue, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()

        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        wrong_message_attributes = {
            "missing_string_attr": {"attr1": {"DataType": "String", "StringValue": ""}},
            "missing_binary_attr": {"attr1": {"DataType": "Binary", "BinaryValue": b""}},
            "str_attr_binary_value": {"attr1": {"DataType": "String", "BinaryValue": b"123"}},
            "int_attr_binary_value": {"attr1": {"DataType": "Number", "BinaryValue": b"123"}},
            "binary_attr_string_value": {"attr1": {"DataType": "Binary", "StringValue": "123"}},
            "invalid_attr_string_value": {
                "attr1": {"DataType": "InvalidType", "StringValue": "123"}
            },
            "too_long_name": {"a" * 257: {"DataType": "String", "StringValue": "123"}},
            "invalid_name": {"a^*?": {"DataType": "String", "StringValue": "123"}},
            "invalid_name_2": {".abc": {"DataType": "String", "StringValue": "123"}},
            "invalid_name_3": {"abc.": {"DataType": "String", "StringValue": "123"}},
            "invalid_name_4": {"a..bc": {"DataType": "String", "StringValue": "123"}},
        }

        for error_type, msg_attrs in wrong_message_attributes.items():
            with pytest.raises(ClientError) as e:
                aws_client.sns.publish(
                    TopicArn=topic_arn,
                    Message="test message",
                    MessageAttributes=msg_attrs,
                )

            snapshot.match(error_type, e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish_batch(
                TopicArn=topic_arn,
                PublishBatchRequestEntries=[
                    {
                        "Id": "1",
                        "Message": "test-batch",
                        "MessageAttributes": wrong_message_attributes["missing_string_attr"],
                    },
                    {
                        "Id": "2",
                        "Message": "test-batch",
                        "MessageAttributes": wrong_message_attributes["str_attr_binary_value"],
                    },
                    {
                        "Id": "3",
                        "Message": "valid-batch",
                    },
                ],
            )
        snapshot.match("batch-exception", e.value.response)

    @markers.aws.validated
    def test_message_attributes_prefixes(
        self, sns_create_sqs_subscription, sns_create_topic, sqs_create_queue, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()

        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message="test message",
                MessageAttributes={"attr1": {"DataType": "String.", "StringValue": "prefixed-1"}},
            )
        snapshot.match("publish-error", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message="test message",
                MessageAttributes={
                    "attr1": {"DataType": "Stringprefixed", "StringValue": "prefixed-1"}
                },
            )
        snapshot.match("publish-error-2", e.value.response)

        response = aws_client.sns.publish(
            TopicArn=topic_arn,
            Message="test message",
            MessageAttributes={
                "attr1": {"DataType": "String.prefixed", "StringValue": "prefixed-1"}
            },
        )
        snapshot.match("publish-ok-1", response)

        response = aws_client.sns.publish(
            TopicArn=topic_arn,
            Message="test message",
            MessageAttributes={
                "attr1": {"DataType": "String.  prefixed.", "StringValue": "prefixed-1"}
            },
        )
        snapshot.match("publish-ok-2", response)

    @markers.aws.validated
    def test_message_structure_json_to_sqs(
        self, aws_client, sns_create_topic, sqs_create_queue, snapshot, sns_create_sqs_subscription
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_name = f"test-queue-{short_uid()}"
        queue_url = sqs_create_queue(QueueName=queue_name)

        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        message = json.dumps({"default": "default field", "sqs": json.dumps({"field": "value"})})
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageStructure="json",
        )
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, WaitTimeSeconds=10, MaxNumberOfMessages=1
        )
        snapshot.match("get-msg-json-sqs", response)
        receipt_handle = response["Messages"][0]["ReceiptHandle"]
        aws_client.sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt_handle)

        # don't json dumps the SQS field, it will be ignored, and the message received will be the `default`
        message = json.dumps({"default": "default field", "sqs": {"field": "value"}})
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageStructure="json",
        )
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, WaitTimeSeconds=10, MaxNumberOfMessages=1
        )
        snapshot.match("get-msg-json-default", response)


class TestSNSSubscriptionSQSFifo:
    @markers.aws.validated
    @pytest.mark.parametrize("content_based_deduplication", [True, False])
    def test_message_to_fifo_sqs(
        self,
        sns_create_topic,
        sqs_create_queue,
        sns_create_sqs_subscription,
        snapshot,
        content_based_deduplication,
        aws_client,
    ):
        topic_name = f"topic-{short_uid()}.fifo"
        queue_name = f"queue-{short_uid()}.fifo"
        topic_attributes = {"FifoTopic": "true"}
        queue_attributes = {"FifoQueue": "true"}
        if content_based_deduplication:
            topic_attributes["ContentBasedDeduplication"] = "true"
            queue_attributes["ContentBasedDeduplication"] = "true"

        topic_arn = sns_create_topic(
            Name=topic_name,
            Attributes=topic_attributes,
        )["TopicArn"]
        queue_url = sqs_create_queue(
            QueueName=queue_name,
            Attributes=queue_attributes,
        )

        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        message = "Test"
        kwargs = {"MessageGroupId": "message-group-id-1"}
        if not content_based_deduplication:
            kwargs["MessageDeduplicationId"] = "message-deduplication-id-1"

        aws_client.sns.publish(TopicArn=topic_arn, Message=message, **kwargs)

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            WaitTimeSeconds=10,
            AttributeNames=["All"],
        )
        snapshot.match("messages", response)

        aws_client.sqs.delete_message(
            QueueUrl=queue_url, ReceiptHandle=response["Messages"][0]["ReceiptHandle"]
        )
        # republish the message, to check deduplication
        aws_client.sns.publish(TopicArn=topic_arn, Message=message, **kwargs)
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            WaitTimeSeconds=1,
            AttributeNames=["All"],
        )
        snapshot.match("dedup-messages", response)

    @markers.aws.validated
    @pytest.mark.parametrize("content_based_deduplication", [True, False])
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.dedup-messages.Messages"
        ],  # FIXME: introduce deduplication at Topic level, not only SQS
    )
    def test_fifo_topic_to_regular_sqs(
        self,
        sns_create_topic,
        sqs_create_queue,
        sns_create_sqs_subscription,
        snapshot,
        content_based_deduplication,
        aws_client,
    ):
        # it seems change is coming on AWS, as FIFO topic do not require FIFO queues anymore. This might mean that
        # the FIFO logic is being migrated to SNS and do not rely on SQS FIFO anymore? or that the FIFO is only
        # guaranteed with FIFO queues, but you can also subscribe with regular subscribers for deduplication for ex. ?
        # The change in error message suggest the latter:
        # "RedrivePolicy: must use a FIFO queue as DLQ for a FIFO topic" became:
        # -> "RedrivePolicy: must use a FIFO queue as DLQ for a FIFO Subscription to a FIFO Topic."

        topic_name = f"topic-{short_uid()}.fifo"
        queue_name = f"queue-{short_uid()}"
        topic_attributes = {"FifoTopic": "true"}
        if content_based_deduplication:
            topic_attributes["ContentBasedDeduplication"] = "true"

        topic_arn = sns_create_topic(
            Name=topic_name,
            Attributes=topic_attributes,
        )["TopicArn"]
        queue_url = sqs_create_queue(QueueName=queue_name)

        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        message = "Test"
        kwargs = {"MessageGroupId": "message-group-id-1"}
        if not content_based_deduplication:
            kwargs["MessageDeduplicationId"] = "message-deduplication-id-1"

        aws_client.sns.publish(TopicArn=topic_arn, Message=message, **kwargs)

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            WaitTimeSeconds=10,
            AttributeNames=["All"],
        )
        snapshot.match("messages", response)

        aws_client.sqs.delete_message(
            QueueUrl=queue_url, ReceiptHandle=response["Messages"][0]["ReceiptHandle"]
        )
        # republish the message, to check deduplication
        # TODO: not implemented in LocalStack yet, only deduplication with FIFO SQS queues
        aws_client.sns.publish(TopicArn=topic_arn, Message=message, **kwargs)
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            WaitTimeSeconds=3,
            AttributeNames=["All"],
        )
        snapshot.match("dedup-messages", response)

    @markers.aws.validated
    def test_validations_for_fifo(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        sns_create_sqs_subscription,
        snapshot,
        aws_client,
    ):
        topic_name = f"topic-{short_uid()}"
        fifo_topic_name = f"topic-{short_uid()}.fifo"
        queue_name = f"queue-{short_uid()}"
        fifo_queue_name = f"queue-{short_uid()}.fifo"
        not_fifo_dlq_name = f"queue-dlq-{short_uid()}"

        topic_arn = sns_create_topic(Name=topic_name)["TopicArn"]

        fifo_topic_arn = sns_create_topic(Name=fifo_topic_name, Attributes={"FifoTopic": "true"})[
            "TopicArn"
        ]

        fifo_queue_url = sqs_create_queue(
            QueueName=fifo_queue_name, Attributes={"FifoQueue": "true"}
        )

        queue_url = sqs_create_queue(QueueName=queue_name)
        not_fifo_dlq_url = sqs_create_queue(QueueName=not_fifo_dlq_name)

        with pytest.raises(ClientError) as e:
            sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=fifo_queue_url)

        assert e.match("standard SNS topic")
        snapshot.match("not-fifo-topic", e.value.response)

        # SNS does not reject a regular SQS queue subscribed to a FIFO topic anymore
        subscription_not_fifo = sns_create_sqs_subscription(
            topic_arn=fifo_topic_arn, queue_url=queue_url
        )
        snapshot.match("not-fifo-queue", subscription_not_fifo)

        not_fifo_queue_arn = sqs_get_queue_arn(not_fifo_dlq_url)
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_not_fifo["SubscriptionArn"],
            AttributeName="RedrivePolicy",
            AttributeValue=json.dumps({"deadLetterTargetArn": not_fifo_queue_arn}),
        )

        subscription = sns_create_sqs_subscription(
            topic_arn=fifo_topic_arn, queue_url=fifo_queue_url
        )
        queue_arn = sqs_get_queue_arn(queue_url)

        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription["SubscriptionArn"],
                AttributeName="RedrivePolicy",
                AttributeValue=json.dumps({"deadLetterTargetArn": queue_arn}),
            )
        snapshot.match("regular-queue-for-dlq-of-fifo-topic", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(TopicArn=fifo_topic_arn, Message="test")

        assert e.match("MessageGroupId")
        snapshot.match("no-msg-group-id", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(
                TopicArn=fifo_topic_arn, Message="test", MessageGroupId=short_uid()
            )
        # if ContentBasedDeduplication is not set at the topic level, it needs MessageDeduplicationId for each msg
        assert e.match("MessageDeduplicationId")
        assert e.match("ContentBasedDeduplication")
        snapshot.match("no-dedup-policy", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(
                TopicArn=topic_arn, Message="test", MessageDeduplicationId=short_uid()
            )
        assert e.match("MessageDeduplicationId")
        snapshot.match("no-msg-dedup-regular-topic", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(TopicArn=topic_arn, Message="test", MessageGroupId=short_uid())
        assert e.match("MessageGroupId")
        snapshot.match("no-msg-group-id-regular-topic", e.value.response)

    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.topic-attrs.Attributes.DeliveryPolicy",
            "$.topic-attrs.Attributes.EffectiveDeliveryPolicy",
            "$.topic-attrs.Attributes.Policy.Statement..Action",  # SNS:Receive is added by moto but not returned in AWS
        ]
    )
    @pytest.mark.parametrize("raw_message_delivery", [True, False])
    def test_publish_fifo_messages_to_dlq(
        self,
        sns_create_topic,
        sqs_create_queue,
        sqs_get_queue_arn,
        sns_create_sqs_subscription,
        sns_allow_topic_sqs_queue,
        snapshot,
        raw_message_delivery,
        aws_client,
    ):
        # the hash isn't the same because of the Binary attributes (maybe decoding order?)
        snapshot.add_transformer(
            snapshot.transform.key_value(
                "MD5OfMessageAttributes",
                value_replacement="<md5-hash>",
                reference_replacement=False,
            )
        )

        topic_name = f"topic-{short_uid()}.fifo"
        queue_name = f"queue-{short_uid()}.fifo"
        dlq_name = f"dlq-{short_uid()}.fifo"

        topic_arn = sns_create_topic(
            Name=topic_name,
            Attributes={"FifoTopic": "true"},
        )["TopicArn"]

        response = aws_client.sns.get_topic_attributes(TopicArn=topic_arn)
        snapshot.match("topic-attrs", response)

        queue_url = sqs_create_queue(
            QueueName=queue_name,
            Attributes={"FifoQueue": "true"},
        )

        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        if raw_message_delivery:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription_arn,
                AttributeName="RawMessageDelivery",
                AttributeValue="true",
            )

        dlq_url = sqs_create_queue(
            QueueName=dlq_name,
            Attributes={"FifoQueue": "true"},
        )
        dlq_arn = sqs_get_queue_arn(dlq_url)

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription["SubscriptionArn"],
            AttributeName="RedrivePolicy",
            AttributeValue=json.dumps({"deadLetterTargetArn": dlq_arn}),
        )

        sns_allow_topic_sqs_queue(
            sqs_queue_url=dlq_url,
            sqs_queue_arn=dlq_arn,
            sns_topic_arn=topic_arn,
        )

        aws_client.sqs.delete_queue(QueueUrl=queue_url)

        message_group_id = "complexMessageGroupId"
        publish_batch_request_entries = [
            {
                "Id": "1",
                "MessageGroupId": message_group_id,
                "Message": "Test Message with two attributes",
                "Subject": "Subject",
                "MessageAttributes": {
                    "attr1": {"DataType": "Number", "StringValue": "99.12"},
                    "attr2": {"DataType": "Number", "StringValue": "109.12"},
                },
                "MessageDeduplicationId": "MessageDeduplicationId-1",
            },
            {
                "Id": "2",
                "MessageGroupId": message_group_id,
                "Message": "Test Message with one attribute",
                "Subject": "Subject",
                "MessageAttributes": {"attr1": {"DataType": "Number", "StringValue": "19.12"}},
                "MessageDeduplicationId": "MessageDeduplicationId-2",
            },
            {
                "Id": "3",
                "MessageGroupId": message_group_id,
                "Message": "Test Message without attribute",
                "Subject": "Subject",
                "MessageDeduplicationId": "MessageDeduplicationId-3",
            },
        ]

        publish_batch_response = aws_client.sns.publish_batch(
            TopicArn=topic_arn,
            PublishBatchRequestEntries=publish_batch_request_entries,
        )

        snapshot.match("publish-batch-response-fifo", publish_batch_response)

        assert "Successful" in publish_batch_response
        assert "Failed" in publish_batch_response

        for successful_resp in publish_batch_response["Successful"]:
            assert "Id" in successful_resp
            assert "MessageId" in successful_resp

        message_ids_received = set()
        messages = []

        def get_messages_from_dlq(amount_msg: int):
            # due to the random nature of receiving SQS messages, we need to consolidate a single object to match
            # MaxNumberOfMessages could return less than 3 messages
            sqs_response = aws_client.sqs.receive_message(
                QueueUrl=dlq_url,
                MessageAttributeNames=["All"],
                AttributeNames=["All"],
                MaxNumberOfMessages=10,
                WaitTimeSeconds=1,
                VisibilityTimeout=1,
            )

            for message in sqs_response["Messages"]:
                LOG.debug("Message received %s", message)
                if message["MessageId"] in message_ids_received:
                    continue

                message_ids_received.add(message["MessageId"])
                messages.append(message)
                aws_client.sqs.delete_message(
                    QueueUrl=dlq_url, ReceiptHandle=message["ReceiptHandle"]
                )

            assert len(messages) == amount_msg

        retry(get_messages_from_dlq, retries=5, sleep=1, amount_msg=3)
        snapshot.match("batch-messages-in-dlq", {"Messages": messages})
        messages.clear()

        publish_response = aws_client.sns.publish(
            TopicArn=topic_arn,
            Message="test-message",
            MessageGroupId="message-group-id-1",
            MessageDeduplicationId="message-deduplication-id-1",
        )
        snapshot.match("publish-response-fifo", publish_response)
        retry(get_messages_from_dlq, retries=5, sleep=1, amount_msg=1)
        snapshot.match("messages-in-dlq", {"Messages": messages})

    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.topic-attrs.Attributes.DeliveryPolicy",
            "$.topic-attrs.Attributes.EffectiveDeliveryPolicy",
            "$.topic-attrs.Attributes.Policy.Statement..Action",  # SNS:Receive is added by moto but not returned in AWS
            "$.republish-batch-response-fifo.Successful..MessageId",  # TODO: SNS doesnt keep track of duplicate
            "$.republish-batch-response-fifo.Successful..SequenceNumber",  # TODO: SNS doesnt keep track of duplicate
        ]
    )
    @pytest.mark.parametrize("content_based_deduplication", [True, False])
    def test_publish_batch_messages_from_fifo_topic_to_fifo_queue(
        self,
        sns_create_topic,
        sqs_create_queue,
        sns_create_sqs_subscription,
        snapshot,
        content_based_deduplication,
        aws_client,
    ):
        topic_name = f"topic-{short_uid()}.fifo"
        queue_name = f"queue-{short_uid()}.fifo"
        topic_attributes = {"FifoTopic": "true"}
        queue_attributes = {"FifoQueue": "true"}
        if content_based_deduplication:
            topic_attributes["ContentBasedDeduplication"] = "true"
            queue_attributes["ContentBasedDeduplication"] = "true"

        topic_arn = sns_create_topic(
            Name=topic_name,
            Attributes=topic_attributes,
        )["TopicArn"]

        response = aws_client.sns.get_topic_attributes(TopicArn=topic_arn)
        snapshot.match("topic-attrs", response)

        queue_url = sqs_create_queue(
            QueueName=queue_name,
            Attributes=queue_attributes,
        )

        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="RawMessageDelivery",
            AttributeValue="true",
        )

        response = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        snapshot.match("sub-attrs-raw-true", response)
        message_group_id = "complexMessageGroupId"
        publish_batch_request_entries = [
            {
                "Id": "1",
                "MessageGroupId": message_group_id,
                "Message": "Test Message with two attributes",
                "Subject": "Subject",
                "MessageAttributes": {
                    "attr1": {"DataType": "Number", "StringValue": "99.12"},
                    "attr2": {"DataType": "Number", "StringValue": "109.12"},
                },
            },
            {
                "Id": "2",
                "MessageGroupId": message_group_id,
                "Message": "Test Message with one attribute",
                "Subject": "Subject",
                "MessageAttributes": {"attr1": {"DataType": "Number", "StringValue": "19.12"}},
            },
            {
                "Id": "3",
                "MessageGroupId": message_group_id,
                "Message": "Test Message without attribute",
                "Subject": "Subject",
            },
        ]

        if not content_based_deduplication:
            for index, message in enumerate(publish_batch_request_entries):
                message["MessageDeduplicationId"] = f"MessageDeduplicationId-{index}"

        publish_batch_response = aws_client.sns.publish_batch(
            TopicArn=topic_arn,
            PublishBatchRequestEntries=publish_batch_request_entries,
        )

        snapshot.match("publish-batch-response-fifo", publish_batch_response)

        assert "Successful" in publish_batch_response
        assert "Failed" in publish_batch_response

        for successful_resp in publish_batch_response["Successful"]:
            assert "Id" in successful_resp
            assert "MessageId" in successful_resp

        message_ids_received = set()
        messages = []

        def get_messages():
            # due to the random nature of receiving SQS messages, we need to consolidate a single object to match
            # MaxNumberOfMessages could return less than 3 messages
            sqs_response = aws_client.sqs.receive_message(
                QueueUrl=queue_url,
                MessageAttributeNames=["All"],
                AttributeNames=["All"],
                MaxNumberOfMessages=10,
                WaitTimeSeconds=1,
                VisibilityTimeout=10,
            )

            for _message in sqs_response["Messages"]:
                if _message["MessageId"] in message_ids_received:
                    continue

                message_ids_received.add(_message["MessageId"])
                messages.append(_message)
                aws_client.sqs.delete_message(
                    QueueUrl=queue_url, ReceiptHandle=_message["ReceiptHandle"]
                )

            assert len(messages) == 3

        retry(get_messages, retries=5, sleep=1)
        snapshot.match("messages", {"Messages": messages})

        publish_batch_response = aws_client.sns.publish_batch(
            TopicArn=topic_arn,
            PublishBatchRequestEntries=publish_batch_request_entries,
        )

        snapshot.match("republish-batch-response-fifo", publish_batch_response)
        get_deduplicated_messages = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            MessageAttributeNames=["All"],
            AttributeNames=["All"],
            MaxNumberOfMessages=10,
            WaitTimeSeconds=3,
            VisibilityTimeout=0,
        )
        # there should not be any messages here, as they are duplicate
        # see https://docs.aws.amazon.com/sns/latest/dg/fifo-message-dedup.html
        snapshot.match("duplicate-messages", get_deduplicated_messages)

    @markers.aws.validated
    @pytest.mark.parametrize("raw_message_delivery", [True, False])
    def test_publish_to_fifo_topic_to_sqs_queue_no_content_dedup(
        self,
        sns_create_topic,
        sqs_create_queue,
        sns_create_sqs_subscription,
        snapshot,
        raw_message_delivery,
        aws_client,
    ):
        topic_name = f"topic-{short_uid()}.fifo"
        queue_name = f"queue-{short_uid()}.fifo"
        topic_attributes = {"FifoTopic": "true", "ContentBasedDeduplication": "true"}
        queue_attributes = {"FifoQueue": "true"}

        topic_arn = sns_create_topic(
            Name=topic_name,
            Attributes=topic_attributes,
        )["TopicArn"]
        queue_url = sqs_create_queue(
            QueueName=queue_name,
            Attributes=queue_attributes,
        )

        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        if raw_message_delivery:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription["SubscriptionArn"],
                AttributeName="RawMessageDelivery",
                AttributeValue="true",
            )

        # Topic has ContentBasedDeduplication set to true, the queue should receive only one message
        # SNS will create a MessageDeduplicationId for the SQS queue, as it does not have ContentBasedDeduplication
        for _ in range(2):
            aws_client.sns.publish(
                TopicArn=topic_arn, Message="Test single", MessageGroupId="message-group-id-1"
            )
            aws_client.sns.publish_batch(
                TopicArn=topic_arn,
                PublishBatchRequestEntries=[
                    {
                        "Id": "1",
                        "MessageGroupId": "message-group-id-1",
                        "Message": "Test batched",
                    }
                ],
            )

        messages = []
        message_ids_received = set()

        def get_messages():
            # due to the random nature of receiving SQS messages, we need to consolidate a single object to match
            # MaxNumberOfMessages could return less than 2 messages
            sqs_response = aws_client.sqs.receive_message(
                QueueUrl=queue_url,
                MessageAttributeNames=["All"],
                AttributeNames=["All"],
                MaxNumberOfMessages=10,
                WaitTimeSeconds=1,
                VisibilityTimeout=10,
            )

            for message in sqs_response["Messages"]:
                if message["MessageId"] in message_ids_received:
                    continue

                message_ids_received.add(message["MessageId"])
                messages.append(message)
                aws_client.sqs.delete_message(
                    QueueUrl=queue_url, ReceiptHandle=message["ReceiptHandle"]
                )

            assert len(messages) == 2

        retry(get_messages, retries=5, sleep=1)
        messages.sort(key=lambda x: x["Attributes"]["MessageDeduplicationId"])
        snapshot.match("messages", {"Messages": messages})

    @markers.aws.validated
    def test_publish_to_fifo_topic_deduplication_on_topic_level(
        self,
        sns_create_topic,
        sqs_create_queue,
        sns_create_sqs_subscription,
        snapshot,
        aws_client,
    ):
        topic_name = f"topic-{short_uid()}.fifo"
        queue_name = f"queue-{short_uid()}.fifo"
        topic_attributes = {"FifoTopic": "true", "ContentBasedDeduplication": "true"}
        queue_attributes = {"FifoQueue": "true"}

        topic_arn = sns_create_topic(
            Name=topic_name,
            Attributes=topic_attributes,
        )["TopicArn"]
        queue_url = sqs_create_queue(
            QueueName=queue_name,
            Attributes=queue_attributes,
        )

        sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)

        # TODO: for message deduplication, we are using the underlying features of the SQS queue
        # however, SQS queue only deduplicate at the Queue level, where the SNS topic deduplicate on the topic level
        # we will need to implement this
        # TODO: add a test with 2 subscriptions and a filter, to validate deduplication at topic level
        message = "Test"
        aws_client.sns.publish(
            TopicArn=topic_arn, Message=message, MessageGroupId="message-group-id-1"
        )
        time.sleep(
            0.5
        )  # this is to ensure order of arrival, because we do not deduplicate at SNS level yet
        aws_client.sns.publish(
            TopicArn=topic_arn, Message=message, MessageGroupId="message-group-id-2"
        )

        # get the deduplicated message and delete it
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            VisibilityTimeout=10,
            WaitTimeSeconds=10,
            AttributeNames=["All"],
        )
        snapshot.match("messages", response)
        aws_client.sqs.delete_message(
            QueueUrl=queue_url, ReceiptHandle=response["Messages"][0]["ReceiptHandle"]
        )
        # assert there are no more messages in the queue
        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url,
            VisibilityTimeout=10,
            WaitTimeSeconds=1,
            AttributeNames=["All"],
        )
        snapshot.match("dedup-messages", response)

    @markers.aws.validated
    def test_publish_to_fifo_with_target_arn(self, sns_create_topic, aws_client):
        topic_name = f"topic-{short_uid()}.fifo"
        topic_attributes = {
            "FifoTopic": "true",
            "ContentBasedDeduplication": "true",
        }

        topic_arn = sns_create_topic(
            Name=topic_name,
            Attributes=topic_attributes,
        )["TopicArn"]

        message = {"foo": "bar"}
        response = aws_client.sns.publish(
            TargetArn=topic_arn,
            Message=json.dumps({"default": json.dumps(message)}),
            MessageStructure="json",
            MessageGroupId="123",
        )
        assert "MessageId" in response


class TestSNSSubscriptionSES:
    @markers.aws.only_localstack
    def test_topic_email_subscription_confirmation(
        self, sns_create_topic, sns_subscription, aws_client
    ):
        # FIXME: we do not send the token to the email endpoint, so they cannot validate it
        # create AWS validated test for format
        # for now, access internals
        topic_arn = sns_create_topic()["TopicArn"]
        subscription = sns_subscription(
            TopicArn=topic_arn,
            Protocol="email",
            Endpoint="localstack@yopmail.com",
        )
        subscription_arn = subscription["SubscriptionArn"]
        parsed_arn = parse_arn(subscription_arn)
        store = SnsProvider.get_store(parsed_arn["account"], parsed_arn["region"])

        sub_attr = aws_client.sns.get_subscription_attributes(SubscriptionArn=subscription_arn)
        assert sub_attr["Attributes"]["PendingConfirmation"] == "true"

        def check_subscription():
            for token, sub_arn in store.subscription_tokens.items():
                if sub_arn == subscription_arn:
                    aws_client.sns.confirm_subscription(TopicArn=topic_arn, Token=token)

            sub_attributes = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=subscription_arn
            )
            assert sub_attributes["Attributes"]["PendingConfirmation"] == "false"

        retry(check_subscription, retries=PUBLICATION_RETRIES, sleep=PUBLICATION_TIMEOUT)


class TestSNSFilter:
    @markers.aws.validated
    def test_filter_policy(
        self, sqs_create_queue, sns_create_topic, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        filter_policy = {"attr1": [{"numeric": [">", 0, "<=", 100]}]}
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=json.dumps(filter_policy),
        )

        response_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("subscription-attributes", response_attributes)

        response_0 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=1
        )
        snapshot.match("messages-0", response_0)
        # get number of messages
        num_msgs_0 = len(response_0.get("Messages", []))

        # publish message that satisfies the filter policy, assert that message is received
        message = "This is a test message"
        message_attributes = {"attr1": {"DataType": "Number", "StringValue": "99"}}
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageAttributes=message_attributes,
        )

        response_1 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )
        snapshot.match("messages-1", response_1)

        num_msgs_1 = len(response_1["Messages"])
        assert num_msgs_1 == (num_msgs_0 + 1)

        # publish message that does not satisfy the filter policy, assert that message is not received
        message = "This is another test message"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageAttributes={"attr1": {"DataType": "Number", "StringValue": "111"}},
        )

        response_2 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )
        snapshot.match("messages-2", response_2)
        num_msgs_2 = len(response_2["Messages"])
        assert num_msgs_2 == num_msgs_1

        # remove all messages from the queue
        receipt_handle = response_1["Messages"][0]["ReceiptHandle"]
        aws_client.sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt_handle)

        # test with a property value set to null with an OR operator with anything-but
        filter_policy = json.dumps({"attr1": [None, {"anything-but": "whatever"}]})
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=filter_policy,
        )

        def get_filter_policy():
            subscription_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=subscription_arn
            )
            return subscription_attrs["Attributes"]["FilterPolicy"]

        # wait for the new filter policy to be in effect
        poll_condition(lambda: get_filter_policy() == filter_policy, timeout=4)
        response_attributes_2 = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("subscription-attributes-2", response_attributes_2)

        # publish message that does not satisfy the filter policy, assert that message is not received
        message = "This the test message for null"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
        )

        response_3 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )
        snapshot.match("messages-3", response_3)
        assert "Messages" not in response_3

    @markers.aws.validated
    def test_exists_filter_policy(
        self, sqs_create_queue, sns_create_topic, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        filter_policy = {"store": [{"exists": True}]}
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=json.dumps(filter_policy),
        )

        response_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("subscription-attributes-policy-1", response_attributes)

        response_0 = aws_client.sqs.receive_message(QueueUrl=queue_url, VisibilityTimeout=0)
        snapshot.match("messages-0", response_0)
        # get number of messages
        num_msgs_0 = len(response_0.get("Messages", []))

        # publish message that satisfies the filter policy, assert that message is received
        message_1 = "message-1"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message_1,
            MessageAttributes={
                "store": {"DataType": "Number", "StringValue": "99"},
                "def": {"DataType": "Number", "StringValue": "99"},
            },
        )
        response_1 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )
        snapshot.match("messages-1", response_1)
        num_msgs_1 = len(response_1["Messages"])
        assert num_msgs_1 == (num_msgs_0 + 1)

        # publish message that does not satisfy the filter policy, assert that message is not received
        message_2 = "message-2"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message_2,
            MessageAttributes={"attr1": {"DataType": "Number", "StringValue": "111"}},
        )

        response_2 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )
        snapshot.match("messages-2", response_2)
        num_msgs_2 = len(response_2["Messages"])
        assert num_msgs_2 == num_msgs_1

        # delete first message
        aws_client.sqs.delete_message(
            QueueUrl=queue_url, ReceiptHandle=response_1["Messages"][0]["ReceiptHandle"]
        )

        # test with exist operator set to false.
        filter_policy = json.dumps({"store": [{"exists": False}]})
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=filter_policy,
        )

        def get_filter_policy():
            subscription_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=subscription_arn
            )
            return subscription_attrs["Attributes"]["FilterPolicy"]

        # wait for the new filter policy to be in effect
        poll_condition(lambda: get_filter_policy() == filter_policy, timeout=4)
        response_attributes_2 = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("subscription-attributes-policy-2", response_attributes_2)

        # publish message that satisfies the filter policy, assert that message is received
        message_3 = "message-3"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message_3,
            MessageAttributes={"def": {"DataType": "Number", "StringValue": "99"}},
        )

        response_3 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )
        snapshot.match("messages-3", response_3)
        num_msgs_3 = len(response_3["Messages"])
        assert num_msgs_3 == num_msgs_1

        # publish message that does not satisfy the filter policy, assert that message is not received
        message_4 = "message-4"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message_4,
            MessageAttributes={
                "store": {"DataType": "Number", "StringValue": "99"},
                "def": {"DataType": "Number", "StringValue": "99"},
            },
        )

        response_4 = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=4
        )
        snapshot.match("messages-4", response_4)
        num_msgs_4 = len(response_4["Messages"])
        assert num_msgs_4 == num_msgs_3

    @markers.aws.validated
    def test_set_subscription_filter_policy_scope(
        self, sqs_create_queue, sns_create_topic, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        # we fetch the default subscription attributes
        # note: the FilterPolicyScope is not present in the response
        subscription_attrs = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("sub-attrs-default", subscription_attrs)

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicyScope",
            AttributeValue="MessageBody",
        )

        # we fetch the subscription attributes after setting the FilterPolicyScope
        # note: the FilterPolicyScope is still not present in the response
        subscription_attrs = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("sub-attrs-filter-scope-body", subscription_attrs)

        # we try to set random values to the FilterPolicyScope
        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription_arn,
                AttributeName="FilterPolicyScope",
                AttributeValue="RandomValue",
            )

        snapshot.match("sub-attrs-filter-scope-error", e.value.response)

        # we try to set a FilterPolicy to see if it will show the FilterPolicyScope in the attributes
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=json.dumps({"attr": ["match-this"]}),
        )
        # the FilterPolicyScope is now present in the attributes
        subscription_attrs = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("sub-attrs-after-setting-policy", subscription_attrs)

    @markers.aws.validated
    def test_sub_filter_policy_nested_property(
        self, sqs_create_queue, sns_create_topic, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        # see https://aws.amazon.com/blogs/compute/introducing-payload-based-message-filtering-for-amazon-sns/
        nested_filter_policy = {"object": {"key": [{"prefix": "auto-"}]}}
        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription_arn,
                AttributeName="FilterPolicy",
                AttributeValue=json.dumps(nested_filter_policy),
            )
        snapshot.match("sub-filter-policy-nested-error", e.value.response)

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicyScope",
            AttributeValue="MessageBody",
        )

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=json.dumps(nested_filter_policy),
        )

        # the FilterPolicyScope is now present in the attributes
        subscription_attrs = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        snapshot.match("sub-attrs-after-setting-nested-policy", subscription_attrs)

    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.sub-filter-policy-rule-no-list.Error.Message",  # message contains java trace in AWS, assert instead
        ]
    )
    def test_sub_filter_policy_nested_property_constraints(
        self, sqs_create_queue, sns_create_topic, sns_create_sqs_subscription, snapshot, aws_client
    ):
        # https://docs.aws.amazon.com/sns/latest/dg/subscription-filter-policy-constraints.html
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicyScope",
            AttributeValue="MessageBody",
        )

        nested_filter_policy = {
            "key_a": {
                "key_b": {"key_c": ["value_one", "value_two", "value_three", "value_four"]},
            },
            "key_d": {"key_e": ["value_one", "value_two", "value_three"]},
            "key_f": ["value_one", "value_two", "value_three"],
        }
        # The first array has four values in a three-level nested key, and the second has three values in a two-level
        # nested key. The total combination is calculated as follows:
        # 3 x 4 x 2 x 3 x 1 x 3 = 216
        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription_arn,
                AttributeName="FilterPolicy",
                AttributeValue=json.dumps(nested_filter_policy),
            )
        snapshot.match("sub-filter-policy-nested-error-too-many-combinations", e.value.response)

        flat_filter_policy = {
            "key_a": ["value_one"],
            "key_b": ["value_two"],
            "key_c": ["value_three"],
            "key_d": ["value_four"],
            "key_e": ["value_five"],
            "key_f": ["value_six"],
        }
        # A filter policy can have a maximum of five attribute names. For a nested policy, only parent keys are counted.
        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription_arn,
                AttributeName="FilterPolicy",
                AttributeValue=json.dumps(flat_filter_policy),
            )
        snapshot.match("sub-filter-policy-max-attr-keys", e.value.response)

        flat_filter_policy = {"key_a": "value_one"}
        # Rules should be contained in a list
        with pytest.raises(ClientError) as e:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription_arn,
                AttributeName="FilterPolicy",
                AttributeValue=json.dumps(flat_filter_policy),
            )
        snapshot.match("sub-filter-policy-rule-no-list", e.value.response)
        assert e.value.response["Error"]["Message"].startswith(
            'Invalid parameter: FilterPolicy: "key_a" must be an object or an array'
        )

    @markers.aws.validated
    @pytest.mark.parametrize("raw_message_delivery", [True, False])
    def test_filter_policy_on_message_body(
        self,
        sqs_create_queue,
        sns_create_topic,
        sns_create_sqs_subscription,
        snapshot,
        raw_message_delivery,
        aws_client,
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]
        # see https://aws.amazon.com/blogs/compute/introducing-payload-based-message-filtering-for-amazon-sns/
        nested_filter_policy = {
            "object": {
                "key": [{"prefix": "auto-"}, "hardcodedvalue"],
                "nested_key": [{"exists": False}],
            },
            "test": [{"exists": False}],
        }

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicyScope",
            AttributeValue="MessageBody",
        )

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=json.dumps(nested_filter_policy),
        )

        if raw_message_delivery:
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription_arn,
                AttributeName="RawMessageDelivery",
                AttributeValue="true",
            )

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=1
        )
        snapshot.match("recv-init", response)
        # assert there are no messages in the queue
        assert "Messages" not in response

        # publish messages that satisfies the filter policy, assert that messages are received
        messages = [
            {"object": {"key": "auto-test"}},
            {"object": {"key": "hardcodedvalue"}},
        ]
        for i, message in enumerate(messages):
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message=json.dumps(message),
            )

            response = aws_client.sqs.receive_message(
                QueueUrl=queue_url,
                VisibilityTimeout=0,
                WaitTimeSeconds=5 if is_aws_cloud() else 2,
            )
            snapshot.match(f"recv-passed-msg-{i}", response)
            receipt_handle = response["Messages"][0]["ReceiptHandle"]
            aws_client.sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt_handle)

        # publish messages that do not satisfy the filter policy, assert those messages are not received
        messages = [
            {"object": {"key": "test-auto"}},
            {"object": {"key": "auto-test"}, "test": "just-exists"},
            {"object": {"key": "auto-test", "nested_key": "just-exists"}},
            {"object": {"test": "auto-test"}},
            {"test": "auto-test"},
        ]
        for message in messages:
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message=json.dumps(message),
            )

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=5 if is_aws_cloud() else 2
        )
        # assert there are no messages in the queue
        assert "Messages" not in response

        # publish message that does not satisfy the filter policy as it's not even JSON, or not a JSON object
        message = "Regular string message"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
        )
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=json.dumps(message),  # send it JSON encoded, but not an object
        )

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=2
        )
        # assert there are no messages in the queue
        assert "Messages" not in response

    @markers.aws.validated
    def test_filter_policy_for_batch(
        self, sqs_create_queue, sns_create_topic, sns_create_sqs_subscription, snapshot, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url_with_filter = sqs_create_queue()
        subscription_with_filter = sns_create_sqs_subscription(
            topic_arn=topic_arn, queue_url=queue_url_with_filter
        )
        subscription_with_filter_arn = subscription_with_filter["SubscriptionArn"]

        queue_url_no_filter = sqs_create_queue()
        subscription_no_filter = sns_create_sqs_subscription(
            topic_arn=topic_arn, queue_url=queue_url_no_filter
        )
        subscription_no_filter_arn = subscription_no_filter["SubscriptionArn"]

        filter_policy = {"attr1": [{"numeric": [">", 0, "<=", 100]}]}
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_with_filter_arn,
            AttributeName="FilterPolicy",
            AttributeValue=json.dumps(filter_policy),
        )

        response_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_with_filter_arn
        )
        snapshot.match("subscription-attributes-with-filter", response_attributes)

        response_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_no_filter_arn
        )
        snapshot.match("subscription-attributes-no-filter", response_attributes)

        sqs_wait_time = 4 if is_aws_cloud() else 1

        response_before_publish_no_filter = aws_client.sqs.receive_message(
            QueueUrl=queue_url_with_filter, VisibilityTimeout=0, WaitTimeSeconds=sqs_wait_time
        )
        snapshot.match("messages-no-filter-before-publish", response_before_publish_no_filter)

        response_before_publish_filter = aws_client.sqs.receive_message(
            QueueUrl=queue_url_with_filter, VisibilityTimeout=0, WaitTimeSeconds=sqs_wait_time
        )
        snapshot.match("messages-with-filter-before-publish", response_before_publish_filter)

        # publish message that satisfies the filter policy, assert that message is received
        message = "This is a test message"
        message_attributes = {"attr1": {"DataType": "Number", "StringValue": "99"}}
        aws_client.sns.publish_batch(
            TopicArn=topic_arn,
            PublishBatchRequestEntries=[
                {
                    "Id": "1",
                    "Message": message,
                    "MessageAttributes": message_attributes,
                }
            ],
        )

        response_after_publish_no_filter = aws_client.sqs.receive_message(
            QueueUrl=queue_url_no_filter, VisibilityTimeout=0, WaitTimeSeconds=sqs_wait_time
        )
        snapshot.match("messages-no-filter-after-publish-ok", response_after_publish_no_filter)
        aws_client.sqs.delete_message(
            QueueUrl=queue_url_no_filter,
            ReceiptHandle=response_after_publish_no_filter["Messages"][0]["ReceiptHandle"],
        )

        response_after_publish_filter = aws_client.sqs.receive_message(
            QueueUrl=queue_url_with_filter, VisibilityTimeout=0, WaitTimeSeconds=sqs_wait_time
        )
        snapshot.match("messages-with-filter-after-publish-ok", response_after_publish_filter)
        aws_client.sqs.delete_message(
            QueueUrl=queue_url_with_filter,
            ReceiptHandle=response_after_publish_filter["Messages"][0]["ReceiptHandle"],
        )

        # publish message that does not satisfy the filter policy, assert that message is not received by the
        # subscription with the filter and received by the other
        aws_client.sns.publish_batch(
            TopicArn=topic_arn,
            PublishBatchRequestEntries=[
                {
                    "Id": "1",
                    "Message": "This is another test message",
                    "MessageAttributes": {"attr1": {"DataType": "Number", "StringValue": "111"}},
                }
            ],
        )

        response_after_publish_no_filter = aws_client.sqs.receive_message(
            QueueUrl=queue_url_no_filter, VisibilityTimeout=0, WaitTimeSeconds=sqs_wait_time
        )
        # there should be 1 message in the queue, latest sent
        snapshot.match("messages-no-filter-after-publish-ok-1", response_after_publish_no_filter)

        response_after_publish_filter = aws_client.sqs.receive_message(
            QueueUrl=queue_url_with_filter, VisibilityTimeout=0, WaitTimeSeconds=sqs_wait_time
        )
        # there should be no messages in this queue
        snapshot.match("messages-with-filter-after-publish-filtered", response_after_publish_filter)

    @markers.aws.validated
    def test_filter_policy_on_message_body_dot_attribute(
        self,
        sqs_create_queue,
        sns_create_topic,
        sns_create_sqs_subscription,
        snapshot,
        aws_client,
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        queue_url = sqs_create_queue()
        subscription = sns_create_sqs_subscription(topic_arn=topic_arn, queue_url=queue_url)
        subscription_arn = subscription["SubscriptionArn"]

        nested_filter_policy = json.dumps(
            {
                "object.nested": ["string.value"],
            }
        )

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicyScope",
            AttributeValue="MessageBody",
        )

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=nested_filter_policy,
        )

        def get_filter_policy():
            subscription_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=subscription_arn
            )
            return subscription_attrs["Attributes"]["FilterPolicy"]

        # wait for the new filter policy to be in effect
        poll_condition(lambda: get_filter_policy() == nested_filter_policy, timeout=4)

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=1
        )
        snapshot.match("recv-init", response)
        # assert there are no messages in the queue
        assert "Messages" not in response

        def _verify_and_snapshot_sqs_messages(msg_to_send: list[dict], snapshot_prefix: str):
            for i, _message in enumerate(msg_to_send):
                aws_client.sns.publish(
                    TopicArn=topic_arn,
                    Message=json.dumps(_message),
                )

                _response = aws_client.sqs.receive_message(
                    QueueUrl=queue_url,
                    VisibilityTimeout=0,
                    WaitTimeSeconds=5 if is_aws_cloud() else 2,
                )
                snapshot.match(f"{snapshot_prefix}-{i}", _response)
                receipt_handle = _response["Messages"][0]["ReceiptHandle"]
                aws_client.sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt_handle)

        # publish messages that satisfies the filter policy, assert that messages are received
        messages = [
            {"object": {"nested": "string.value"}},
            {"object.nested": "string.value"},
        ]
        _verify_and_snapshot_sqs_messages(messages, snapshot_prefix="recv-nested-msg")

        # publish messages that do not satisfy the filter policy, assert those messages are not received
        messages = [
            {"object": {"nested": "test-auto"}},
        ]
        for message in messages:
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message=json.dumps(message),
            )

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=5 if is_aws_cloud() else 2
        )
        # assert there are no messages in the queue
        assert "Messages" not in response

        # assert with more nesting
        deep_nested_filter_policy = json.dumps(
            {
                "object.nested.test": ["string.value"],
            }
        )

        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=subscription_arn,
            AttributeName="FilterPolicy",
            AttributeValue=deep_nested_filter_policy,
        )
        # wait for the new filter policy to be in effect
        poll_condition(lambda: get_filter_policy() == deep_nested_filter_policy, timeout=4)

        messages = [
            {"object": {"nested": {"test": "string.value"}}},
            {"object.nested.test": "string.value"},
            {"object.nested": {"test": "string.value"}},
            {"object": {"nested.test": "string.value"}},
        ]
        _verify_and_snapshot_sqs_messages(messages, snapshot_prefix="recv-deep-nested-msg")
        # publish messages that do not satisfy the filter policy, assert those messages are not received
        messages = [
            {"object": {"nested": {"test": "string.notvalue"}}},
        ]
        for message in messages:
            aws_client.sns.publish(
                TopicArn=topic_arn,
                Message=json.dumps(message),
            )

        response = aws_client.sqs.receive_message(
            QueueUrl=queue_url, VisibilityTimeout=0, WaitTimeSeconds=5 if is_aws_cloud() else 2
        )
        # assert there are no messages in the queue
        assert "Messages" not in response


class TestSNSPlatformEndpoint:
    @markers.aws.only_localstack
    def test_subscribe_platform_endpoint(
        self, sns_create_topic, sns_subscription, sns_create_platform_application, aws_client
    ):
        sns_backend = SnsProvider.get_store(TEST_AWS_ACCOUNT_ID, TEST_AWS_REGION_NAME)
        topic_arn = sns_create_topic()["TopicArn"]

        app_arn = sns_create_platform_application(Name="app1", Platform="p1", Attributes={})[
            "PlatformApplicationArn"
        ]
        platform_arn = aws_client.sns.create_platform_endpoint(
            PlatformApplicationArn=app_arn, Token="token_1"
        )["EndpointArn"]

        # create subscription with filter policy
        filter_policy = {"attr1": [{"numeric": [">", 0, "<=", 100]}]}
        sns_subscription(
            TopicArn=topic_arn,
            Protocol="application",
            Endpoint=platform_arn,
            Attributes={"FilterPolicy": json.dumps(filter_policy)},
        )
        # publish message that satisfies the filter policy
        message = "This is a test message"
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message,
            MessageAttributes={"attr1": {"DataType": "Number", "StringValue": "99.12"}},
        )

        # assert that message has been received
        def check_message():
            assert len(sns_backend.platform_endpoint_messages[platform_arn]) > 0

        retry(check_message, retries=PUBLICATION_RETRIES, sleep=PUBLICATION_TIMEOUT)

    @markers.aws.needs_fixing
    # AWS validating this is hard because we need real credentials for a GCM/Apple mobile app
    # Error responses are from reported https://github.com/spulec/moto/issues/2333
    def test_create_platform_endpoint_check_idempotency(
        self, sns_create_platform_application, aws_client
    ):
        response = sns_create_platform_application(
            Name=f"test-{short_uid()}",
            Platform="GCM",
            Attributes={"PlatformCredential": "123"},
        )
        token = "test1"
        kwargs_list = [
            {"Token": token, "CustomUserData": "test-data"},
            {"Token": token, "CustomUserData": "test-data"},
            {"Token": token},
            {"Token": token},
        ]
        platform_arn = response["PlatformApplicationArn"]
        responses = []
        for kwargs in kwargs_list:
            responses.append(
                aws_client.sns.create_platform_endpoint(
                    PlatformApplicationArn=platform_arn, **kwargs
                )
            )
        # Assert EndpointArn is returned in every call create platform call
        assert all("EndpointArn" in response for response in responses)
        endpoint_arn = responses[0]["EndpointArn"]

        with pytest.raises(ClientError) as e:
            aws_client.sns.create_platform_endpoint(
                PlatformApplicationArn=platform_arn,
                Token=token,
                CustomUserData="different-user-data",
            )
        assert e.value.response["Error"]["Code"] == "InvalidParameter"
        assert (
            e.value.response["Error"]["Message"]
            == f"Endpoint {endpoint_arn} already exists with the same Token, but different attributes."
        )

    @markers.aws.needs_fixing
    # AWS validating this is hard because we need real credentials for a GCM/Apple mobile app
    def test_publish_disabled_endpoint(self, sns_create_platform_application, aws_client):
        response = sns_create_platform_application(
            Name=f"test-{short_uid()}",
            Platform="GCM",
            Attributes={"PlatformCredential": "123"},
        )
        platform_arn = response["PlatformApplicationArn"]
        response = aws_client.sns.create_platform_endpoint(
            PlatformApplicationArn=platform_arn,
            Token="test1",
        )
        endpoint_arn = response["EndpointArn"]

        get_attrs = aws_client.sns.get_endpoint_attributes(EndpointArn=endpoint_arn)
        assert get_attrs["Attributes"]["Enabled"] == "true"

        aws_client.sns.set_endpoint_attributes(
            EndpointArn=endpoint_arn, Attributes={"Enabled": "false"}
        )

        get_attrs = aws_client.sns.get_endpoint_attributes(EndpointArn=endpoint_arn)
        assert get_attrs["Attributes"]["Enabled"] == "false"

        with pytest.raises(ClientError) as e:
            message = {
                "GCM": '{ "notification": {"title": "Title of notification", "body": "It works" } }'
            }
            aws_client.sns.publish(
                TargetArn=endpoint_arn, MessageStructure="json", Message=json.dumps(message)
            )

        assert e.value.response["Error"]["Code"] == "EndpointDisabled"
        assert e.value.response["Error"]["Message"] == "Endpoint is disabled"

    @markers.aws.only_localstack  # needs real credentials for GCM/FCM
    @pytest.mark.xfail(reason="Need to implement credentials validation when creating platform")
    def test_publish_to_gcm(self, sns_create_platform_application, aws_client):
        key = "mock_server_key"
        token = "mock_token"

        response = sns_create_platform_application(
            Name="firebase", Platform="GCM", Attributes={"PlatformCredential": key}
        )

        platform_app_arn = response["PlatformApplicationArn"]

        response = aws_client.sns.create_platform_endpoint(
            PlatformApplicationArn=platform_app_arn,
            Token=token,
        )
        endpoint_arn = response["EndpointArn"]

        message = {
            "GCM": '{ "notification": {"title": "Title of notification", "body": "It works" } }'
        }

        with pytest.raises(ClientError) as ex:
            aws_client.sns.publish(
                TargetArn=endpoint_arn, MessageStructure="json", Message=json.dumps(message)
            )
        assert ex.value.response["Error"]["Code"] == "InvalidParameter"

    @markers.aws.only_localstack
    def test_publish_to_platform_endpoint_is_dispatched(
        self, sns_create_topic, sns_subscription, sns_create_platform_application, aws_client
    ):
        topic_arn = sns_create_topic()["TopicArn"]
        endpoints_arn = {}
        for platform_type in ["APNS", "GCM"]:
            application_platform_name = f"app-platform-{platform_type}-{short_uid()}"

            # Create an Apple platform application
            app_arn = sns_create_platform_application(
                Name=application_platform_name, Platform=platform_type, Attributes={}
            )["PlatformApplicationArn"]

            endpoint_arn = aws_client.sns.create_platform_endpoint(
                PlatformApplicationArn=app_arn, Token=short_uid()
            )["EndpointArn"]

            # store the endpoint for checking results
            endpoints_arn[platform_type] = endpoint_arn

            # subscribe this endpoint to a topic
            sns_subscription(
                TopicArn=topic_arn,
                Protocol="application",
                Endpoint=endpoint_arn,
            )

        # now we have two platform endpoints subscribed to the same topic
        message = {
            "default": "This is the default message which must be present when publishing a message to a topic.",
            "APNS": '{"aps":{"alert": "Check out these awesome deals!","url":"www.amazon.com"} }',
            "GCM": '{"data":{"message":"Check out these awesome deals!","url":"www.amazon.com"}}',
        }

        # publish to the topic
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=json.dumps(message),
            MessageStructure="json",
        )

        sns_backend = SnsProvider.get_store(TEST_AWS_ACCOUNT_ID, TEST_AWS_REGION_NAME)
        platform_endpoint_msgs = sns_backend.platform_endpoint_messages

        # assert that message has been received
        def check_message():
            assert len(platform_endpoint_msgs[endpoint_arn]) > 0

        retry(check_message, retries=PUBLICATION_RETRIES, sleep=PUBLICATION_TIMEOUT)

        # each endpoint should only receive the message that was directed to them
        assert platform_endpoint_msgs[endpoints_arn["GCM"]][0]["Message"] == message["GCM"]
        assert platform_endpoint_msgs[endpoints_arn["APNS"]][0]["Message"] == message["APNS"]


class TestSNSSMS:
    @markers.aws.only_localstack
    def test_publish_sms(self, aws_client):
        phone_number = "+33000000000"
        response = aws_client.sns.publish(PhoneNumber=phone_number, Message="This is a SMS")
        assert "MessageId" in response
        assert response["ResponseMetadata"]["HTTPStatusCode"] == 200

        sns_backend = SnsProvider.get_store(
            account_id=TEST_AWS_ACCOUNT_ID,
            region_name=TEST_AWS_REGION_NAME,
        )

        def check_messages():
            sms_was_found = False
            for message in sns_backend.sms_messages:
                if message["PhoneNumber"] == phone_number:
                    sms_was_found = True
                    break

            assert sms_was_found

        retry(check_messages, sleep=0.5)

    @markers.aws.validated
    def test_subscribe_sms_endpoint(self, sns_create_topic, sns_subscription, snapshot, aws_client):
        phone_number = "+123123123"
        topic_arn = sns_create_topic()["TopicArn"]
        response = sns_subscription(TopicArn=topic_arn, Protocol="sms", Endpoint=phone_number)
        snapshot.match("subscribe-sms-endpoint", response)

        sub_attrs = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=response["SubscriptionArn"]
        )
        snapshot.match("subscribe-sms-attrs", sub_attrs)

    @markers.aws.only_localstack
    def test_publish_sms_endpoint(self, sns_create_topic, sns_subscription, aws_client):
        list_of_contacts = [
            f"+{random.randint(100000000, 9999999999)}",
            f"+{random.randint(100000000, 9999999999)}",
            f"+{random.randint(100000000, 9999999999)}",
        ]
        message = "Good news everyone!"
        topic_arn = sns_create_topic()["TopicArn"]
        for number in list_of_contacts:
            sns_subscription(TopicArn=topic_arn, Protocol="sms", Endpoint=number)

        aws_client.sns.publish(Message=message, TopicArn=topic_arn)

        sns_backend = SnsProvider.get_store(TEST_AWS_ACCOUNT_ID, TEST_AWS_REGION_NAME)

        def check_messages():
            sms_messages = sns_backend.sms_messages
            for contact in list_of_contacts:
                sms_was_found = False
                for _message in sms_messages:
                    if _message["PhoneNumber"] == contact:
                        sms_was_found = True
                        break

                assert sms_was_found

        retry(check_messages, sleep=0.5)

    @markers.aws.validated
    def test_publish_wrong_phone_format(
        self, sns_create_topic, sns_subscription, snapshot, aws_client
    ):
        message = "Good news everyone!"
        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(Message=message, PhoneNumber="+1a234")

        snapshot.match("invalid-number", e.value.response)

        with pytest.raises(ClientError) as e:
            aws_client.sns.publish(Message=message, PhoneNumber="NAA+15551234567")

        snapshot.match("wrong-format", e.value.response)

        topic_arn = sns_create_topic()["TopicArn"]
        with pytest.raises(ClientError) as e:
            sns_subscription(TopicArn=topic_arn, Protocol="sms", Endpoint="NAA+15551234567")
        snapshot.match("wrong-endpoint", e.value.response)


class TestSNSSubscriptionHttp:
    @markers.aws.manual_setup_required
    def test_redrive_policy_http_subscription(
        self, sns_create_topic, sqs_create_queue, sqs_get_queue_arn, sns_subscription, aws_client
    ):
        dlq_name = f"dlq-{short_uid()}"
        dlq_url = sqs_create_queue(QueueName=dlq_name)
        dlq_arn = sqs_get_queue_arn(dlq_url)
        topic_arn = sns_create_topic()["TopicArn"]

        # create HTTP endpoint and connect it to SNS topic
        with HTTPServer() as server:
            server.expect_request("/subscription").respond_with_data(b"", 200)
            http_endpoint = server.url_for("/subscription")
            wait_for_port_open(server.port)

            subscription = sns_subscription(
                TopicArn=topic_arn, Protocol="http", Endpoint=http_endpoint
            )
            aws_client.sns.set_subscription_attributes(
                SubscriptionArn=subscription["SubscriptionArn"],
                AttributeName="RedrivePolicy",
                AttributeValue=json.dumps({"deadLetterTargetArn": dlq_arn}),
            )

            # wait for subscription notification to arrive at http endpoint
            poll_condition(lambda: len(server.log) >= 1, timeout=10)
            request, _ = server.log[0]
            event = request.get_json(force=True)
            assert request.path.endswith("/subscription")
            assert event["Type"] == "SubscriptionConfirmation"
            assert event["TopicArn"] == topic_arn
            aws_client.sns.confirm_subscription(TopicArn=topic_arn, Token=event["Token"])

        wait_for_port_closed(server.port)

        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=json.dumps({"message": "test_redrive_policy"}),
        )

        response = aws_client.sqs.receive_message(QueueUrl=dlq_url, WaitTimeSeconds=10)
        assert (
            len(response["Messages"]) == 1
        ), f"invalid number of messages in DLQ response {response}"
        message = json.loads(response["Messages"][0]["Body"])
        assert message["Type"] == "Notification"
        assert json.loads(message["Message"])["message"] == "test_redrive_policy"

    @markers.aws.manual_setup_required
    def test_multiple_subscriptions_http_endpoint(
        self, sns_create_topic, sns_subscription, aws_client
    ):
        # create a topic
        topic_arn = sns_create_topic()["TopicArn"]

        # build fake http server endpoints
        _requests = queue.Queue()

        # create HTTP endpoint and connect it to SNS topic
        def handler(_request):
            _requests.put(_request)
            return Response(status=429)

        number_of_endpoints = 4

        servers = []
        try:
            for _ in range(number_of_endpoints):
                server = HTTPServer()
                server.start()
                servers.append(server)
                server.expect_request("/").respond_with_handler(handler)
                http_endpoint = server.url_for("/")
                wait_for_port_open(http_endpoint)

                sns_subscription(TopicArn=topic_arn, Protocol="http", Endpoint=http_endpoint)

            # fetch subscription information
            subscription_list = aws_client.sns.list_subscriptions_by_topic(TopicArn=topic_arn)
            assert subscription_list["ResponseMetadata"]["HTTPStatusCode"] == 200
            assert (
                len(subscription_list["Subscriptions"]) == number_of_endpoints
            ), f"unexpected number of subscriptions {subscription_list}"

            tokens = []
            for _ in range(number_of_endpoints):
                request = _requests.get(timeout=2)
                request_data = request.get_json(True)
                tokens.append(request_data["Token"])
                assert request_data["TopicArn"] == topic_arn

            with pytest.raises(queue.Empty):
                # make sure only four requests are received
                _requests.get(timeout=1)

            # assert the first subscription is pending confirmation
            sub_1 = subscription_list["Subscriptions"][0]
            sub_1_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=sub_1["SubscriptionArn"]
            )
            assert sub_1_attrs["Attributes"]["PendingConfirmation"] == "true"

            # assert the second subscription is pending confirmation
            sub_2 = subscription_list["Subscriptions"][1]
            sub_2_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=sub_2["SubscriptionArn"]
            )
            assert sub_2_attrs["Attributes"]["PendingConfirmation"] == "true"

            # confirm the first subscription
            response = aws_client.sns.confirm_subscription(TopicArn=topic_arn, Token=tokens[0])
            # assert the confirmed subscription is the first one
            assert response["SubscriptionArn"] == sub_1["SubscriptionArn"]

            # assert the first subscription is confirmed
            sub_1_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=sub_1["SubscriptionArn"]
            )
            assert sub_1_attrs["Attributes"]["PendingConfirmation"] == "false"

            # assert the second subscription is NOT confirmed
            sub_2_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=sub_2["SubscriptionArn"]
            )
            assert sub_2_attrs["Attributes"]["PendingConfirmation"] == "true"

        finally:
            subscription_list = aws_client.sns.list_subscriptions_by_topic(TopicArn=topic_arn)
            for subscription in subscription_list["Subscriptions"]:
                aws_client.sns.unsubscribe(SubscriptionArn=subscription["SubscriptionArn"])
            for server in servers:
                server.stop()

    @markers.aws.manual_setup_required
    @pytest.mark.parametrize("raw_message_delivery", [True, False])
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.http-message-headers.Accept",  # requests adds the header but not SNS, not very important
            "$.http-message-headers-raw.Accept",
            "$.http-confirm-sub-headers.Accept",
        ]
    )
    def test_subscribe_external_http_endpoint(
        self, sns_create_http_endpoint, raw_message_delivery, aws_client, snapshot
    ):
        def _get_snapshot_requests_response(response: requests.Response) -> dict:
            parsed_xml_body = xmltodict.parse(response.content)
            for root_tag, fields in parsed_xml_body.items():
                fields.pop("@xmlns", None)
                if "ResponseMetadata" in fields:
                    fields["ResponseMetadata"]["HTTPHeaders"] = dict(response.headers)
                    fields["ResponseMetadata"]["HTTPStatusCode"] = response.status_code
            return parsed_xml_body

        def _clean_headers(response_headers: dict):
            return {key: val for key, val in response_headers.items() if "Forwarded" not in key}

        snapshot.add_transformer(
            [
                snapshot.transform.key_value("RequestId"),
                snapshot.transform.key_value("Token"),
                snapshot.transform.key_value("Host"),
                snapshot.transform.key_value(
                    "Content-Length", reference_replacement=False
                ),  # might change depending on compression
                snapshot.transform.key_value(
                    "Connection", reference_replacement=False
                ),  # casing might change
                snapshot.transform.regex(
                    r"(?i)(?<=SubscribeURL[\"|']:\s[\"|'])(https?.*?)(?=/\?Action=ConfirmSubscription)",
                    replacement="<subscribe-domain>",
                ),
            ]
        )

        # Necessitate manual set up to allow external access to endpoint, only in local testing
        topic_arn, subscription_arn, endpoint_url, server = sns_create_http_endpoint(
            raw_message_delivery
        )
        assert poll_condition(
            lambda: len(server.log) >= 1,
            timeout=5,
        )
        sub_request, _ = server.log[0]
        payload = sub_request.get_json(force=True)
        snapshot.match("subscription-confirmation", payload)
        assert payload["Type"] == "SubscriptionConfirmation"
        assert sub_request.headers["x-amz-sns-message-type"] == "SubscriptionConfirmation"
        assert "Signature" in payload
        assert "SigningCertURL" in payload

        snapshot.match("http-confirm-sub-headers", _clean_headers(sub_request.headers))

        token = payload["Token"]
        subscribe_url = payload["SubscribeURL"]
        service_url, subscribe_url_path = payload["SubscribeURL"].rsplit("/", maxsplit=1)
        assert subscribe_url == (
            f"{service_url}/?Action=ConfirmSubscription&TopicArn={topic_arn}&Token={token}"
        )

        test_broken_confirm_url = (
            f"{service_url}/?Action=ConfirmSubscription&TopicArn=not-an-arn&Token={token}"
        )
        broken_confirm_subscribe_request = requests.get(test_broken_confirm_url)
        snapshot.match(
            "broken-topic-arn-confirm",
            _get_snapshot_requests_response(broken_confirm_subscribe_request),
        )

        test_broken_token_confirm_url = (
            f"{service_url}/?Action=ConfirmSubscription&TopicArn={topic_arn}&Token=abc123"
        )
        broken_token_confirm_subscribe_request = requests.get(test_broken_token_confirm_url)
        snapshot.match(
            "broken-token-confirm",
            _get_snapshot_requests_response(broken_token_confirm_subscribe_request),
        )

        # using the right topic name with a different region will fail when confirming the subscription
        parsed_arn = parse_arn(topic_arn)
        different_region = "eu-central-1" if parsed_arn["region"] != "eu-central-1" else "us-east-1"
        different_region_topic = topic_arn.replace(parsed_arn["region"], different_region)
        different_region_topic_confirm_url = f"{service_url}/?Action=ConfirmSubscription&TopicArn={different_region_topic}&Token={token}"
        region_topic_confirm_subscribe_request = requests.get(different_region_topic_confirm_url)
        snapshot.match(
            "different-region-arn-confirm",
            _get_snapshot_requests_response(region_topic_confirm_subscribe_request),
        )

        # but a nonexistent topic in the right region will succeed
        last_fake_topic_char = "a" if topic_arn[-1] != "a" else "b"
        nonexistent = topic_arn[:-1] + last_fake_topic_char
        assert nonexistent != topic_arn
        test_wrong_topic_confirm_url = (
            f"{service_url}/?Action=ConfirmSubscription&TopicArn={nonexistent}&Token={token}"
        )
        wrong_topic_confirm_subscribe_request = requests.get(test_wrong_topic_confirm_url)
        snapshot.match(
            "nonexistent-token-confirm",
            _get_snapshot_requests_response(wrong_topic_confirm_subscribe_request),
        )

        # weirdly, even with a wrong topic, SNS will confirm the topic
        subscription_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        assert subscription_attributes["Attributes"]["PendingConfirmation"] == "false"

        confirm_subscribe_request = requests.get(subscribe_url)
        confirm_subscribe = xmltodict.parse(confirm_subscribe_request.content)
        assert (
            confirm_subscribe["ConfirmSubscriptionResponse"]["ConfirmSubscriptionResult"][
                "SubscriptionArn"
            ]
            == subscription_arn
        )
        # also confirm that ConfirmSubscription is idempotent
        snapshot.match(
            "confirm-subscribe", _get_snapshot_requests_response(confirm_subscribe_request)
        )

        subscription_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=subscription_arn
        )
        assert subscription_attributes["Attributes"]["PendingConfirmation"] == "false"

        message = "test_external_http_endpoint"
        aws_client.sns.publish(TopicArn=topic_arn, Message=message)

        assert poll_condition(
            lambda: len(server.log) >= 2,
            timeout=5,
        )
        notification_request, _ = server.log[1]
        assert notification_request.headers["x-amz-sns-message-type"] == "Notification"

        expected_unsubscribe_url = (
            f"{service_url}/?Action=Unsubscribe&SubscriptionArn={subscription_arn}"
        )
        if raw_message_delivery:
            payload = notification_request.data.decode()
            assert payload == message
            snapshot.match("http-message-headers-raw", _clean_headers(notification_request.headers))
        else:
            payload = notification_request.get_json(force=True)
            assert payload["Type"] == "Notification"
            assert "Signature" in payload
            assert "SigningCertURL" in payload
            assert payload["Message"] == message
            assert payload["UnsubscribeURL"] == expected_unsubscribe_url
            snapshot.match("http-message", payload)
            snapshot.match("http-message-headers", _clean_headers(notification_request.headers))

        unsub_request = requests.get(expected_unsubscribe_url)
        unsubscribe_confirmation = xmltodict.parse(unsub_request.content)
        assert "UnsubscribeResponse" in unsubscribe_confirmation
        snapshot.match("unsubscribe-response", _get_snapshot_requests_response(unsub_request))

        assert poll_condition(
            lambda: len(server.log) >= 3,
            timeout=5,
        )
        unsub_request, _ = server.log[2]

        payload = unsub_request.get_json(force=True)
        assert payload["Type"] == "UnsubscribeConfirmation"
        assert unsub_request.headers["x-amz-sns-message-type"] == "UnsubscribeConfirmation"
        assert "Signature" in payload
        assert "SigningCertURL" in payload
        token = payload["Token"]
        assert payload["SubscribeURL"] == (
            f"{service_url}/?" f"Action=ConfirmSubscription&TopicArn={topic_arn}&Token={token}"
        )
        snapshot.match("unsubscribe-request", payload)

    @markers.aws.manual_setup_required
    @pytest.mark.parametrize("raw_message_delivery", [True, False])
    def test_dlq_external_http_endpoint(
        self,
        sqs_create_queue,
        sqs_get_queue_arn,
        sns_create_http_endpoint,
        sns_allow_topic_sqs_queue,
        raw_message_delivery,
        aws_client,
    ):
        # Necessitate manual set up to allow external access to endpoint, only in local testing
        topic_arn, http_subscription_arn, endpoint_url, server = sns_create_http_endpoint(
            raw_message_delivery
        )

        dlq_url = sqs_create_queue()
        dlq_arn = sqs_get_queue_arn(dlq_url)

        sns_allow_topic_sqs_queue(
            sqs_queue_url=dlq_url, sqs_queue_arn=dlq_arn, sns_topic_arn=topic_arn
        )
        aws_client.sns.set_subscription_attributes(
            SubscriptionArn=http_subscription_arn,
            AttributeName="RedrivePolicy",
            AttributeValue=json.dumps({"deadLetterTargetArn": dlq_arn}),
        )
        assert poll_condition(
            lambda: len(server.log) >= 1,
            timeout=5,
        )
        sub_request, _ = server.log[0]
        payload = sub_request.get_json(force=True)
        assert payload["Type"] == "SubscriptionConfirmation"
        assert sub_request.headers["x-amz-sns-message-type"] == "SubscriptionConfirmation"

        subscribe_url = payload["SubscribeURL"]
        service_url, subscribe_url_path = payload["SubscribeURL"].rsplit("/", maxsplit=1)

        confirm_subscribe_request = requests.get(subscribe_url)
        confirm_subscribe = xmltodict.parse(confirm_subscribe_request.content)
        assert (
            confirm_subscribe["ConfirmSubscriptionResponse"]["ConfirmSubscriptionResult"][
                "SubscriptionArn"
            ]
            == http_subscription_arn
        )

        subscription_attributes = aws_client.sns.get_subscription_attributes(
            SubscriptionArn=http_subscription_arn
        )
        assert subscription_attributes["Attributes"]["PendingConfirmation"] == "false"

        server.stop()
        wait_for_port_closed(server.port)

        message = "test_dlq_external_http_endpoint"
        aws_client.sns.publish(TopicArn=topic_arn, Message=message)

        response = aws_client.sqs.receive_message(QueueUrl=dlq_url, WaitTimeSeconds=3)
        assert (
            len(response["Messages"]) == 1
        ), f"invalid number of messages in DLQ response {response}"

        if raw_message_delivery:
            assert response["Messages"][0]["Body"] == message
        else:
            received_message = json.loads(response["Messages"][0]["Body"])
            assert received_message["Type"] == "Notification"
            assert received_message["Message"] == message

        receipt_handle = response["Messages"][0]["ReceiptHandle"]
        aws_client.sqs.delete_message(QueueUrl=dlq_url, ReceiptHandle=receipt_handle)

        expected_unsubscribe_url = (
            f"{service_url}/?Action=Unsubscribe&SubscriptionArn={http_subscription_arn}"
        )

        unsub_request = requests.get(expected_unsubscribe_url)
        unsubscribe_confirmation = xmltodict.parse(unsub_request.content)
        assert "UnsubscribeResponse" in unsubscribe_confirmation

        response = aws_client.sqs.receive_message(QueueUrl=dlq_url, WaitTimeSeconds=2)
        # AWS doesn't send to the DLQ if the UnsubscribeConfirmation fails to be delivered
        assert "Messages" not in response


class TestSNSSubscriptionFirehose:
    @markers.aws.validated
    def test_publish_to_firehose_with_s3(
        self,
        create_role,
        s3_create_bucket,
        firehose_create_delivery_stream,
        sns_create_topic,
        sns_subscription,
        aws_client,
    ):
        role_name = f"test-role-{short_uid()}"
        stream_name = f"test-stream-{short_uid()}"
        bucket_name = f"test-bucket-{short_uid()}"
        topic_name = f"test_topic_{short_uid()}"

        trust_policy = {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Principal": {"Service": "s3.amazonaws.com"},
                    "Action": "sts:AssumeRole",
                },
                {
                    "Effect": "Allow",
                    "Principal": {"Service": "firehose.amazonaws.com"},
                    "Action": "sts:AssumeRole",
                },
                {
                    "Effect": "Allow",
                    "Principal": {"Service": "sns.amazonaws.com"},
                    "Action": "sts:AssumeRole",
                },
            ],
        }

        role = create_role(RoleName=role_name, AssumeRolePolicyDocument=json.dumps(trust_policy))

        aws_client.iam.attach_role_policy(
            RoleName=role_name,
            PolicyArn="arn:aws:iam::aws:policy/AmazonKinesisFirehoseFullAccess",
        )

        aws_client.iam.attach_role_policy(
            RoleName=role_name, PolicyArn="arn:aws:iam::aws:policy/AmazonS3FullAccess"
        )
        subscription_role_arn = role["Role"]["Arn"]

        if is_aws_cloud():
            time.sleep(10)

        s3_create_bucket(Bucket=bucket_name)

        stream = firehose_create_delivery_stream(
            DeliveryStreamName=stream_name,
            DeliveryStreamType="DirectPut",
            S3DestinationConfiguration={
                "RoleARN": subscription_role_arn,
                "BucketARN": f"arn:aws:s3:::{bucket_name}",
                "BufferingHints": {"SizeInMBs": 1, "IntervalInSeconds": 60},
            },
        )

        topic = sns_create_topic(Name=topic_name)
        sns_subscription(
            TopicArn=topic["TopicArn"],
            Protocol="firehose",
            Endpoint=stream["DeliveryStreamARN"],
            Attributes={"SubscriptionRoleArn": subscription_role_arn},
            ReturnSubscriptionArn=True,
        )

        message = json.dumps({"message": "hello world"})
        message_attributes = {
            "testAttribute": {"DataType": "String", "StringValue": "valueOfAttribute"}
        }
        aws_client.sns.publish(
            TopicArn=topic["TopicArn"], Message=message, MessageAttributes=message_attributes
        )

        def validate_content():
            files = aws_client.s3.list_objects(Bucket=bucket_name)["Contents"]
            f = BytesIO()
            aws_client.s3.download_fileobj(bucket_name, files[0]["Key"], f)
            content = to_str(f.getvalue())

            sns_message = json.loads(content.split("\n")[0])

            assert "Type" in sns_message
            assert "MessageId" in sns_message
            assert "Message" in sns_message
            assert "Timestamp" in sns_message

            assert message == sns_message["Message"]

        retries = 5
        sleep = 1
        sleep_before = 0
        if is_aws_cloud():
            retries = 30
            sleep = 10
            sleep_before = 10

        retry(validate_content, retries=retries, sleep_before=sleep_before, sleep=sleep)


class TestSNSMultiAccounts:
    @pytest.fixture
    def sns_primary_client(self, aws_client):
        return aws_client.sns

    @pytest.fixture
    def sns_secondary_client(self, secondary_aws_client):
        return secondary_aws_client.sns

    @pytest.fixture
    def sqs_primary_client(self, aws_client):
        return aws_client.sqs

    @pytest.fixture
    def sqs_secondary_client(self, secondary_aws_client):
        return secondary_aws_client.sqs

    @markers.aws.only_localstack
    def test_cross_account_access(self, sns_primary_client, sns_secondary_client):
        # Cross-account access is supported for below operations.
        # This list is taken from ActionName param of the AddPermissions operation
        #
        # - GetTopicAttributes
        # - SetTopicAttributes
        # - AddPermission
        # - RemovePermission
        # - Publish
        # - Subscribe
        # - ListSubscriptionsByTopic
        # - DeleteTopic

        topic_name = f"topic-{short_uid()}"
        topic_arn = sns_primary_client.create_topic(Name=topic_name)["TopicArn"]

        assert sns_secondary_client.set_topic_attributes(
            TopicArn=topic_arn, AttributeName="DisplayName", AttributeValue="xenon"
        )

        response = sns_secondary_client.get_topic_attributes(TopicArn=topic_arn)
        assert response["Attributes"]["DisplayName"] == "xenon"

        assert sns_secondary_client.add_permission(
            TopicArn=topic_arn,
            Label="foo",
            AWSAccountId=["666666666666"],
            ActionName=["AddPermission"],
        )
        assert sns_secondary_client.remove_permission(TopicArn=topic_arn, Label="foo")

        assert sns_secondary_client.publish(TopicArn=topic_arn, Message="hello world")

        subscription_arn = sns_secondary_client.subscribe(
            TopicArn=topic_arn, Protocol="email", Endpoint="devil@hell.com"
        )["SubscriptionArn"]

        response = sns_secondary_client.list_subscriptions_by_topic(TopicArn=topic_arn)
        subscriptions = [s["SubscriptionArn"] for s in response["Subscriptions"]]
        assert subscription_arn in subscriptions

        assert sns_secondary_client.delete_topic(TopicArn=topic_arn)

    @markers.aws.only_localstack
    def test_cross_account_publish_to_sqs(
        self,
        sns_primary_client,
        sns_secondary_client,
        sqs_primary_client,
        sqs_secondary_client,
        sqs_get_queue_arn,
    ):
        """
        This test validates that we can publish to SQS queues that are not in the default account, and that another
        account can publish to the topic as well

        Note: we are not setting Queue policies here as it's only in localstack and IAM is not enforced, for the sake
        of simplicity
        """

        topic_name = "sample_topic"
        topic_1 = sns_primary_client.create_topic(Name=topic_name)
        topic_1_arn = topic_1["TopicArn"]

        # create a queue with the primary AccountId
        queue_name = "sample_queue"
        queue_1 = sqs_primary_client.create_queue(QueueName=queue_name)
        queue_1_url = queue_1["QueueUrl"]
        queue_1_arn = sqs_get_queue_arn(queue_1_url)

        # create a queue with the secondary AccountId
        queue_2 = sqs_secondary_client.create_queue(QueueName=queue_name)
        queue_2_url = queue_2["QueueUrl"]
        # test that we get the right queue URL at the same time, even if we use the primary client
        queue_2_arn = sqs_queue_arn(
            queue_2_url,
            SECONDARY_TEST_AWS_ACCOUNT_ID,
            TEST_AWS_REGION_NAME,
        )

        # test that we can subscribe with the primary client to a queue from the same account
        sns_primary_client.subscribe(
            TopicArn=topic_1_arn,
            Protocol="sqs",
            Endpoint=queue_1_arn,
        )

        # test that we can subscribe with the primary client to a queue from the secondary account
        sns_primary_client.subscribe(
            TopicArn=topic_1_arn,
            Protocol="sqs",
            Endpoint=queue_2_arn,
        )

        # now, we have 2 subscriptions in topic_1, one to the queue_1 located in the same account, and to queue_2
        # located in the secondary account

        sns_primary_client.publish(TopicArn=topic_1_arn, Message="TestMessageOwner")

        def get_messages_from_queues(message_content: str):
            for client, queue_url in (
                (sqs_primary_client, queue_1_url),
                (sqs_secondary_client, queue_2_url),
            ):
                response = client.receive_message(
                    QueueUrl=queue_url,
                    VisibilityTimeout=0,
                    WaitTimeSeconds=5,
                )
                messages = response["Messages"]
                assert len(messages) == 1
                assert topic_1_arn in messages[0]["Body"]
                assert message_content in messages[0]["Body"]
                client.delete_message(
                    QueueUrl=queue_url, ReceiptHandle=messages[0]["ReceiptHandle"]
                )

        get_messages_from_queues("TestMessageOwner")

        # assert that we can also publish to the topic 1 from the secondary account
        sns_secondary_client.publish(TopicArn=topic_1_arn, Message="TestMessageSecondary")

        get_messages_from_queues("TestMessageSecondary")


class TestSNSPublishDelivery:
    @markers.aws.validated
    @markers.snapshot.skip_snapshot_verify(
        paths=[
            "$.get-topic-attrs.Attributes.DeliveryPolicy",
            "$.get-topic-attrs.Attributes.EffectiveDeliveryPolicy",
            "$.get-topic-attrs.Attributes.Policy.Statement..Action",  # SNS:Receive is added by moto but not returned in AWS
        ]
    )
    def test_delivery_lambda(
        self,
        sns_create_topic,
        sns_subscription,
        lambda_su_role,
        create_lambda_function,
        create_role,
        create_policy,
        snapshot,
        aws_client,
    ):
        snapshot.add_transformers_list(
            [
                snapshot.transform.key_value(
                    "dwellTimeMs", reference_replacement=False, value_replacement="<time-ms>"
                ),
                snapshot.transform.key_value("nextBackwardToken"),
                snapshot.transform.key_value("nextForwardToken"),
            ]
        )
        function_name = f"lambda-function-{short_uid()}"
        permission_id = f"test-statement-{short_uid()}"
        subject = "[Subject] Test subject"
        message = "Hello world."
        topic_name = f"test-topic-{short_uid()}"
        topic_arn = sns_create_topic(Name=topic_name)["TopicArn"]
        parsed_arn = parse_arn(topic_arn)
        account_id = parsed_arn["account"]
        region = parsed_arn["region"]
        role_name = f"SNSSuccessFeedback-{short_uid()}"
        policy_name = f"SNSSuccessFeedback-policy-{short_uid()}"

        # enable Success Feedback from SNS to be sent to CloudWatch
        # TODO: this is enabled by default in LS
        trust_policy = {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Principal": {"Service": "sns.amazonaws.com"},
                    "Action": "sts:AssumeRole",
                }
            ],
        }
        cloudwatch_policy = {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": [
                        "logs:CreateLogGroup",
                        "logs:CreateLogStream",
                        "logs:PutLogEvents",
                        "logs:PutMetricFilter",
                        "logs:PutRetentionPolicy",
                    ],
                    "Resource": ["*"],
                }
            ],
        }

        role_response = create_role(
            RoleName=role_name, AssumeRolePolicyDocument=json.dumps(trust_policy)
        )
        role_arn = role_response["Role"]["Arn"]
        policy_arn = create_policy(
            PolicyName=policy_name, PolicyDocument=json.dumps(cloudwatch_policy)
        )["Policy"]["Arn"]
        aws_client.iam.attach_role_policy(RoleName=role_name, PolicyArn=policy_arn)
        if is_aws_cloud():
            # wait for the policy to be properly attached
            time.sleep(20)

        aws_client.sns.set_topic_attributes(
            TopicArn=topic_arn,
            AttributeName="LambdaSuccessFeedbackRoleArn",
            AttributeValue=role_arn,
        )

        aws_client.sns.set_topic_attributes(
            TopicArn=topic_arn,
            AttributeName="LambdaSuccessFeedbackSampleRate",
            AttributeValue="100",
        )

        topic_attributes = aws_client.sns.get_topic_attributes(TopicArn=topic_arn)
        snapshot.match("get-topic-attrs", topic_attributes)

        lambda_creation_response = create_lambda_function(
            func_name=function_name,
            handler_file=TEST_LAMBDA_PYTHON_ECHO,
            runtime=Runtime.python3_9,
            role=lambda_su_role,
        )
        lambda_arn = lambda_creation_response["CreateFunctionResponse"]["FunctionArn"]
        aws_client.lambda_.add_permission(
            FunctionName=function_name,
            StatementId=permission_id,
            Action="lambda:InvokeFunction",
            Principal="sns.amazonaws.com",
            SourceArn=topic_arn,
        )

        subscription = sns_subscription(
            TopicArn=topic_arn,
            Protocol="lambda",
            Endpoint=lambda_arn,
        )

        def check_subscription():
            subscription_arn = subscription["SubscriptionArn"]
            subscription_attrs = aws_client.sns.get_subscription_attributes(
                SubscriptionArn=subscription_arn
            )
            assert subscription_attrs["Attributes"]["PendingConfirmation"] == "false"

        retry(check_subscription, retries=PUBLICATION_RETRIES, sleep=PUBLICATION_TIMEOUT)

        aws_client.sns.publish(TopicArn=topic_arn, Subject=subject, Message=message)

        # TODO: Wait until Lambda function actually executes and not only for SNS logs
        log_group_name = f"sns/{region}/{account_id}/{topic_name}"

        def get_log_events():
            log_streams = aws_client.logs.describe_log_streams(logGroupName=log_group_name)[
                "logStreams"
            ]
            assert len(log_streams) == 1
            log_events = aws_client.logs.get_log_events(
                logGroupName=log_group_name,
                logStreamName=log_streams[0]["logStreamName"],
            )
            assert len(log_events["events"]) == 1
            # the default retention is 30 days, so delete the logGroup to clean up AWS
            with contextlib.suppress(ClientError):
                aws_client.logs.delete_log_group(logGroupName=log_group_name)
            return log_events

        sleep_time = 5 if is_aws_cloud() else 0.3
        events = retry(get_log_events, retries=10, sleep=sleep_time)

        # we need to decode the providerResponse to be able to properly match on the response
        # test would raise an error anyway if it's not a JSON string
        msg = json.loads(events["events"][0]["message"])
        events["events"][0]["message"] = msg
        events["events"][0]["message"]["delivery"]["providerResponse"] = json.loads(
            msg["delivery"]["providerResponse"]
        )

        snapshot.match("delivery-events", events)


class TestSNSRetrospectionEndpoints:
    @markers.aws.only_localstack
    def test_publish_to_platform_endpoint_can_retrospect(
        self, sns_create_topic, sns_subscription, sns_create_platform_application, aws_client
    ):
        sns_backend = SnsProvider.get_store(TEST_AWS_ACCOUNT_ID, TEST_AWS_REGION_NAME)
        # clean up the saved messages
        sns_backend_endpoint_arns = list(sns_backend.platform_endpoint_messages.keys())
        for saved_endpoint_arn in sns_backend_endpoint_arns:
            sns_backend.platform_endpoint_messages.pop(saved_endpoint_arn, None)

        topic_arn = sns_create_topic()["TopicArn"]
        application_platform_name = f"app-platform-{short_uid()}"

        app_arn = sns_create_platform_application(
            Name=application_platform_name, Platform="APNS", Attributes={}
        )["PlatformApplicationArn"]

        endpoint_arn = aws_client.sns.create_platform_endpoint(
            PlatformApplicationArn=app_arn, Token=short_uid()
        )["EndpointArn"]

        endpoint_arn_2 = aws_client.sns.create_platform_endpoint(
            PlatformApplicationArn=app_arn, Token=short_uid()
        )["EndpointArn"]

        sns_subscription(
            TopicArn=topic_arn,
            Protocol="application",
            Endpoint=endpoint_arn,
        )

        # example message from
        # https://docs.aws.amazon.com/sns/latest/dg/sns-send-custom-platform-specific-payloads-mobile-devices.html
        message = json.dumps({"APNS": json.dumps({"aps": {"content-available": 1}})})
        message_for_topic = {
            "default": "This is the default message which must be present when publishing a message to a topic.",
            "APNS": json.dumps({"aps": {"content-available": 1}}),
        }
        message_for_topic_string = json.dumps(message_for_topic)
        message_attributes = {
            "AWS.SNS.MOBILE.APNS.TOPIC": {
                "DataType": "String",
                "StringValue": "com.amazon.mobile.messaging.myapp",
            },
            "AWS.SNS.MOBILE.APNS.PUSH_TYPE": {
                "DataType": "String",
                "StringValue": "background",
            },
            "AWS.SNS.MOBILE.APNS.PRIORITY": {
                "DataType": "String",
                "StringValue": "5",
            },
        }
        # publish to a topic which has a platform subscribed to it
        aws_client.sns.publish(
            TopicArn=topic_arn,
            Message=message_for_topic_string,
            MessageAttributes=message_attributes,
            MessageStructure="json",
        )
        # publish directly to the platform endpoint
        aws_client.sns.publish(
            TargetArn=endpoint_arn_2,
            Message=message,
            MessageAttributes=message_attributes,
            MessageStructure="json",
        )

        # assert that message has been received
        def check_message():
            assert len(sns_backend.platform_endpoint_messages[endpoint_arn]) > 0

        retry(check_message, retries=PUBLICATION_RETRIES, sleep=PUBLICATION_TIMEOUT)

        msgs_url = config.get_edge_url() + PLATFORM_ENDPOINT_MSGS_ENDPOINT
        api_contents = requests.get(
            msgs_url, params={"region": TEST_AWS_REGION_NAME, "accountId": TEST_AWS_ACCOUNT_ID}
        ).json()
        api_platform_endpoints_msgs = api_contents["platform_endpoint_messages"]

        assert len(api_platform_endpoints_msgs) == 2
        assert len(api_platform_endpoints_msgs[endpoint_arn]) == 1
        assert len(api_platform_endpoints_msgs[endpoint_arn_2]) == 1
        assert api_contents["region"] == TEST_AWS_REGION_NAME

        assert api_platform_endpoints_msgs[endpoint_arn][0]["Message"] == json.dumps(
            message_for_topic["APNS"]
        )
        assert (
            api_platform_endpoints_msgs[endpoint_arn][0]["MessageAttributes"] == message_attributes
        )

        # Ensure you can select the region
        msg_with_region = requests.get(
            msgs_url,
            params={"region": SECONDARY_TEST_AWS_REGION_NAME, "accountId": TEST_AWS_ACCOUNT_ID},
        ).json()
        assert len(msg_with_region["platform_endpoint_messages"]) == 0
        assert msg_with_region["region"] == SECONDARY_TEST_AWS_REGION_NAME

        # Ensure default region is us-east-1
        msg_with_region = requests.get(msgs_url).json()
        assert msg_with_region["region"] == AWS_REGION_US_EAST_1

        # Ensure messages can be filtered by EndpointArn
        api_contents_with_endpoint = requests.get(
            msgs_url,
            params={
                "endpointArn": endpoint_arn,
                "region": TEST_AWS_REGION_NAME,
                "accountId": TEST_AWS_ACCOUNT_ID,
            },
        ).json()
        msgs_with_endpoint = api_contents_with_endpoint["platform_endpoint_messages"]
        assert len(msgs_with_endpoint) == 1
        assert len(msgs_with_endpoint[endpoint_arn]) == 1
        assert api_contents_with_endpoint["region"] == TEST_AWS_REGION_NAME

        # Ensure you can reset the saved messages by EndpointArn
        delete_res = requests.delete(
            msgs_url,
            params={
                "endpointArn": endpoint_arn,
                "region": TEST_AWS_REGION_NAME,
                "accountId": TEST_AWS_ACCOUNT_ID,
            },
        )
        assert delete_res.status_code == 204
        api_contents_with_endpoint = requests.get(
            msgs_url,
            params={
                "endpointArn": endpoint_arn,
                "region": TEST_AWS_REGION_NAME,
                "accountId": TEST_AWS_ACCOUNT_ID,
            },
        ).json()
        msgs_with_endpoint = api_contents_with_endpoint["platform_endpoint_messages"]
        assert len(msgs_with_endpoint[endpoint_arn]) == 0

        # Ensure you can reset the saved messages by region
        delete_res = requests.delete(
            msgs_url, params={"region": TEST_AWS_REGION_NAME, "accountId": TEST_AWS_ACCOUNT_ID}
        )
        assert delete_res.status_code == 204
        msg_with_region = requests.get(
            msgs_url, params={"region": TEST_AWS_REGION_NAME, "accountId": TEST_AWS_ACCOUNT_ID}
        ).json()
        assert not msg_with_region["platform_endpoint_messages"]

    @markers.aws.only_localstack
    def test_publish_sms_can_retrospect(self, sns_create_topic, sns_subscription, aws_client):
        sns_store = SnsProvider.get_store(TEST_AWS_ACCOUNT_ID, TEST_AWS_REGION_NAME)

        list_of_contacts = [
            f"+{random.randint(100000000, 9999999999)}",
            f"+{random.randint(100000000, 9999999999)}",
            f"+{random.randint(100000000, 9999999999)}",
        ]
        phone_number_1 = list_of_contacts[0]
        message = "Good news everyone!"
        topic_arn = sns_create_topic()["TopicArn"]
        for number in list_of_contacts:
            sns_subscription(TopicArn=topic_arn, Protocol="sms", Endpoint=number)

        # clean up the saved messages
        sns_store.sms_messages.clear()

        # publish to a topic which has a PhoneNumbers subscribed to it
        aws_client.sns.publish(Message=message, TopicArn=topic_arn)

        # publish directly to the PhoneNumber
        aws_client.sns.publish(
            PhoneNumber=phone_number_1,
            Message=message,
        )

        # assert that message has been received
        def check_message():
            assert len(sns_store.sms_messages) == 4

        retry(check_message, retries=PUBLICATION_RETRIES, sleep=PUBLICATION_TIMEOUT)

        msgs_url = config.get_edge_url() + SMS_MSGS_ENDPOINT
        api_contents = requests.get(
            msgs_url, params={"region": TEST_AWS_REGION_NAME, "accountId": TEST_AWS_ACCOUNT_ID}
        ).json()
        api_sms_msgs = api_contents["sms_messages"]

        assert len(api_sms_msgs) == 3
        assert len(api_sms_msgs[phone_number_1]) == 2
        assert len(api_sms_msgs[list_of_contacts[1]]) == 1
        assert len(api_sms_msgs[list_of_contacts[2]]) == 1

        assert api_contents["region"] == TEST_AWS_REGION_NAME

        assert api_sms_msgs[phone_number_1][0]["Message"] == "Good news everyone!"

        # Ensure you can select the region
        msg_with_region = requests.get(
            msgs_url, params={"region": SECONDARY_TEST_AWS_REGION_NAME}
        ).json()
        assert len(msg_with_region["sms_messages"]) == 0
        assert msg_with_region["region"] == SECONDARY_TEST_AWS_REGION_NAME

        # Ensure default region is us-east-1
        msg_with_region = requests.get(msgs_url).json()
        assert msg_with_region["region"] == AWS_REGION_US_EAST_1

        # Ensure messages can be filtered by EndpointArn
        api_contents_with_number = requests.get(
            msgs_url,
            params={
                "phoneNumber": phone_number_1,
                "accountId": TEST_AWS_ACCOUNT_ID,
                "region": TEST_AWS_REGION_NAME,
            },
        ).json()
        msgs_with_number = api_contents_with_number["sms_messages"]
        assert len(msgs_with_number) == 1
        assert len(msgs_with_number[phone_number_1]) == 2
        assert api_contents_with_number["region"] == TEST_AWS_REGION_NAME

        # Ensure you can reset the saved messages by EndpointArn
        delete_res = requests.delete(
            msgs_url,
            params={
                "phoneNumber": phone_number_1,
                "accountId": TEST_AWS_ACCOUNT_ID,
                "region": TEST_AWS_REGION_NAME,
            },
        )
        assert delete_res.status_code == 204
        api_contents_with_number = requests.get(
            msgs_url, params={"phoneNumber": phone_number_1}
        ).json()
        msgs_with_number = api_contents_with_number["sms_messages"]
        assert len(msgs_with_number[phone_number_1]) == 0

        # Ensure you can reset the saved messages by region
        delete_res = requests.delete(
            msgs_url, params={"region": TEST_AWS_REGION_NAME, "accountId": TEST_AWS_ACCOUNT_ID}
        )
        assert delete_res.status_code == 204
        msg_with_region = requests.get(msgs_url, params={"region": TEST_AWS_REGION_NAME}).json()
        assert not msg_with_region["sms_messages"]

    @markers.aws.only_localstack
    def test_subscription_tokens_can_retrospect(
        self, sns_create_topic, sns_subscription, sns_create_http_endpoint, aws_client
    ):
        sns_store = SnsProvider.get_store(TEST_AWS_ACCOUNT_ID, TEST_AWS_REGION_NAME)
        # clean up the saved tokens
        sns_store.subscription_tokens.clear()

        message = "Good news everyone!"
        # Necessitate manual set up to allow external access to endpoint, only in local testing
        topic_arn, subscription_arn, endpoint_url, server = sns_create_http_endpoint()
        assert poll_condition(
            lambda: len(server.log) >= 1,
            timeout=5,
        )
        sub_request, _ = server.log[0]
        payload = sub_request.get_json(force=True)
        assert payload["Type"] == "SubscriptionConfirmation"
        token = payload["Token"]
        server.clear()

        # we won't confirm the subscription, to simulate an external provider that wouldn't be able to access LocalStack
        # try to access the internal to confirm the Token is there
        tokens_base_url = config.get_edge_url() + SUBSCRIPTION_TOKENS_ENDPOINT
        api_contents = requests.get(f"{tokens_base_url}/{subscription_arn}").json()
        assert api_contents["subscription_token"] == token
        assert api_contents["subscription_arn"] == subscription_arn

        # try to send a message to an unconfirmed subscription, assert that the message isn't received
        aws_client.sns.publish(Message=message, TopicArn=topic_arn)

        assert poll_condition(
            lambda: len(server.log) == 0,
            timeout=1,
        )

        aws_client.sns.confirm_subscription(TopicArn=topic_arn, Token=token)
        aws_client.sns.publish(Message=message, TopicArn=topic_arn)
        assert poll_condition(
            lambda: len(server.log) == 1,
            timeout=2,
        )

        wrong_sub_arn = subscription_arn.replace(TEST_AWS_REGION_NAME, "us-west-1")
        wrong_region_req = requests.get(f"{tokens_base_url}/{wrong_sub_arn}")
        assert wrong_region_req.status_code == 404
        assert wrong_region_req.json() == {
            "error": "The provided SubscriptionARN is not found",
            "subscription_arn": wrong_sub_arn,
        }

        # Ensure proper error is raised with wrong ARN
        incorrect_arn_req = requests.get(f"{tokens_base_url}/randomarnhere")
        assert incorrect_arn_req.status_code == 400
        assert incorrect_arn_req.json() == {
            "error": "The provided SubscriptionARN is invalid",
            "subscription_arn": "randomarnhere",
        }
